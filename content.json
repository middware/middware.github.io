{"pages":[{"title":"关于我","text":"一.自我介绍 籍贯云南，现居上海。入职于阿里，花名玹霖。软件工程专业，专注于基础架构和各种中间件设计与研发。Spring Cloud中国社区创始人，《重新定义Spring Cloud实战》作者之一。 当当购买地址:http://product.dangdang.com/25348282.html京东购买地址:https://item.jd.com/12447280.html 曾就职于饿了么。 曾就职于唯品会平台架构部，参与唯品会中间件(服务网关,应用框架，代码生成器等)相关的研发工作。 曾参与唯品会互联网金融平台的设计与开发(https://jinrong.vip.com/)， 曾参与基于云计算Iaas的平安科技云平台(www.pinganyun.com)和`国泰君安证卷`云平台的开发， 曾参与基于云计算Saas平台的云销售管理系统的开发等。开发的私有云产品应用于太平人寿，东亚银行，天翼视讯，上海证券交易所,国泰君安等。 熟练运用各种流行的JavaEE技术进行组合式架构设计与开发。业余时间研究并发编程，中间件，异地多活，Spring Cloud，ZStack(zstack.org.cn)，Mycat等开源项目，以及软件架构设计，程序性能优化，JVM，高并发等！ 二.分享经历 Spring Cloud Zuul与网关中间件 Spring Cloud与中间件及国内使用情况 Spring Cloud 与微服务网关 Spring Cloud与领域驱动架构治理实战 三.联系方式 E-mail: Software_King@qq.com Github: Software_King 网站: http://xujin.org 网络ID:Software_King 微信:Software_King Spring Cloud中国社区:http://springcloud.cn 座右铭:软件世界就是模拟客观世界，从而需求分析，技术驱动，改造世界！","link":"/about/index.html"},{"title":"404 找不到该页面！","text":"对不起，您要找的内容本站不存在，可以在本站听一会音乐，休息一下！无法访本页的原因是：你使用的URL可能拼写错误或者它只是临时脱机所访问的页面不存在或被管理员已删除 请尝试以下操作： 1、尝试按F5进行页面刷新 2、重新键入URL地址进入访问 3、或返回 网站首页","link":"/404.html"}],"posts":[{"title":"Spring Boot中自定义注解+AOP实现主备库切换","text":"摘要: 本篇文章的场景是做调度中心和监控中心时的需求，后端使用TDDL实现分表分库，需求:实现关键业务的查询监控,当用Mybatis查询数据时需要从主库切换到备库或者直接连到备库上查询,从而减小主库的压力，在本篇文章中主要记录在Spring Boot中通过自定义注解结合AOP实现直接连接备库查询。 一.通过AOP 自定义注解实现主库到备库的切换1.1 自定义注解 自定义注解如下代码所示 12345678910import java.lang.annotation.ElementType;import java.lang.annotation.Retention;import java.lang.annotation.RetentionPolicy;import java.lang.annotation.Target;@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.METHOD)public @interface SwitchDataBase { boolean switch2Backup() default false;} 1.2 实现方法拦截器对自定义注解处理1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859import java.lang.reflect.Method;import java.util.Arrays;import org.aopalliance.intercept.MethodInterceptor;import org.aopalliance.intercept.MethodInvocation;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.stereotype.Component;/** * 处理走备库逻辑的注解 */@Componentpublic class SwitchDataBaseInterceptor implements MethodInterceptor { private final Logger log = LoggerFactory.getLogger(SwitchDataBaseInterceptor.class); @Override public Object invoke(MethodInvocation invocation) throws Throwable { Method method = invocation.getMethod(); SwitchDataBase annotation = getAnnotation(method); if (annotation == null) { return invocation.proceed(); } Object val = null; if(!ThreadLocalMap.containsKey(GroupDataSourceRouteHelper.DATASOURCE_INDEX)) { if (annotation.switch2Backup()) { log.info(\"query back up DB, method: \" + method.getName()); GroupDataSourceRouteHelper.executeByGroupDataSourceIndex(1, true); } else { log.info(\"query primary DB, method: \" + method.getName()); GroupDataSourceRouteHelper.executeByGroupDataSourceIndex(0, true); } } try { val = invocation.proceed(); } catch (Exception e) { log.info(method.getDeclaringClass().getName() + \".\" + invocation.getMethod().getName() + \"方法调用失败，arguments：\" + Arrays.toString(invocation.getArguments())); throw new RuntimeException(e); } finally { GroupDataSourceRouteHelper.removeGroupDataSourceIndex(); } return val; } /** * 找方法上面声明的注解 */ private SwitchDataBase getAnnotation(Method method) { if (method.isAnnotationPresent(SwitchDataBase.class)) { return method.getAnnotation(SwitchDataBase.class); } return null; }} 1.3 配置OverallQueryConfiguration 在Spring Boot中装配AOP Bean，实现扫描特定目录下的注解，实现切面变成形成通知处理。示例代码如下 12345678910111213141516171819202122232425262728293031323334353637package com.wdk.wms.configuration;import com.wdk.wms.annotation.SwitchDataBaseInterceptor;import org.springframework.aop.Advisor;import org.springframework.aop.support.DefaultPointcutAdvisor;import org.springframework.aop.support.JdkRegexpMethodPointcut;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;@Configurationpublic class SwitchDataBaseConfiguration { @Bean(name = \"overallQueryInterceptor\") public SwitchDataBaseInterceptor overallQueryInterceptor() { return new SwitchDataBaseInterceptor(); } //添加aop的pointcut @Bean(name = \"jdkRegexpMethodPointcut\") public JdkRegexpMethodPointcut jdkRegexpMethodPointcut() { JdkRegexpMethodPointcut jdkRegexpMethodPointcut = new JdkRegexpMethodPointcut(); jdkRegexpMethodPointcut.setPatterns(\"com.wdk.wms.mapper.*\"); return jdkRegexpMethodPointcut; } //设置默认的aop配置对应的是原来的&lt;aop:advisor&gt; @Bean public Advisor druidAdvisor() { DefaultPointcutAdvisor defaultPointcutAdvisor = new DefaultPointcutAdvisor(); defaultPointcutAdvisor.setPointcut(jdkRegexpMethodPointcut()); defaultPointcutAdvisor.setAdvice(overallQueryInterceptor()); return defaultPointcutAdvisor; }} 1.4 如何使用注解从主库到备库的切换12@SwitchDataBase(switch2Backup = true)List&lt;ConsumerNoticeMsg&gt; listByTemplateOver3(@Param(\"templates\") List&lt;Integer&gt; templates);","link":"/sb/sb-aop/"},{"title":"公益Eureka Server与定制方法","text":"摘要: 本文主要简单介绍如何定制一个eureka server，并直接指出最优的定制方式。 1. Spring Cloud中国公益Eureka ServerEureka Server为作为Spring Cloud开发过程中常用的注册中心组件，作为基础设施组件，开发学习过程中，经常需要自己创建Eureka Server应用和重启。为了帮助开发者快速学习入门。Spring Cloud中国社区特搭建一个公益注册中心，仅作为帮助Spring Cloud的开发者进行学习和调试。为了更好服务大家，请勿对本注册中心进行压测。定制的Eureka Server注册中心UI如下所示。 1.1 访问地址 http://eureka.springcloud.cn 2.定制Eureka Serrver的UI2.1 为什么要定制Eureka Server 原因两点: 1.觉得默认的UI比较丑 2.Eureka Server想客制化一下 至于Spring Cloud Eureka的UI客制化成什么样子由你而定！ 3. 两种方法定制Eureka Server3.1 直接修改eureka server的源代码 直接修改eureka server的源代码，该方法是最纯的方式，而且每次有一个Eureka Server的版本都需要去修改。 3.2 只修改Eureka Server的UI只需要修改对应的html+css+文案即可，完全不用去修改Eureka Server的源码,强烈推荐。 源码参考地址:https://github.com/SpringCloud/spring-cloud-eureka 3.3 为什么我定制自己的UI加进去 为什么我定制自己的UI加进去，就可以直接Run，那源码代码中的UI是不是被覆盖了？ 123456789101112&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;cn.springcloud.eureka&lt;/groupId&gt; &lt;artifactId&gt;eureka-server-ui&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 如上maven配置所示，官方的spring-cloud-starter-netflix-eureka-server依赖信息配置在下面，由maven的依赖加载顺序决定，定制的UI优先加载显示。 4. 如何在项目中使用DIY的Eureka Server只需要配置maven依赖即可:123456789101112&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;cn.springcloud.eureka&lt;/groupId&gt; &lt;artifactId&gt;eureka-server-ui&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;","link":"/sc/sc-diy-eureka/"},{"title":"《Spring Cloud中国社区上海网关专题会议》","text":"网关在微服务中的地位尤其重要，如果网关挂了或者出现任何抖动，用户请求的流量将会损耗，将会造成巨大的损失。因此Spring Cloud中国社区联合上海秦苍科技，走进企业畅聊Spring Cloud实战经验，以及网关经验。 一.会议内容1.主题《Spring Cloud中国社区上海网关专题》2.时间:2017年8月20，会议方式:闭门会议3.地点:上海市浦东新区峨山路91弄陆家嘴软件园9号楼（北楼）8楼4.主办方Spring Cloud中国社区+上海秦苍科技5.预计参会人数: 40-50人之间，先到先得，名额满关闭报名通道。6.分享方式(分享人分享+讨论+头脑风暴) 二.分享内容 Spring Cloud Zuul与GPRC服务治理体系整合，来源于Spring Cloud中国社区开源项目saluki。 基于Netty自研网关中间件纳管Spring Cloud。 如何压测和自动化测试网关 上海秦苍科技(买单侠)Spring Cloud生产实战分享(包括Zuul) PS:分享嘉宾保密，闭门会议，您懂得。 三.报名方式扫支付宝二维码，支付完毕之后，加管理员微信Software_King，进入微信群，同时会进入Spring Cloud中国社区VIP会员群。 报名费-&gt;用于茶歇+请分享嘉宾喝咖啡","link":"/sc/sc-gw/"},{"title":"Spring Cloud 使用 HTTP2的性能压测对比","text":"摘要:本文由何鹰投稿分享。投稿请加微信Software_King,本文主要是对Spring Cloud中的HTTP2的性能进行压测分析，生成压测结果。spring cloud 使用 HTTP2源码地址 一.Spring Cloud 使用 HTTP2 我本人是从 Dubbo 转用 Spring cloud。2016年9月左右刚接触 Spring cloud，那个时候跟大家一样做了很多 dubbo vs Spring cloud 的对比分析。当时最大的疑问是性能对比，问 Josh Long 后续有无支持类似于 dubbo 的其他RPC、序列化协议，他说 HTTP2性能已经足够好了，没有计划支持。当时想到 HTTP2是多路复用，长连接，性能损失仅仅是序列化反序列化的区别，因此就此打住没有深入测试。 上周在 W3上看到张琦的帖子里说到 ServiceCombo以性能问题第一个就把 Spring cloud 淘汰了，加上之前的dubbo vs Spring cloud 性能测试结果，就想到用 HTTP2进一步优化 Spring cloud 性能。孰优孰劣？Dubbo VS Spring Cloud性能测试大对决！ 二.启动顺序2.1 启动 config2.2 启动 eureka2.3 启动 provider2.4 启动 consumerJDK9以下不默认支持HTTP2，需要添加启动参数： -Xbootclasspath/p:/Users/charles/.m2/repository/org/mortbay/jetty/alpn/alpn-boot/8.1.12-SNAPSHOT/alpn-boot-8.1.12-SNAPSHOT.jar 三.测试 HTTP23.1 测试服务提供者访问 https://localhost:8443/user访问 chrome://net-internals/#http2确认服务器HTTP2支持已经开启 3.2 测试服务消费者访问 http://localhost:18090/test在服务提供者控制台查看日志 是否是 http2 协议 2017-12-17 11:36:59.479 INFO 663 — [ XNIO-2 task-7] c.g.c.s.p.p.controller.UserController : query all HTTP/2.0 [accept-language:en-US,en;q=0.9] [upgrade-insecure-requests:1] [Host:localhost:8443] [accept-encoding:gzip, deflate, br] [accept:text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,/;q=0.8] [user-agent:Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.84 Safari/537.36] 3.3 测试性能访问： http://localhost:18090/test/count?thread=200&amp;api=test100 thread 可以为任意值api为 test10 test100 test1000服务消费者控制台查看吞吐量 四.性能对比4.1 测试 HTTP with SSL 性能对比provider bootstrap.properties 注释 server.http2.enabled=true和上面一样进行性能测试 4.2 测试 HTTP 性能对比provider bootstrap.properties 注释 server.http2.enabled=true以及下方所有配置项和上面一样进行性能测试 4.3 测试 HTTP without Keep-Alive修改TestController 每次 new RestTemplate (其实在 Header 中指定 Connection=close 可以关闭 Keep-Alive 但是会运行一段时间后超时 error) new RestTemplate().getForObject(“http://127.0.0.1:8080/user/&quot; + api, String.class); // restTemplate.getForObject(“http://provider/user/&quot; + api, String.class); 4.4 测试结果 吞吐量/秒 测试组合 HTTP without Keep-Alive HTTP with Keep-Alive HTTP+SSL HTTP2 T100 O10 1210 8850 3310 6320 T100 0100 1115 7525 2225 3410 T100 01000 950 2710 1150 1080 T200 010 1050 8650+error 4200+error 6120 T200 0100 1035 7250 330+error 3250 T200 01000 870 2650 495 930 分析： 测试结果与 Josh Long 所说不同，HTTP2并不能带来性能的提升。HTTP2 的多路复用相比 HTTP1.1 Keep-Alive 的”单路复用”相比优势并不大，反而带来了 SSL 加解密的性能损失(HTTP2协议本身不要求 SSL，但是目前实现均为 HTTP2强制 SSL)。HTTP2多路复用可以节省链接，避免链接超容器上限。 HTTP2+SSL 相比 HTTP1.1+SSL 有性能优势，但是针对 Spring cloud 内部调用场景我们并不会开启 HTTPS，因此是个废的，在此场景之下最佳选择是 HTTP1.1 + Keep-Alive。 原文链接:http://www.jianshu.com/p/ed3f8f983764","link":"/sc/sq/sc-http2/"},{"title":"SC中Eureka Server的HA和安全身份验证","text":"摘要:在《跟我学Spring Cloud》中的上一篇文章中简单介绍了使用Eureka实现服务的注册与发现。在这篇文章中主要介绍一下Eureka Server注册中心的HA以及Eureka Server的身份验证。 什么是高可用高可用 High Availability，即高可用HA。在分布式情况下，我们经常说4个9(99.99%)或者5个9(99.999%)。举个简单例子，如果一个微服务分布式系统依赖于30个微服务，每个微服务可用性是99.99%，那么整个微服务系统的可用性就是99.99%的30次方 ≈ 99.7% ，也就是说有0.3%系统是不可用的，0.3%意味着如果Qps很高，有一亿次请求的话，那么就会有30万次失败。换算成时间大约每月有2个小时服务不稳定。特别是随着服务依赖数量的变多，微服务不稳定的概率会成指数性上升。因此要保证微服务应用的HA需要从各方面入手，下面会介绍一下如何实现Eureka Server的HA。参考工程如下所示。 Tips：代码示例:https://github.com/SoftwareKing/spring-cloud-study/tree/master/sc-eureka-ha Eureka Server的HAEureka Server的HA两个工程演示HA 如示例工程所示，我新建了两个Project分别为sc-eureka-ha-server1，sc-eureka-ha-server2， 我们知道在Eureka Server的Standalone模式下面，由于只有一个Eureka Server，所以我们通过配置如下信息关闭Eureka Server的自我注册和抓取注册信息，但是两个Eureka Server之间需要设置为True，相互注册相互感知对方注册信息的变化，从而实现信息同步。 1.sc-eureka-ha-server1的application.yml配置Info 如下： 123456789spring: application: name: sc-eureka-ha-server1server: port: 8761 # 指定该Eureka实例的端口eureka: client: serviceUrl: defaultZone: http://localhost:8762/eureka/ 2.sc-eureka-ha-server2的application.yml配置Info 如下 12345678910spring: application: name: sc-eureka-ha-server2 server: port: 8762 # 指定该Eureka实例的端口eureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka/ 3.主程序入口代码没什么区别如下: 1234567@EnableEurekaServer@SpringBootApplicationpublic class EurekaServerApplication { public static void main(String[] args) { SpringApplication.run(EurekaServerApplication.class, args); }} 4.分别启动sc-eureka-ha-server1和sc-eureka-ha-server2，访问http://localhost:8761/ ,http://localhost:8762/ ，如下: 5.服务提供者sc-eureka-ha-provider其它代码见工程,application.yml如下所示。 1234567891011 server: port: 8000 spring: application: name: sc-eureka-ha-provider eureka: client: service-url: defaultZone: http://localhost:8761/eureka/ tips: 把服务提供者的服务注册信息，注册到Eureka Server 01上。 启动服务提供者，见如下图所示。 片刻服务提供者的信息也同步到Eureka Server02上面 Jar方式演示HA Eureka Server的HA，其实可以通过jar的方式指定使用不同的profile配置的方式，在本地运行两个Eureka Server。只需将Eureka server的application.yml修改如下：12345678910111213141516171819202122232425spring: application: name: sc-eureka-ha-server --- spring: profiles: peer1 server: port: 8761 eureka: instance: hostname: peer1.xujin.org client: serviceUrl: defaultZone: http://peer2.xujin.org:8762/eureka/ --- spring: profiles: peer2 server: port: 8762 eureka: instance: hostname: peer2.xujin.org client: serviceUrl: defaultZone: http://peer1.xujin.org:8761/eureka/ 通过配置switcHosts或者自行配置HostName对应的IP地址,把工程打成jar之后，运行如下命令123 java -jar sc-eureka-ha-server1-0.0.1-SNAPSHOT.jar --spring.profiles.active=peer2java -jar sc-eureka-ha-server1-0.0.1-SNAPSHOT.jar --spring.profiles.active=peer1 测试如下: 安全身份验证 如果客户端的eureka.client.serviceUrl.defaultZone参数值(即Eureka Server的地址)中包含HTTP Basic Authentication信息，如http://user:password@localhost:8761/eureka，那么客户端就会自动使用该用户名、密码信息与Eureka服务端进行验证。如果你需要更复杂的验证逻辑，你必须注册一个DiscoveryClientOptionalArgs组件，并将ClientFilter组件注入，在这里定义的逻辑会在每次客户端向服务端发起请求时执行。 Tips：代码示例:https://github.com/SoftwareKing/spring-cloud-study/tree/master/sc-eureka-security 访问Eureka Server安全身份验证 如工程sc-eureka-securit中的sc-eureka-security-server工程所示，在pom.xml中增加依赖如下: 1234 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt; application.yml如下 123456789101112131415161718 server: port: 8761 # 指定该Eureka实例的端口eureka: client: #表示是否将自己注册到Eureka Server上，默认为true，当前应用为Eureka Server所以无需注册 registerWithEureka: false #表示是否从Eureka Server获取注册信息，默认为true。因为这是一个单点的Eureka Server，不需要同步其他的Eureka Server节点的数据，故而设为false。 fetchRegistry: false #Eureka Server的访问地址，服务注册和client获取服务注册信息均通过该URL，多个服务注册地址用,隔开 serviceUrl: defaultZone: http://localhost:8761/eureka/ security: basic: enabled: true user: name: xujin password: 123 3.启动Eureka server测试，如下图所示 服务提供者注册Eureka Server安全身份验证1.服务提供者只需注册时修改application.yml 1234567891011 server: port: 8000 spring: application: name: sc-eureka-security-provider eureka: client: service-url: defaultZone: http://xujin:123@localhost:8761/eureka/ Tips:如上所示:http://用户名:密码@localhost:8761/eureka/","link":"/sc/sc-eureka-02/"},{"title":"Spring Cloud Netflix之Eureka上篇","text":"前言:Spring Cloud NetFlix这个项目对NetFlix中一些久经考验靠谱的服务发现，熔断，网关，智能路由，以及负载均衡等做了封装，并通过注解的或简单配置的方式提供给Spring Cloud用户用。本文主要介绍 Spring Cloud中的Eureka组件。由于Spring Cloud做技术选型时中立的，因此Spring Cloud也提供了Spring Cloud Zookeeper,Spring Cloud Consul用于服务治理或服务发现供大家选择使用，另外我还发现Spring Cloud etcd这个项目，也可以用于服务注册和发现 什么是 Spring Cloud Netflix ?其官方文档中对自己的定义是如下，官网连接,Github地址 This project provides Netflix OSS integrations for Spring Boot apps through autoconfiguration and binding to the Spring Environment and other Spring programming model idioms. With a few simple annotations you can quickly enable and configure the common patterns inside your application and build large distributed systems with battle-tested Netflix components. The patterns provided include Service Discovery (Eureka), Circuit Breaker (Hystrix), Intelligent Routing (Zuul) and Client Side Load Balancing (Ribbon). Spring Cloud Netflix这个项目对于Spring Boot应用来说，它集成了NetFlix OSS的一些组件，只需通过注解配置和Spring环境的通用简单的使用注解，你可以快速的启用和配置这些久经测试考验的NetFlix的组件于你的应用和用于构建分布式系统中。这些组件包含的功能有服务发现（Eureka），熔断器（Hystrix），智能路由(Zuul)以及客户端的负载均衡器（Ribbon） 简单的来说，Spring Cloud NetFlix这个项目对NetFlix中一些久经考验靠谱的服务发现，熔断，网关，智能路由，以及负载均衡等做了封装，并通过注解的或简单配置的方式提供给Spring Cloud用户用。 什么是 Eureka?官网定义是: Eureka is a REST (Representational State Transfer) based service that is primarily used in the AWS cloud for locating services for the purpose of load balancing and failover of middle-tier servers. We call this service, the Eureka Server. Eureka also comes with a Java-based client component,the Eureka Client, which makes interactions with the service much easier. The client also has a built-in load balancer that does basic round-robin load balancing. 简单来说Eureka就是Netflix开源的一款提供服务注册和发现的产品，并且提供了相应的Java客户端。 为什么要选择 Eureka?那么为什么我们在项目中使用了Eureka呢？主要原因如下: 它提供了完整的Service Registry和Service Discovery实现 首先是提供了完整的实现，并且也经受住了Netflix的生产环境考验，使用比较方便只需通过注解或简单配置的方式即可。 和Spring Cloud无缝集成 Spring Cloud对Eureka做了无缝集成，提供了一套完善的解决方案，所以使用起来非常方便。 另外，Eureka支持嵌入到应用自身的容器中启动，应用启动完之后，既充当了Eureka的角色，同时也是服务的提供者。这样就极大的提高了服务的可用性。 开源 开源代码，方便学习掌握其源码并驾驭它。 参考阅读：为什么不应该使用ZooKeeper做服务发现英文链接:Eureka! Why You Shouldn’t Use ZooKeeper for Service Discovery:http://www.knewton.com/tech/blog/2014/12/eureka-shouldnt-use-zookeeper-service-discovery/中文链接:http://blog.csdn.net/jenny8080/article/details/52448403Eureka vs. Zookeeper：https://groups.google.com/forum/#%21topic/eureka_netflix/LXKWoD14RFY 进一步了解 EurekaEureka基本架构图 上图简要描述了Eureka的基本架构，由3个角色组成： Eureka Server 提供服务注册和发现 Service Provider 服务提供者，服务启动的时候会将自己的服务信息注册到Eureka Service Consumer 服务消费者，从Eureka中获取已注的服务信息，用于调用服务生产者 需要注意一点是：一个Service Provider既可以是Service Consumer，也可以是Service Provider。 集群模式下的Eureka 上图更进一步的展示了3个角色之间的交互。 Service Provider会向Eureka Server做Register（服务注册）、Renew（服务续约）、Cancel（服务下线）等操作。 Eureka Server之间会做注册服务的同步，从而保证状态一致 Service Consumer会向Eureka Server获取注册服务列表，并消费服务","link":"/sc/sc-netflix-eureka/"},{"title":"Spring Cloud Netflix之Eureka下篇原理","text":"摘要:本文主要介绍Eureka的工作原理，Eureka 组件分为两部分：Eureka server和 Eureka client。而客户端又分为 Application Service 客户端和 Application Client 客户端两种。Eureka 的工作机制每个 region 都有自己的 Eureka 服务器集群，每个 zone 至少要有一个 Eureka 服务器以应对 zone 瘫痪。 概述名词解释 Renew:我的理解是续约，为什么叫续约呢？Renew（服务续约）操作由Service Provider定期调用，类似于heartbeat。目的是隔一段时间Service Provider调用接口，告诉Eureka Server它还活着没挂，不要把它踢掉。通俗的说就是它们两之间的心跳检测，避免服务提供者被剔除掉。 Cancel（服务下线）一般在Service Provider挂了或shut down的时候调用，用来把自身的服务从Eureka Server中删除，以防客户端调用到不存在的服务。 Fetch Registries(获取注册信息)，Fetch Registries由Service Consumer(服务消费者)调用，用来获取Eureka Server上注册的服务info。 Eviction(剔除)Eviction（失效服务剔除）用来定期在Eureka Server检测失效的服务，检测标准就是超过一定时间没有Renew的服务。回顾Eureka架构图Eureka架构图Eureka架构图如下图所示，github地址:https://github.com/netflix/eurekadocument地址:https://github.com/Netflix/eureka/wiki/Eureka-at-a-glance&ensp; 从图中我们可以看出，Eureka 组件分为两部分：Eureka server和 Eureka client。而客户端又分为 Application Service 客户端和 Application Client 客户端两种。Eureka 的工作机制每个 region 都有自己的 Eureka 服务器集群，每个 zone 至少要有一个 Eureka 服务器以应对 zone 瘫痪。&ensp; Application Service 在启动时注册到 Eureka 服务器，之后每 30 秒钟发送心跳以更新自身状态,即Renew(续约)。如果该客户端没能发送心跳更新，它将在 90 秒之后被其注册的 Eureka 服务器剔除，即Eviction(剔除)。来自任意 zone 的 Application Client 可以获取这些注册信息(每隔 30 秒查看一次)并依此定位到在任何区域可以给自己提供服务的提供者(即Fetch Registries)，进而进行远程调用。 服务提供者本身携带的Eureka Client既能服务注册，服务续约，也能通过client定位服务和调用其它的服务。 服务注册服务注册 服务注册源码分析，请参考:http://blog.xujin.org/sc/sc-eureka-register/ Renew(服务续约)服务续约 Renew操作会在Service Provider端定期发起，用来通知Eureka Server自己还活着。 这里有两个比较重要的配置需要注意一下：1eureka.instance.leaseRenewalIntervalInSeconds Renew频率。默认是30秒，也就是每30秒会向Eureka Server发起Renew操作。1eureka.instance.leaseExpirationDurationInSeconds 服务失效时间。默认是90秒，也就是如果Eureka Server在90秒内没有接收到来自Service Provider的Renew操作，就会把Service Provider剔除。","link":"/sc/sc-eureka-mid/"},{"title":"Spring Cloud项目中通过Feign进行内部服务调用发生401\\407错误无返回信息的问题","text":"前言 最近好几个小伙伴，问Spring Cloud项目中通过Feign进行内部服务调用发生401\\407错误无返回信息的问题。这个问题如果没有自定义异常自定义Code或者系统中没有自定义code为401或407的code，基本很少能碰到。刚好Spring Cloud中国社区的VIP会员任聪博客原文也遇到这个，经过和他交流之后。整理出这篇文章希望能帮助更多的人快速定位问题。 问题描述最近在使用Spring Cloud改造现有服务的工作中，在内部服务的调用方式上选择了Feign组件，由于服务与服务之间有权限控制，发现通过Feign来进行调用时如果发生了401、407错误时，调用方不能够取回被调用方返回的错误信息。 产生原因分析产生原因Feign默认使用java.net.HttpURLConnection进行通信，通过查看其子类sun.net.www.protocol.http.HttpURLConnection源码发现代码中在进行通信时单独对错误码为401\\407的错误请求做了处理，当请求的错误码为401\\407时，会关闭请求流，由于此时还并没有将返回的错误信息写入响应流中，所以接收的返回信息中仅仅能获取到response.status()，而response.body()为null。HttpURLConnection相关信息的源码链接 问题源代码示例1234567if (respCode == HTTP_UNAUTHORIZED) { if (streaming()) { disconnectInternal(); throw new HttpRetryException (RETRY_MSG2, HTTP_UNAUTHORIZED); } //其余代码省略} java.net.HttpURLConnection中的HTTP_UNAUTHORIZED的定义如下: 1public static final int HTTP_UNAUTHORIZED = 401; 解决思路关于此问题产生的原因已经很明显了，就是feign.Client实现通信的方式选用了我们不想使用的HttpURLConnection。想到通常在Spring的代码中OCP都是运用得很好的，所以基本上有解决此问题的信心了，最不济就是自己扩展Feign，实现一个自己想要的feign.Client，当然这种事情Spring Cloud基本都会自己搞定，这也是Spring Cloud强大完善的一个地方。通过这个思路查看源码，果然看到了Spring Cloud在使用Feign提前内置了三种通信方式（feign.Client.Default，feign.httpclient.ApacheHttpClient，feign.okhttp.OkHttpClient），其中缺省的情况使用的就是feign.Client.Default，这个就是使用HttpURLConnection通信的方式。 源码解析在Spring Cloud项目中使用了Ribbon的组件，其会帮助我们管理使用Feign，查看org.springframework.cloud.netflix.feign.ribbon.FeignRibbonClientAutoConfiguration源码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859@ConditionalOnClass({ ILoadBalancer.class, Feign.class })@Configuration@AutoConfigureBefore(FeignAutoConfiguration.class)public class FeignRibbonClientAutoConfiguration { @Bean @ConditionalOnMissingBean public Client feignClient(CachingSpringLoadBalancerFactory cachingFactory, SpringClientFactory clientFactory) { return new LoadBalancerFeignClient(new Client.Default(null, null), cachingFactory, clientFactory); } @Configuration @ConditionalOnClass(ApacheHttpClient.class) @ConditionalOnProperty(value = \"feign.httpclient.enabled\", matchIfMissing = true) protected static class HttpClientFeignLoadBalancedConfiguration { @Autowired(required = false) private HttpClient httpClient; @Bean @ConditionalOnMissingBean(Client.class) public Client feignClient(CachingSpringLoadBalancerFactory cachingFactory, SpringClientFactory clientFactory) { ApacheHttpClient delegate; if (this.httpClient != null) { delegate = new ApacheHttpClient(this.httpClient); } else { delegate = new ApacheHttpClient(); } return new LoadBalancerFeignClient(delegate, cachingFactory, clientFactory); } } @Configuration @ConditionalOnClass(OkHttpClient.class) @ConditionalOnProperty(value = \"feign.okhttp.enabled\", matchIfMissing = true) protected static class OkHttpFeignLoadBalancedConfiguration { @Autowired(required = false) private okhttp3.OkHttpClient okHttpClient; @Bean @ConditionalOnMissingBean(Client.class) public Client feignClient(CachingSpringLoadBalancerFactory cachingFactory, SpringClientFactory clientFactory) { OkHttpClient delegate; if (this.okHttpClient != null) { delegate = new OkHttpClient(this.okHttpClient); } else { delegate = new OkHttpClient(); } return new LoadBalancerFeignClient(delegate, cachingFactory, clientFactory); } }} 从feignClient(CachingSpringLoadBalancerFactory cachingFactory, SpringClientFactory clientFactory) 方法结合其上注解我们可以很清楚的知道，当没有feign.ClientBean的时候会默认生成feign.Client.Default来进行通信，这就是之前说的缺省通信方式 从HttpClientFeignLoadBalancedConfiguration、OkHttpFeignLoadBalancedConfiguration，我们可以看到其生效的条件，当classpath中有feign.httpclient.ApacheHttpClient并且配置feign.httpclient.enabled=true（缺省为true）、feign.okhttp.OkHttpClient并且配置feign.okhttp.enabled=true（缺省为true） 当使用ApacheHttpClient或者OkHttpClient进行通信时就不会导致发生401\\407错误时，取不到返回的错误信息了 解决方法通过其上的分析，解决方法已经显而易见了替换默认的Client pom.xml文件中新增依赖替换为默认为okhttp Client 增加依赖 12345&lt;dependency&gt; &lt;groupId&gt;com.netflix.feign&lt;/groupId&gt; &lt;artifactId&gt;feign-okhttp&lt;/artifactId&gt; &lt;version&gt;8.18.0&lt;/version&gt; &lt;/dependency&gt; 2.在application.properties增加配置如下: 1feign.okhttp.enabled=true 如何把默认的Client替换为okhttp在这里不做过多阐述，可以参考：spring cloud feign使用okhttp3 替换为httpclient 增加依赖 12345&lt;dependency&gt; &lt;groupId&gt;com.netflix.feign&lt;/groupId&gt; &lt;artifactId&gt;feign-httpclient&lt;/artifactId&gt; &lt;version&gt;8.18.0&lt;/version&gt; &lt;/dependency&gt; 2.在application.properties增加配置如下: 1feign.httpclient.enabled=true 可以参考更换Feign默认使用的HTTP Client 总结 由于新增的依赖没有被start管理，并且缺省不会导致程序启动异常，并且返回响应为null与此依赖没有直接关系，因此不方便定位到问题，特此记录下来，希望能帮助到遇到同样问题的人，如对文章有不同的看法，望给予指正。 本文建立在已经搭建完成Feign的调用基础之上，没有讲述Feign的使用，因为此类文章很多，在此就不重复了，更多的信息可以参考如下文章。 快速使用Spring Cloud Feign作为客户端调用服务提供者spring cloud feign使用okhttp3","link":"/sc/sc-feign-4xx/"},{"title":"Spring Cloud Gateway离开孵化器的变化","text":"摘要: Spring Cloud对Netflix的Zuul进行封装之后，Spring Cloud Zuul作为Spring Cloud的网关一直被大家使用用至今，在Spring Cloud的核心项目开发者Spencergibb的一篇博客The API Gateway is Dead! Long Live the API Gateway!中介绍了Zuul，Zuul 2以及为什么会有Spring Cloud Gateway,大家有兴趣可以看一下。本文将会对spring-cloud-gateway-mvc源码进行demo演示和简单分析。 一.Spring Cloud Gateway概况1.1 什么是Spring Cloud GateWayA Gateway built on Spring Framework 5.0 and Spring Boot 2.0 providing routing and more。 Spring Cloud Gateway是基于Spring 框架5.0版本和Spring Boot 2.0的版本构建，提供路由等功能。 1.2 Spring Cloud GateWay的功能Spring Cloud GateWay具有以下特征 Java 8/Spring 5/Boot 2 WebFlux/Reactor HTTP/2 and Websockets Finchley Release Train (Q4 2017) 由于Spring 5.0支持Netty，Http2，而Spring Boot 2.0支持Spring 5.0，因此Spring Cloud Gateway支持Netty和Http2顺理成章。至于2017年Q4季度是否发布完整的Spring Cloud Gateway我们拭目以待。 1.3 Spring Cloud GateWay离开孵化器从2016年12月份以后，在Github上出现了Spring Cloud Gateway的项目，地址为:https://github.com/spring-cloud-incubator/spring-cloud-gateway,如下图所示。 Spring Cloud GateWay离开孵化器之后master分支有MVC模块,需要查看完整的其它的模块请切换分支到2.X 。因此在本文不分析core里面的设计和实现,后面将会补一篇文章介绍。 2.Spring Cloud Gateway的设计核心代码主要在spring-cloud-gateway-core,但是由于目前离开孵化器之后spring-cloud-gateway-core的代码挪到了2.X中,点击访问会自动转发到https://github.com/spring-cloud/spring-cloud-gateway 如上图所示，目前master分支中gateway没有core和starter，相对而言增加了一个spring-cloud-gateway-mvc模块，在下面章节将会对该模块进行demo和源码分析。 1.3 用Spring MVC的方式构建Gateway1.3.1 How to Include Spring Cloud GatewayTo include Spring Cloud Gateway in your project add a dependency with group org.springframework.cloud and artifact id spring-cloud-gateway-mvc. See the Spring Cloud Project page for details on setting up your build system with the current Spring Cloud Release Train. 使用spring-cloud-gateway-mvc，只要引入对应的spring-cloud-gateway-mvc的依赖坐标。 1.3.2 Building a Gateway Using Spring MVCSpring Cloud Gateway provides a utility object called ProxyExchange which you can use inside a regular Spring MVC handler as a method parameter. It supports basic downstream HTTP exchanges via methods that mirror the HTTP verbs, or forwarding to a local handler via the forward() method. Example (proxying a request to “/test” downstream to a remote server): 12345678910111213 @RestController@SpringBootApplicationpublic class GatewaySampleApplication { @Value(\"${remote.home}\") private URI home; @GetMapping(\"/test\") public ResponseEntity&lt;?&gt; proxy(ProxyExchange&lt;Object&gt; proxy) throws Exception { return proxy.uri(home.toString() + \"/image/png\").get(); }} Spring Cloud Gateway 提供了一个实用的对象叫ProxyExchange，你可以用它像使用Spring MVC Handler的方式去转发，重定向构建网关。 更多信息参考:https://github.com/spring-cloud/spring-cloud-gateway/blob/master/docs/src/main/asciidoc/spring-cloud-gateway.adoc 二.Spring Cloud Gateway的MVC模块源码分析2.1 构建Spring Cloud Gateway的DemoSpring Cloud Gateway的工程里已经给我提供了一个，spring-cloud-gateway-sample的工程，该工程项目依赖于spring-cloud-gateway-mvc，因此要对其源码分析，只需让才sample 正常work就ok。 从工程截图来看，和我之前看的core模块来说，mvc模块只是做了个请求的转发。 2.2 Spring Cloud Gateway模块源码分析1.在spring-cloud-gateway-sample中application.yml增加应用名和端口配置 123456789101112 server: port: 8080spring: application: name: sc-gwmanagement: security: enabled: falseremote: home: http://httpbin.org #请求转发的目标服务Url 2.org.springframework.cloud.gateway.sample.GatewaySampleApplication.java 123456789101112131415161718192021222324252627282930 @RestController@SpringBootApplicationpublic class GatewaySampleApplication { @Value(\"${remote.home}\") private URI home; //该方法需要传递head为x-host=png.abc.org方可调用 @GetMapping(path=\"/test\", headers=\"x-host=png.abc.org\") public ResponseEntity&lt;Object&gt; proxy(ProxyExchange&lt;Object&gt; proxy) throws Exception { return proxy.uri(home.toString() + \"/image/png\") .get(header(\"X-TestHeader\", \"foobar\")); } @GetMapping(\"/test2\") public ResponseEntity&lt;Object&gt; proxyFoos(ProxyExchange&lt;Object&gt; proxy) throws Exception { return proxy.uri(home.toString() + \"/image/webp\").get(header(\"X-AnotherHeader\", \"baz\")); } private Function&lt;ResponseEntity&lt;Object&gt;, ResponseEntity&lt;Object&gt;&gt; header(String key, String value) { return response -&gt; ResponseEntity.status(response.getStatusCode()) .headers(response.getHeaders()).header(key, value) .body(response.getBody()); } public static void main(String[] args) { SpringApplication.run(GatewaySampleApplication.class, args); }} 2.3 代码分析 启动GatewaySampleApplication主应用程序，访问http://localhost:8080/test2,Debug流程如下。 1234@GetMapping(\"/test2\")public ResponseEntity&lt;Object&gt; proxyFoos(ProxyExchange&lt;Object&gt; proxy) throws Exception { return proxy.uri(home.toString() + \"/image/webp\").get(header(\"X-AnotherHeader\", \"baz\"));} 在ProxyExchange.java中的237行代码 12345678910public ProxyExchange&lt;T&gt; uri(String uri) { try { //将uri:http://httpbin.org/image/webp，new URI对象返回 this.uri = new URI(uri); } catch (URISyntaxException e) { throw new IllegalStateException(\"Cannot create URI\", e); } return this;} 在RestTemplate.java中的628行doExecute去使用对应的httpClient实现远程调用 123456@Overridepublic &lt;T&gt; T execute(URI url, HttpMethod method, RequestCallback requestCallback, ResponseExtractor&lt;T&gt; responseExtractor) throws RestClientException { return doExecute(url, method, requestCallback, responseExtractor);} 最终调用代码如下图所示,由于源码比较简单，因此有些细节流程略过，有兴趣可以自己跟踪理解。","link":"/sc/sc-gateway/"},{"title":"Spring Cloud Gateway入门案例","text":"摘要:本篇文章主要介绍了什么是Spring Cloud Gateway，并基于Spring Cloud Gateway的Finchley.M8版本编写一个Spring Cloud Gateway的入门案例，即基本代理的路由转发配置。 1.Spring Gateway概述1.1 什么是Spring Cloud Gateway Spring Cloud Gateway是Spring官方基于Spring 5.0，Spring Boot 2.0和Project Reactor等技术开发的网关，Spring Cloud Gateway旨在为微服务架构提供一种简单而有效的统一的API路由管理方式。Spring Cloud Gateway作为Spring Cloud生态系中的网关，目标是替代Netflix ZUUL，其不仅提供统一的路由方式，并且基于Filter链的方式提供了网关基本的功能，例如：安全，监控/埋点，和限流等。 2. Spring Cloud Gateway入门案例2.1 创建maven工程配置Spring Cloud Gateway的相关Maven依赖 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;ch18-1&lt;/artifactId&gt; &lt;groupId&gt;cn.springcloud.book&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;ch18-1-gateway&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;ch18-1-gateway&lt;/name&gt; &lt;url&gt;http://springcloud.cn&lt;/url&gt; &lt;properties&gt; &lt;spring-cloud.version&gt;Finchley.M8&lt;/spring-cloud.version&gt; &lt;/properties&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring-cloud.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-snapshots&lt;/id&gt; &lt;name&gt;Spring Snapshots&lt;/name&gt; &lt;url&gt;https://repo.spring.io/snapshot&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;spring-snapshots&lt;/id&gt; &lt;name&gt;Spring Snapshots&lt;/name&gt; &lt;url&gt;https://repo.spring.io/snapshot&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/pluginRepository&gt; &lt;pluginRepository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt;&lt;/project&gt; 2.2 Spring Cloud Gateway主程序SpringCloudGatewayApplication.java，代码如下所示: 12345678910111213141516171819202122232425package cn.springcloud.book.gateway;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.gateway.route.RouteLocator;import org.springframework.cloud.gateway.route.builder.RouteLocatorBuilder;import org.springframework.context.annotation.Bean;@SpringBootApplicationpublic class SpringCloudGatewayApplication { @Bean public RouteLocator customRouteLocator(RouteLocatorBuilder builder) { return builder.routes() //basic proxy .route(r -&gt; r.path(\"/baidu\") .uri(\"http://baidu.com:80/\") ).build(); } public static void main(String[] args) { SpringApplication.run(SpringCloudGatewayApplication.class, args); }} 2.3 编写application.yml文件123456789101112131415161718192021server: port: 8080spring: application: name: spring-cloud-gatewayspring: cloud: gateway: routes: - id: xujin_route uri: http://www.xujin.org:80/ predicates: - Path=/xujinlogging: level: org.springframework.cloud.gateway: TRACE org.springframework.http.server.reactive: DEBUG org.springframework.web.reactive: DEBUG reactor.ipc.netty: DEBUG 2.4 基本代理路由配置等同写法Spring Cloud Gateway提供了两种配置路由规则的方法 第一:通过@Bean自定义RouteLocator12345678@Beanpublic RouteLocator customRouteLocator(RouteLocatorBuilder builder) { return builder.routes() //basic proxy .route(r -&gt; r.path(\"/baidu\") .uri(\"http://baidu.com:80/\") ).build();} 第二:通过属于文件或者yml文件配置 12345678spring: cloud: gateway: routes: - id: xujin_route uri: http://www.xujin.org:80/ predicates: - Path=/xujin PS,以上两种方式等同。 2.5 错误的示范代码如下:12345678@Beanpublic RouteLocator routingConfig() { return Routes.locator() .route(\"xujin_route\") .uri(\"http://xujin.org\") .predicate(host(\"**.xujin.org\")) .build();} 温馨提示，上面这种写法是基于Spring Cloud Gateway FM4的版本，相关代码已废弃，目前Spring Cloud Gateway将会在FM9之后Realese。 2.6 运行测试 访问http://localhost:8080/baidu,路由转发到http://www.baidu.com 访问http://localhost:8080/xujin,路由转发到http://xujin.orgyml 12345678@Bean public RouteLocator customRouteLocator(RouteLocatorBuilder builder) { return builder.routes() //basic proxy .route(r -&gt; r.path(\"/baidu\") .uri(\"http://baidu.com:80/\") ).build(); } 12345678spring: cloud: gateway: routes: - id: xujin_route uri: http://www.xujin.org:80/ predicates: - Path=/xujin","link":"/sc/gw/gw-01/"},{"title":"Spring Cloud微服务框架主要子项目和RPC框架的对比","text":"摘要:Spring Cloud是一个相对比较新的微服务框架，今年(2016)推出1.0的release版本，目前Github上更新速度很快. 虽然Spring Cloud时间最短, 但是相比Dubbo等RPC框架, Spring Cloud提供的全套的分布式系统解决方案。spring cloud 为开发者提供了在分布式系统（配置管理，服务发现，熔断，路由，微代理，控制总线，一次性token，全局琐，leader选举，分布式session，集群状态）中快速构建的工具，使用Spring Cloud的开发者可以快速的启动服务或构建应用．它们将在任何分布式环境中工作，包括开发人员自己的笔记本电脑，裸物理机的数据中心，和像Cloud Foundry云管理平台。在未来引领这微服务架构的发展，提供业界标准的一套微服务架构解决方案。 什么是Spring Cloud？ Spring Cloud是一个相对比较新的微服务框架，今年(2016)才推出1.0的release版本. 虽然Spring Cloud时间最短, 但是相比Dubbo等RPC框架, Spring Cloud提供的全套的分布式系统解决方案。spring cloud 为开发者提供了在分布式系统（配置管理，服务发现，熔断，路由，微代理，控制总线，一次性token，全居琐，leader选举，分布式session，集群状态）中快速构建的工具，使用Spring Cloud的开发者可以快速的启动服务或构建应用．它们将在任何分布式环境中工作，包括开发人员自己的笔记本电脑，裸物理机的数据中心，和像Cloud Foundry云管理平台。下面是官方对Spring Cloud定义和解释。 Spring Cloud provides tools for developers to quickly build some of the common patterns in distributed systems (e.g. configuration management, service discovery, circuit breakers, intelligent routing, micro-proxy, control bus, one-time tokens, global locks, leadership election, distributed sessions, cluster state). Coordination of distributed systems leads to boiler plate patterns, and using Spring Cloud developers can quickly stand up services and applications that implement those patterns. They will work well in any distributed environment, including the developer’s own laptop, bare metal data centres, and managed platforms such as Cloud Foundry. Spring Cloud主要项目 Spring Cloud 侧重于提供良好的开箱即用的功能，以便支持典型的开发场景和扩展支持。下面主要Spring Cloud项目在微服务框架中的主要子项目，具体的子项目源码分析，以及实现细节，将会在后面的文章中介绍。 Spring Cloud Config—配置中心 Spring Cloud Config就是我们通常意义上的配置中心 - 把应用原本放在本地文件的配置抽取出来放在中心服务器，从而能够提供更好的管理、发布。 在RPC服务治理框架中，一般都会开发一个配置中心和ZK配合使用，用于管理分布式应用中的配置信息。比如熔断的阀值，负载均衡的策略等。 Spring Cloud Netflix–注册中心，服务发现，LB Spring Cloud Netflix通过Eureka Server实现服务注册中心(包括服务注册，服务发现)，通过Ribbon实现软负载均衡(load balance,简称LB) 在RPC框架中，例如：dubboX，HSF，OSP(唯品会的RPC框架)等RPC框架，都会通过ZK等实现服务注册，服务发现。当服务启动时，会将服务的IP地址，端口，服务命名，版本号等信息注册到ZK中，同时ZK Node会监听变化，接收最新的服务注册信息到client端或Proxy端。至于LB，都会有自己的实现算法，熔断等都有自己的实现方式。 Hystrix 熔断，包含在服务治理中。 Spring Cloud Sleuth Spring Cloud Sleuth为Spring Cloud提供了分布式追踪方案。全链路监控系统。 APM（Application Performance Monitor）这个领域最近异常火热。国外该领域知名公司包括New Relic，Appdynamics，Splunk。其中New Relic已经成功IPO，估值超过20亿美元。 １．国内外的个大互联网公司也都有类似大名鼎鼎的APM产品，例如淘宝鹰眼Eagle Eyes，点评的CAT，微博的Watchman，twitter的Zipkin。他们的产品虽未像专业APM公司的产品这样功能强大，但结合各自公司的业务特点，这些产品在支撑业务系统的高性能和稳定性方面，发挥了显著的作用。 ２．众所周知，中大型互联网公司的后台业务系统由众多分布式组件构成，这些组件由web类型组件，RPC服务化类型组件，缓存组件，消息组件和数据库组件。一个通过浏览器或移动客户端的前端请求到达后台系统后，会经过很多个业务组件和系统组件，并且留下足迹和相关日志信息。但这些分散在每个业务组件和主机下的日志信息不利于问题排查和定位问题的Root Cause。这种监控场景正是应用性能监控系统的用武之地，应用性能监控系统收集，汇总并分析日志信息达到有效监控系统性能和问题的效果． ３．在唯品会体系中，Mercury提供的主要功能包括： 定位慢调用：包括慢Web服务（包括Restful Web服务），慢OSP服务，慢SQL 定位错误：包括4XX，5XX，OSP Error 定位异常：包括Error Exception，Fatal Exception 展现依赖和拓扑：域拓扑，服务拓扑，trace拓扑 Trace调用链：将端到端的调用，以及附加在这次调用的上下文信息，异常日志信息，每一个调用点的耗时都呈现给用户 应用告警：根据运维设定的告警规则，扫描指标数据，如违反告警规则，则将告警信息上报到唯品会中央告警平台 dubbo与Spring Cloud的比较 1.dubbo出自于阿里，Spring cloud出自于Spring社区,基于Spring boot提供一套完整的微服务解决方案。dubbo或者dubbox是RPC框 架，功能是Spring Cloud功能的一个子集。 2.dubbo是RPC服务治理框架，和Spring Cloud一样具备服务注册、发现、路由、负载均衡等能力。但是没有配置中心，完整的好用全链路监 控，需要采用开源的解决方案定制或者自研。Spring cloud的配置中心，全链路监控等组件。从目前来看，Spring Cloud国内中小型企业用的比较多，大型企业可能需要对其需要的组件进行定制化处理。 3.Spring cloud基于注解的服务发现，服务治理等功能具有代码侵入性，dubbo没有代码侵入性，业务开发人员不需要通过注解的方式去关注框架级别的处理。从中间件或者做基础架构的角度来看，其实服务治理等功能对普通的业务程序员应该是透明的，业务程序员不需要关注服务治理框架的使用，专注于业务代码即可。 因此大型企业可能需要对Spring cloud进行定制化处理。更多比较信息，可以参考下面的连接。","link":"/sc/sc-introduce/"},{"title":"Spring Cloud Gateway的Before路由断言工厂","text":"摘要:在上本篇文章Spring Cloud Gateway的After路由断言工厂介绍了Spring Cloud Gateway核心概念和After路由断言，本文简单介绍Before路由断言工厂。因为比较简单所以就抛砖引玉，旨在帮助大家快速入门Spring Cloud Gateway，欢迎大家加我微信Software_King，进入Spring Cloud中国社区微信群交流。 1. Spring Cloud Gateway核心概念 网关简单的说就是提供一个对外统一的API入口和出口，统管企业对外的所有API出口。一般来说，网关对外暴露的URL或者接口信息，我们统称之为路由信息。如果研发过网关中间件，或者使用或了解过ZUUL的，网关的核心肯定是Filter以及Filter Chain(Filter责任链)。Spring Cloud Gateway也具有路由信息和Filter。下面介绍一下Spring Cloud gateway中最重要的几个概念: 路由(route):路由是网关最基础的部分，路由信息由一个ID、一个目的url、一组断言工厂和一组Filter组成。如果路由断言工厂为真，则说明请求的Url和配置的路由匹配。 断言(Predicate): java 8中的断言函数。Spring Cloud Gateway中的断言函数输入类型是Spring 5.0框架中的ServerWebExchange。Spring Cloud Gateway中的断言函数允许开发者去定义匹配来自于http request中的任何信息，比如请求头和参数等。 过滤器(filter):一个标准的Spring webFilter。Spring Cloud Gateway中的Filter分为两种类型的Filter，分别是Gateway Filter和Global Filter.网关 Filter实例是由Spring 框架中的网关Filter的特殊工厂构造。request在转发到目前服务之前，response在返回到调用端之前都可以被修改或者自定义。 2. 什么是Before路由断言 Before路由断言工厂带有一个UTC时间格式的时间参数，当请求进来的当前时间在路由断言工厂之前会成功匹配，否则不能成功匹配。 3. Before路由断言工厂的案例3.1 引入pom依赖pom.xml依赖配置如下所示: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990&lt;properties&gt; &lt;spring-cloud.version&gt;Finchley.M9&lt;/spring-cloud.version&gt; &lt;/properties&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring-cloud.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-webflux&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-snapshots&lt;/id&gt; &lt;name&gt;Spring Snapshots&lt;/name&gt; &lt;url&gt;https://repo.spring.io/snapshot&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;spring-snapshots&lt;/id&gt; &lt;name&gt;Spring Snapshots&lt;/name&gt; &lt;url&gt;https://repo.spring.io/snapshot&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/pluginRepository&gt; &lt;pluginRepository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt; 3.2 application.yml文件配置:1234567891011121314151617181920server: port: 8082spring: cloud: gateway: routes: - id: before_route uri: http://xujin.org predicates: - Before=2022-03-13T00:54:30.877+08:00[Asia/Shanghai]logging: level: org.springframework.cloud.gateway: TRACE org.springframework.http.server.reactive: DEBUG org.springframework.web.reactive: DEBUG reactor.ipc.netty: DEBUGmanagement.endpoints.web.exposure.include: '*' Spring Cloud Gateway提供两种方式去配置Before路由断言工厂，这里介绍的是yml文件的配置方式。 3.3 等价的@Bean配置12345678910111213@Beanpublic RouteLocator customRouteLocator(RouteLocatorBuilder builder) { ZonedDateTime datetime = LocalDateTime.now().plusDays(1).atZone(ZoneId.systemDefault()); //@formatter:off return builder.routes() .route(\"before_route\", r -&gt; r.before(datetime) .uri(\"http://xujin.org\")) .build(); //@formatter:on } Spring Cloud Gateway提供两种方式去配置After路由断言工厂，这里介绍的是@Bean的配置方式。不管通过yml文件配置或者通过@Bean的方式配置是等价的。 3.4 测试如下:访问http://localhost:8082/ 成功转发到http://xujin.org。","link":"/sc/gw/gw04/"},{"title":"Spring Cloud Gateway中的权重路由","text":"摘要:本文主要通过运用Spring Cloud Gateway的WeightRoutePredicateFactory对URL进行权重路由。 1.权重路由1.1 权重路由使用场景在开发或者测试的时候，或者线上发布，线上服务多版本控制的时候，需要对服务提供权重路由，最常见的使用就是，一个服务有两个版本，旧版本V1，新版本v2。在线上灰度的时候，需要通过网关动态实时推送，路由权重信息。比如95%的流量走服务v1版本，5%的流量走服务v2版本。 issue: The Spring Cloud Gateway issue of Allow Rolling Deployments https://github.com/spring-cloud/spring-cloud-gateway/issues/67 1.2 Spring Cloud Gateway权重路由原理Spring Cloud Gateway中提供了org.springframework.cloud.gateway.handler.predicate.WeightRoutePredicateFactory去实现根据分组设置权重进行路由，因此使用起来相对比较简单，有兴趣的可以debug阅读源码。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public class WeightRoutePredicateFactory extends AbstractRoutePredicateFactory&lt;WeightConfig&gt; implements ApplicationEventPublisherAware { private static final Log log = LogFactory.getLog(WeightRoutePredicateFactory.class); public static final String GROUP_KEY = WeightConfig.CONFIG_PREFIX + \".group\"; public static final String WEIGHT_KEY = WeightConfig.CONFIG_PREFIX + \".weight\"; private ApplicationEventPublisher publisher; public WeightRoutePredicateFactory() { super(WeightConfig.class); } @Override public void setApplicationEventPublisher(ApplicationEventPublisher publisher) { this.publisher = publisher; } @Override public List&lt;String&gt; shortcutFieldOrder() { return Arrays.asList(GROUP_KEY, WEIGHT_KEY); } @Override public String shortcutFieldPrefix() { return WeightConfig.CONFIG_PREFIX; } @Override public void beforeApply(WeightConfig config) { if (publisher != null) { publisher.publishEvent(new WeightDefinedEvent(this, config)); } } @Override public Predicate&lt;ServerWebExchange&gt; apply(WeightConfig config) { return exchange -&gt; { Map&lt;String, String&gt; weights = exchange.getAttributeOrDefault(WEIGHT_ATTR, Collections.emptyMap()); String routeId = exchange.getAttribute(GATEWAY_PREDICATE_ROUTE_ATTR); // all calculations and comparison against random num happened in // WeightCalculatorWebFilter String group = config.getGroup(); if (weights.containsKey(group)) { String chosenRoute = weights.get(group); if (log.isTraceEnabled()) { log.trace(\"in group weight: \"+ group + \", current route: \" + routeId +\", chosen route: \" + chosenRoute); } return routeId.equals(chosenRoute); } return false; }; }} 2.Spring Cloud Gateway中的权重路由案例2.1 案例代码地址https://github.com/SoftwareKing/sc-gateway/tree/master/ch4 2.2 Spring Cloud Gateway Server说明Spring Cloud Gateway will dispatch 95% of the requests to version 1 and 5% of the traffic to version 2 of a specified service, as shown by the following figure. 我们通过在Spring Cloud Gateway中会配置不同的权重信息到不同URL上，Spring Cloud Gateway会根据我们配置的路由权重信息，将请求分发到不同的源服务组，权重信息如ch4/ch4-gateway中的application.yml所示，主要配置信息如下。 123456789101112131415161718spring: application: name: ch4-gateway cloud: gateway: routes: - id: service1_v1 uri: http://localhost:8081/v1 predicates: - Path=/test - Weight=service1, 95 - id: service1_v2 uri: http://localhost:8081/v2 predicates: - Path=/test - Weight=service1, 5 Weight=service1, 95，Weight=service1, 5就是路由的权重信息。 2.3 源服务源服务在本案例中源服务如ch4-service-provider所示，主要提提供Gateway Server权重路由对应的后端源服务。因为比较简单因此不做详细说明，主要代码如下所示。 1234567891011121314151617181920package org.xujin.sc.service;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;import reactor.core.publisher.Mono;@RestControllerpublic class ServiceController { @RequestMapping(value = \"/v1\", produces = \"text/plain;charset=UTF-8\") public Mono&lt;String&gt; v1() { return Mono.just(\"v1\"); } @RequestMapping(value = \"/v2\", produces = \"text/plain;charset=UTF-8\") public Mono&lt;String&gt; v2() { return Mono.just(\"v2\"); }} 2.4 测试分别启动ch4-gateway，ch4-service-provider进行访问:http://localhost:8080/test 测试,发现会根据所设权重进行路由。","link":"/sc/gw/gw08/"},{"title":"Spring Cloud Gateway只有Pre和POST两种类型的Filter","text":"摘要:Spring Cloud Gateway只有两种类型的Filter，本文介绍如何在Spring Cloud Gateway中创建一个Pre或Post类型的Filter。 zuul的Filter类型Zuul 的 Filter 是通过filterType()方法来指定，一个 Filter 只能对应一种类型，要么是 “pre” 要么是“post” Spring Cloud Gateway的Filter类型Spring Cloud Gateway 基于 Project Reactor 和 WebFlux，采用响应式编程风格，打开它的 Filter 的接口GatewayFilter你会发现它只有一个方法filter Pre类型的Filter在Spring Cloud Gateway源码中定义了一个Pre类型的Filter，code将会在chain.filter() 之前被执行,代码:AddRequestHeader 12345678910111213141516171819202122package org.springframework.cloud.gateway.filter.factory;import org.springframework.cloud.gateway.filter.GatewayFilter;import org.springframework.http.server.reactive.ServerHttpRequest;/** * @author Spencer Gibb */public class AddRequestHeaderGatewayFilterFactory extends AbstractNameValueGatewayFilterFactory { @Override public GatewayFilter apply(NameValueConfig config) { return (exchange, chain) -&gt; { ServerHttpRequest request = exchange.getRequest().mutate() .header(config.getName(), config.getValue()) .build(); return chain.filter(exchange.mutate().request(request).build()); }; }} Post类型的Filter对于Post类型的Filter，SetStatus代码将会在chain.filter(exchange).then()里面的代码运行。 12345678910111213141516public class SetStatusGatewayFilterFactory extends AbstractGatewayFilterFactory&lt;SetStatusGatewayFilterFactory.Config&gt; { @Override public GatewayFilter apply(Config config) { final HttpStatus status = ServerWebExchangeUtils.parse(config.status); return (exchange, chain) -&gt; { return chain.filter(exchange).then(Mono.fromRunnable(() -&gt; { // check not really needed, since it is guarded in setStatusCode, // but it's a good example if (!exchange.getResponse().isCommitted()) { setResponseStatus(exchange, status); } })); }; }}","link":"/sc/gw/gw06/"},{"title":"Spring Cloud Gateway揭秘之处理请求流程","text":"摘要:本篇文章主要从源码的角度揭秘Spring Cloud Gateway的怎么处理请求流程。 1.Spring Gateway概述 Spring Cloud Gateway是Spring官方基于Spring 5.0，Spring Boot 2.0和Project Reactor等技术开发的网关，Spring Cloud Gateway旨在为微服务架构提供一种简单而有效的统一的API路由管理方式。Spring Cloud Gateway作为Spring Cloud生态系中的网关，目标是替代Netflix ZUUL，其不仅提供统一的路由方式，并且基于Filter链的方式提供了网关基本的功能，例如：安全，监控/埋点，和限流等。 2. Spring Cloud gateway请求入口分析 不管是Zuul，还是Spring Cloud Gateway还是基于Netty的自研网关，都会把请求进来的Request，或者返回的Response进行包装，转换提取为网关运行的上下文信息，而在Spring Cloud gateway中网关的上下文为ServerWebExchange。 2.1 入口HttpServerRequest和HttpServerResponse转换Spring Cloud Gateway的请求入口，org.springframework.http.server.reactive.ReactorHttpHandlerAdapter#apply方法 123456789101112131415161718192021222324@Override public Mono&lt;Void&gt; apply(HttpServerRequest request, HttpServerResponse response) { NettyDataBufferFactory bufferFactory = new NettyDataBufferFactory(response.alloc()); ServerHttpRequest adaptedRequest; ServerHttpResponse adaptedResponse; try { adaptedRequest = new ReactorServerHttpRequest(request, bufferFactory); adaptedResponse = new ReactorServerHttpResponse(response, bufferFactory); } catch (URISyntaxException ex) { logger.error(\"Invalid URL \" + ex.getMessage(), ex); response.status(HttpResponseStatus.BAD_REQUEST); return Mono.empty(); } if (adaptedRequest.getMethod() == HttpMethod.HEAD) { adaptedResponse = new HttpHeadResponseDecorator(adaptedResponse); } return this.httpHandler.handle(adaptedRequest, adaptedResponse) .doOnError(ex -&gt; logger.error(\"Handling completed with error\", ex)) .doOnSuccess(aVoid -&gt; logger.debug(\"Handling completed with success\")); } PS，代码来源于spring-web-5.0.4.RELEASE.jar此方法为Spring Cloud Gateway的请求入口方法，该方法的作用就是把接收到的HttpServerRequest或者最终需要返回的HttpServerResponse，包装转换为ReactorServerHttpRequest和ReactorServerHttpResponse。 2.2 构造Spring Cloud gateway的上下文ServerWebExchange在org.springframework.web.server.adapter.HttpWebHandlerAdapter的182行，代码如下所示: 1234567@Override public Mono&lt;Void&gt; handle(ServerHttpRequest request, ServerHttpResponse response) { ServerWebExchange exchange = createExchange(request, response); return getDelegate().handle(exchange) .onErrorResume(ex -&gt; handleFailure(request, response, ex)) .then(Mono.defer(response::setComplete)); } createExchange()将ServerHttpRequest ServerHttpResponse构建网关上下文ServerWebExchange。 PS:其中org.springframework.web.server.handler.WebHandlerDecorator.getDelegate()通过委托的方式获取一系列需要处理的WebHandler. 2.3 进入Filter链org.springframework.cloud.gateway.handler.FilteringWebHandler#handle方法，即77行，代码如下所示 12345678910111213@Overridepublic Mono&lt;Void&gt; handle(ServerWebExchange exchange) { Route route = exchange.getRequiredAttribute(GATEWAY_ROUTE_ATTR); List&lt;GatewayFilter&gt; gatewayFilters = route.getFilters(); List&lt;GatewayFilter&gt; combined = new ArrayList&lt;&gt;(this.globalFilters); combined.addAll(gatewayFilters); //TODO: needed or cached? AnnotationAwareOrderComparator.sort(combined); logger.debug(\"Sorted gatewayFilterFactories: \"+ combined); return new DefaultGatewayFilterChain(combined).filter(exchange);} 2.4 执行Filter链1234567891011121314151617181920private static class DefaultGatewayFilterChain implements GatewayFilterChain { private int index; private final List&lt;GatewayFilter&gt; filters; public DefaultGatewayFilterChain(List&lt;GatewayFilter&gt; filters) { this.filters = filters; } @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange) { if (this.index &lt; filters.size()) { GatewayFilter filter = filters.get(this.index++); return filter.filter(exchange, this); } else { return Mono.empty(); // complete } } } 2.5 Gateway Filter委托为Gloable Filter执行123456789101112131415161718192021private static class GatewayFilterAdapter implements GatewayFilter { private final GlobalFilter delegate; public GatewayFilterAdapter(GlobalFilter delegate) { this.delegate = delegate; } @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) { return this.delegate.filter(exchange, chain); } @Override public String toString() { final StringBuilder sb = new StringBuilder(\"GatewayFilterAdapter{\"); sb.append(\"delegate=\").append(delegate); sb.append('}'); return sb.toString(); } } 2.6 预告待续在之后的文章中，将会揭秘Spring Cloud Gateway的架构设计，Filter链设计，以及启动装在流程等。","link":"/sc/gw/gw02/"},{"title":"Spring Cloud Gateway的After路由断言工厂","text":"摘要:本篇文章主要介绍了Spring Cloud Gateway核心概念和After路由断言，因为比较简单所以就抛砖引玉，旨在帮助大家快速入门Spring Cloud Gateway，欢迎大家加我微信Software_King，进入Spring Cloud中国社区微信群交流。 1.Spring Cloud Gateway核心概念 网关简单的说就是提供一个对外统一的API入口和出口，统管企业对外的所有API出口。一般来说，网关对外暴露的URL或者接口信息，我们统称之为路由信息。如果研发过网关中间件，或者使用或了解过ZUUL的，网关的核心肯定是Filter以及Filter Chain(Filter责任链)。Spring Cloud Gateway也具有路由信息和Filter。下面介绍一下Spring Cloud gateway中最重要的几个概念: 路由(route):路由是网关最基础的部分，路由信息由一个ID、一个目的url、一组断言工厂和一组Filter组成。如果路由断言工厂为真，则说明请求的Url和配置的路由匹配。 断言(Predicate): java 8中的断言函数。Spring Cloud Gateway中的断言函数输入类型是Spring 5.0框架中的ServerWebExchange。Spring Cloud Gateway中的断言函数允许开发者去定义匹配来自于http request中的任何信息，比如请求头和参数等。 过滤器(filter):一个标准的Spring webFilter。Spring Cloud Gateway中的Filter分为两种类型的Filter，分别是Gateway Filter和Global Filter.网关 Filter实例是由Spring 框架中的网关Filter的特殊工厂构造。request在转发到目前服务之前，response在返回到调用端之前都可以被修改或者自定义。 2.什么是After路由断言 After Route Predicate Factory带有一个UTC时间格式的时间参数，当请求进来的当前时间在路由断言工厂之后会成功匹配，否则不能成功匹配。 3.After路由断言工厂的案例3.1 引入pom依赖pom.xml依赖配置如下所示: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990&lt;properties&gt; &lt;spring-cloud.version&gt;Finchley.M9&lt;/spring-cloud.version&gt; &lt;/properties&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring-cloud.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-webflux&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-snapshots&lt;/id&gt; &lt;name&gt;Spring Snapshots&lt;/name&gt; &lt;url&gt;https://repo.spring.io/snapshot&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;spring-snapshots&lt;/id&gt; &lt;name&gt;Spring Snapshots&lt;/name&gt; &lt;url&gt;https://repo.spring.io/snapshot&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/pluginRepository&gt; &lt;pluginRepository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt; 3.2 application.yml文件配置:123456789101112131415161718192021server: port: 8081spring: cloud: gateway: routes: - id: after_route uri: http://xujin.org predicates: - After=2018-03-18T17:32:58.129+08:00[Asia/Shanghai]logging: level: org.springframework.cloud.gateway: TRACE org.springframework.http.server.reactive: DEBUG org.springframework.web.reactive: DEBUG reactor.ipc.netty: DEBUGmanagement.endpoints.web.exposure.include: '*' Spring Cloud Gateway提供两种方式去配置After路由断言工厂，这里介绍的是yml文件的配置方式。 3.3 等价的@Bean配置123456789@Beanpublic RouteLocator customRouteLocator(RouteLocatorBuilder builder) { ZonedDateTime minusTime = LocalDateTime.now().minusDays(1).atZone(ZoneId.systemDefault()); return builder.routes() .route(\"after_route\", r -&gt; r.after(minusTime) .uri(\"http://xujin.org\")) .build(); } Spring Cloud Gateway提供两种方式去配置After路由断言工厂，这里介绍的是@Bean的配置方式。不管通过yml文件配置或者通过@Bean的方式配置是等价的。 3.4 测试如下:访问http://localhost:8081/成功转发到http://xujin.org","link":"/sc/gw/gw03/"},{"title":"Spring Cloud Eureka服务下线(Cancel)源码分析","text":"摘要:在本篇文章中主要对Eureka的Cancel(服务下线)进行源码分析，在Service Provider服务shut down的时候，需要及时通知Eureka Server把自己剔除，从而避免其它客户端调用已经下线的服务，导致服务不可用。 Cancel(服务下线)概述在Service Provider服务shut down的时候，需要及时通知Eureka Server把自己剔除，从而避免客户端调用已经下线的服务。 服务提供者端源码分析 在eureka-client-1.4.1中的com.netflix.discovery.DiscoveryClient中shutdown()的867行。 123456789101112131415161718192021222324252627282930313233/** * Shuts down Eureka Client. Also sends a deregistration request to the * eureka server. */ @PreDestroy @Override public synchronized void shutdown() { if (isShutdown.compareAndSet(false, true)) { logger.info(\"Shutting down DiscoveryClient ...\"); if (statusChangeListener != null &amp;&amp; applicationInfoManager != null) { applicationInfoManager.unregisterStatusChangeListener(statusChangeListener.getId()); } cancelScheduledTasks(); // If APPINFO was registered if (applicationInfoManager != null &amp;&amp; clientConfig.shouldRegisterWithEureka()) { applicationInfoManager.setInstanceStatus(InstanceStatus.DOWN); //调用下线接口 unregister(); } if (eurekaTransport != null) { eurekaTransport.shutdown(); } heartbeatStalenessMonitor.shutdown(); registryStalenessMonitor.shutdown(); logger.info(\"Completed shut down of DiscoveryClient\"); } } Tips @PreDestroy注解或shutdown()的方法是服务下线的入口 在eureka-client-1.4.1中的com.netflix.discovery.DiscoveryClient中unregister（）的897行12345678910111213141516 /** * unregister w/ the eureka service. */ void unregister() { // It can be null if shouldRegisterWithEureka == false if(eurekaTransport != null &amp;&amp; eurekaTransport.registrationClient != null) { try { logger.info(\"Unregistering ...\"); //发送服务下线请求 EurekaHttpResponse&lt;Void&gt; httpResponse = eurekaTransport.registrationClient.cancel(instanceInfo.getAppName(), instanceInfo.getId()); logger.info(PREFIX + appPathIdentifier + \" - deregister status: \" + httpResponse.getStatusCode()); } catch (Exception e) { logger.error(PREFIX + appPathIdentifier + \" - de-registration failed\" + e.getMessage(), e); } }} Eureka Server服务下线实现细节 在com.netflix.eureka.resources.InstanceResource中的280行中的cancelLease()方法 123456789101112131415@DELETEpublic Response cancelLease( @HeaderParam(PeerEurekaNode.HEADER_REPLICATION) String isReplication) { //调用cancel boolean isSuccess = registry.cancel(app.getName(), id, \"true\".equals(isReplication)); if (isSuccess) { logger.debug(\"Found (Cancel): \" + app.getName() + \" - \" + id); return Response.ok().build(); } else { logger.info(\"Not Found (Cancel): \" + app.getName() + \" - \" + id); return Response.status(Status.NOT_FOUND).build(); }} 在org.springframework.cloud.netflix.eureka.server.InstanceRegistry中的95行的cancel()方法， 123456@Overridepublic boolean cancel(String appName, String serverId, boolean isReplication) { handleCancelation(appName, serverId, isReplication); //调用父类中的cancel return super.cancel(appName, serverId, isReplication);} 在com.netflix.eureka.registry.PeerAwareInstanceRegistryImpl中的376行 123456789101112131415161718 @Override public boolean cancel(final String appName, final String id, final boolean isReplication) { if (super.cancel(appName, id, isReplication)) { //服务下线成功后，同步更新信息到其它Eureka Server节点 replicateToPeers(Action.Cancel, appName, id, null, null, isReplication); synchronized (lock) { if (this.expectedNumberOfRenewsPerMin &gt; 0) { // Since the client wants to cancel it, reduce the threshold (1 for 30 seconds, 2 for a minute) this.expectedNumberOfRenewsPerMin = this.expectedNumberOfRenewsPerMin - 2; this.numberOfRenewsPerMinThreshold = (int) (this.expectedNumberOfRenewsPerMin * serverConfig.getRenewalPercentThreshold()); } } return true; } return false;} 4.在com.netflix.eureka.registry.PeerAwareInstanceRegistryImpl中的618行，主要接口实现方式和register基本一致：首先更新自身Eureka Server中服务的状态，再同步到其它Eureka Server中。12345678910111213141516171819202122232425private void replicateToPeers(Action action, String appName, String id, InstanceInfo info /* optional */, InstanceStatus newStatus /* optional */, boolean isReplication) { Stopwatch tracer = action.getTimer().start(); try { if (isReplication) { numberOfReplicationsLastMin.increment(); } // If it is a replication already, do not replicate again as this will create a poison replication if (peerEurekaNodes == Collections.EMPTY_LIST || isReplication) { return; } // 同步把服务信息同步到其它的Eureka Server中 for (final PeerEurekaNode node : peerEurekaNodes.getPeerEurekaNodes()) { // If the url represents this host, do not replicate to yourself. if (peerEurekaNodes.isThisMyUrl(node.getServiceUrl())) { continue; } //根据action做相应操作的同步 replicateInstanceActionsToPeers(action, appName, id, info, newStatus, node); } } finally { tracer.stop(); } } 至此，Eureka服务续约源码分析结束，大家有兴趣可自行阅读。 源码分析链接 其它源码分析链接: Spring Cloud中@EnableEurekaClient源码分析: http://xujin.org/sc/sc-enableEurekaClient-annonation/ Spring Cloud Eureka服务注册源码分析： http://xujin.org/sc/sc-eureka-register/ Spring Cloud Eureka服务续约(Renew)源码分析 http://xujin.org/sc/sc-eureka-renew/","link":"/sc/sc-eureka-cancle/"},{"title":"Spring Cloud Zuul异常处理","text":"最近看到了一个GitHub issue在讨论如何在post类型的zuul filter中设置response body，其中涉及到异常情况下，如何返回一个自定义的response body。正好我在升级spring-cloud，也想弄清楚，spring-cloud-zuul是如何处理异常情况的，所以就仔细看了看这部分的实现细节，现在做个笔记记录下来。 1.zull请求的生命周期图关于zuul是如何工作的，这里不再介绍，具体可以参看这里。官方给了一个zull请求的生命周期图： 上图中，实线表示请求必然经过的路径，而虚线表示可能经过的路径；从这张图中可以看出： 所有请求都必然按照pre-&gt; route -&gt; post的顺序执行。 post返回response。 如果pre中有自定义filter，则执行自定义filter。 如果pre,route,post发生错误则执行error，然后再执行post。 这张图忽略了很多细节；最明显的就是，自定义的filter可以是pre,route,post,error中的任何一种；其次假如post中发生了异常，执行流程交给error处理完之后，又重新回到post中，会不会又有问题？ 所以还是看看代码比较靠谱。以下基于spring-cloud Dalston.RELEASE做代码分析。 调试一下，就可以看到请求进入zuul之后的整个调用链，简单来说如下：ZuulServlet#service -&gt; FilterProcessor#processZuulFilter -&gt; ZuulFilter#runFilter -&gt; [Concret]ZuulFilter#run。 2.源码分析ZuulServlet#service首先找到请求进入zuul filters的入口：ZuulServlet#service(ServletRequest, ServletResponse)。 下面抽出这个函数的主干： 12345678910111213141516171819202122232425try { try { preRoute(); } catch (ZuulException e) { error(e); postRoute(); return; } try { route(); } catch (ZuulException e) { error(e); postRoute(); return; } try { postRoute(); } catch (ZuulException e) { error(e); return; } } catch (Throwable e) { error(new ZuulException(e, 500, \"UNHANDLED_EXCEPTION_\" + e.getClass().getName())); } 这个函数基本遵从但不完全符合官网给出的生命周期图： 正常情况下，请求只经过pre -&gt; route -&gt; post。 两层try...catch，内层只捕获ZuulException，而其他异常由外层捕获。 内层3个try...catch语句，只有pre,route抛出ZuulException时，才会执行errror，再执行post。而当post(88行)抛出ZuulException后，只会执行error。 外层捕获其他异常(内层try语句块中抛出的非ZuulException异常以及内层catch语句中抛出的所有异常)后，将HTTP状态码设置为500，同时交给error处理。 整个流程的终点有两个：post及error；而非只有post一个。 另外看一下error(ZuulException)这个函数到底做了什么： 1234void error(ZuulException e) { RequestContext.getCurrentContext().setThrowable(e); zuulRunner.error();} 异常信息是在这里被加入到RequestContext中的，以供后续的filter使用，然后调用error filters。 至此我们可以得到一个流程图(感觉还不如代码看得清晰-_-!!)： FilterProcessor#processZuulFilterFilterPreocessor#processZuulFilter，这个函数调用ZuulFilter，并且会将异常重新抛出，如果是非ZuulException的异常，则转为状态码为500的ZuulException。 123456789101112131415161718192021222324try { Throwable t = null; ZuulFilterResult result = filter.runFilter(); ExecutionStatus s = result.getStatus(); switch (s) { case FAILED: t = result.getException(); break; } if (t != null) throw t; } catch (Throwable e) { if (e instanceof ZuulException) { throw (ZuulException) e; } else { ZuulException ex = new ZuulException(e, \"Filter threw Exception\", 500, filter.filterType() + \":\" + filterName); throw ex; } } 如果ZuulFilter执行失败，即结果状态为FAILED，则从ZuulFilter的执行结果ZuulFilterResult中提取出异常信息(199行)，然后抛出(214)；在catch语句块中，捕获刚才抛出的异常，判断是否为ZuulException，如果是则直接抛出，否则转化为状态为500的ZuulException再抛出。 看到这里，基本确认的一点是，ZuulFilter中抛出的任何形式的异常，最终都会转化为ZuulException抛给上层调用者，即ZuulServlet#service。但是这里并不是通过try...catch来捕获ZuulFilter执行中抛出的异常，而是从返回结果ZuulFilterResult中直接获取的，这是怎么一回事，需要再看下ZuulFilter#runFilter的实现逻辑。 ZuulFilter#runFilter下面是从ZuulFilter#runFilter()抽取出来的核心代码： 1234567891011ZuulFilterResult zr = new ZuulFilterResult(); try { Object res = run(); zr = new ZuulFilterResult(res, ExecutionStatus.SUCCESS); } catch (Throwable e) { zr = new ZuulFilterResult(ExecutionStatus.FAILED); zr.setException(e); } return zr; 这段代码会调用某个具体的ZuulFilter实现的run方法，如果不抛出异常，则返回状态为ExecutionStatus.SUCCESS的ZuulFilterResult(117行)；若有任何异常，则将返回结果的状态设置为ExecutionStatus.FAILED(120)，同时将异常信息设置到返回结果中(121)。即我们实现一个ZuulFilter，如果不抛出异常，则会被认为是成功的，否则就会被当作失败的。 结合上面两节的代码分析，ZuulFilter中一旦有异常抛出，必然是(或被转化为)ZuulException，然后必然进入到error filters中处理。由此，我们简化一下上面的流程图： 3.SpringCloud中的SendErrorFilter在Dalston.RELEASE之前，spring-cloud-netflix中并不包含error类型的Filter；而处理错误情况的filter为SendErrorFilter，其类型为post，order为0，比SendResponseFilter优先级高(1000)，即更早调用。先来分析一下Dalston.RELEASE之前版本的SendErrorFilter，下面的代码片段摘自spring-cloud-netflix 1.2.7.RELEASE： 1234567891011121314151617181920212223242526272829@Value(\"${error.path:/error}\") private String errorPath; @Override public boolean shouldFilter() { RequestContext ctx = RequestContext.getCurrentContext(); // only forward to errorPath if it hasn't been forwarded to already return ctx.containsKey(\"error.status_code\") &amp;&amp; !ctx.getBoolean(SEND_ERROR_FILTER_RAN, false); } @Override public Object run() { int statusCode = (Integer) ctx.get(\"error.status_code\"); request.setAttribute(\"javax.servlet.error.status_code\", statusCode); Object e = ctx.get(\"error.exception\"); request.setAttribute(\"javax.servlet.error.exception\", e); String message = (String) ctx.get(\"error.message\"); request.setAttribute(\"javax.servlet.error.message\", message); RequestDispatcher dispatcher = request.getRequestDispatcher( this.errorPath); dispatcher.forward(request, ctx.getResponse()); } 从上面的代码中可以得出以下几点： SendErrorFilter的进入条件是：RequestContext中包含error.status_code，且之前从未执行过该filter。(55, 56) 会将错误信息转发给errorPath执行；errorPath可由配置项error.paht指定，默认为/error。(38, 79, 84) 转发的错误信息是从RequestContext中的三个key得到：error.status_code, error.exception, error.message。(65~76) 如果要使用SendErrorFilter，则我们在自己实现自定义ZuulFilter做异常处理的时候，需要注意： 如果是pre, route类型的filter，则捕获所有内部异常，将异常信息设置到error.message中，设置所需返回的HTTP状态码到error.status_code中；然后抛出一个异常。抛出异常是为了将执行流程交给error-&gt;post这个执行分支；否则，当前filter会被认为执行成功，继续执行后续的filter。run()方法抛出的异常需是(或继承)RuntimeException，因为IZuulFilter#run()接口没有显示抛出异常。 如果是 post类型： 设置该filter的order，小于0(这是SendErrorFilter)。 仔细考虑shouldFilter()的实现细节，因为异常流也会进入post filters，确定是否需要处理。 run()方法中捕获所有异常，然后设置error.status_code, error.message, error.exception，并且不再抛出异常。否则会进入error filters，但是现在没有，由SendErrorFilter替代；除非自己实现一个error filter，然后禁掉SendErrorFilter。 这个版本中，spring-cloud-netflix提供的这个SendErrorFilter有明显的缺陷，无法处理由post filters抛出的异常，也不符合zuul请求的生命周期图。所以在Dalston.RELEASE之后，即spring-cloud-netflix 1.3.0.RELEASE，将SendErrorFilter的类型改为了error。 下面的代码片段摘自spring-cloud-netflix 1.3.0.RELEASE的SendErrorFilter类: 12345678910111213141516171819202122232425262728293031@Override public String filterType() { return ERROR_TYPE; } @Override public boolean shouldFilter() { RequestContext ctx = RequestContext.getCurrentContext(); // only forward to errorPath if it hasn't been forwarded to already return ctx.getThrowable() != null &amp;&amp; !ctx.getBoolean(SEND_ERROR_FILTER_RAN, false); } @Override public Object run() { ZuulException exception = findZuulException(ctx.getThrowable()); request.setAttribute(\"javax.servlet.error.status_code\", exception.nStatusCode); request.setAttribute(\"javax.servlet.error.exception\", exception); request.setAttribute(\"javax.servlet.error.message\", exception.errorCause); } ZuulException findZuulException(Throwable throwable) { if (throwable.getCause() instanceof ZuulRuntimeException) { // this was a failure initiated by one of the local filters return (ZuulException) throwable.getCause().getCause(); } } 需要注意几点： 类型为error(53行)。 进入条件为：RequestContext中有异常，并且该filter从未执行过(65, 66)。异常对象是在ZuulServlet#error(ZuulException)方法中设置的。 run()方法中提取错误信息不再是从RequestContext的三个key(error.status_code, error.message, error.exception)中获取；而是直接从ZuulException对象中获取(73~82)。 如何取得ZuulException对象(100118)，最重要的一点是从ZuulRuntimeException中提取ZuulException对象(101103)，而ZuulRuntimeException继承RuntimeException。 注意101行代码，是判断throwable.getCause()是否为ZuulRuntimeException，这是因为所有非ZuulException的异常在FilterProcessor#processZuulFilter()(227行)中会被转化为ZuulException。 findZuulException没有贴全，其会优先从自定义filter中抛出的ZuulRuntimeException中提取ZuulException对象。这样就允许我们返回我们想要的错误信息和HTTP状态码。 那基于1.3.0.RELEASE，我们在写自定义filter时，如何做异常处理呢： 将filter内部异常转化为ZuulException，设置自己需要返回的HTTP状态码，然后包装为ZuulRuntimeException抛出。 如若不封装为ZuulRuntimeException，则返回的HTTP状态码为500。 举个例子： 12345678public Object run() { try { // do something } catch (Throwable t) { throw new ZuulRuntimeException(new ZuulException(t, HttpStatus.BAD_REQUEST.value(), t.getMessage())); } return null;} 如果想自定义返回的异常信息的response body的格式，最简单的方法是仿照BasicErrorController重写一下/error接口。","link":"/sc/sc-zuul-excpetion/"},{"title":"Spring Cloud Zuul遗失的世界(一)","text":"摘要: Zuul作为java网关届的鼻祖，2016年自研网关中间件的时候，对其源码看了很多次，经过两大互联网公司中间件的洗礼之后，目前轮到自己设计一个网关中间件纳管Spring Cloud。最近抽空把自己的理解，备注一下。由于Spring cloud整合Zuul的代码过多。本文主要介绍Spring Cloud对Netflix Zuul高度抽象封装整合部分。即spring-cloud-netflix-core的代码。 一.Spring Cloud Zuul源码分析1.1 @EnableZuulProxy与@EnableZuulServer如下主应用程序代码所示，我们使用Spring Cloud Zuul只需要加上@EnableZuulProxy或@EnableZuulServer两种注解就可以。 12345678@SpringBootApplication@EnableZuulProxypublic class SpringCloudZuulApplication { public static void main(String[] args) { SpringApplication.run(SpringCloudZuulApplication.class, args); }} @EnableZuulProxy与@EnableZuulServer,@EnableZuulServer - 普通Zuul Server,只支持基本的route与filter功能.@EnableZuulProxy - 普通Zuul Server+服务发现与熔断等功能的增强版,具有反向代理功能. 1.2 @EnableZuulProxy注解入口 点开注解@EnableZuulProxy，进入到org.springframework.cloud.netflix.zuul.EnableZuulProxy，如下所示。 1234567@EnableCircuitBreaker@EnableDiscoveryClient@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Import(ZuulProxyConfiguration.class)public @interface EnableZuulProxy {} 1.3 ZuulProxyConfiguration代码@Import(ZuulProxyConfiguration.class)，查看导入的类org.springframework.cloud.netflix.zuul.ZuulProxyConfiguration，如下所示，可以看到org.springframework.cloud.netflix.zuul.ZuulProxyConfiguration,继承了上文的ZuulConfiguration,新增了服务与实例等概念，核心重要代码已经加入注释 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273@Configuration@Import({ RibbonCommandFactoryConfiguration.RestClientRibbonConfiguration.class, RibbonCommandFactoryConfiguration.OkHttpRibbonConfiguration.class, RibbonCommandFactoryConfiguration.HttpClientRibbonConfiguration.class })public class ZuulProxyConfiguration extends ZuulConfiguration { @SuppressWarnings(\"rawtypes\") @Autowired(required = false) private List&lt;RibbonRequestCustomizer&gt; requestCustomizers = Collections.emptyList(); // DiscoveryClient肩负着从Eureka中获取服务列表,获取对应实例的功能 @Autowired private DiscoveryClient discovery; @Autowired private ServiceRouteMapper serviceRouteMapper; // zuulFeature 依然是将Zuul标识为Discovery模式. @Override public HasFeatures zuulFeature() { return HasFeatures.namedFeature(\"Zuul (Discovery)\", ZuulProxyConfiguration.class); } @Bean @ConditionalOnMissingBean(DiscoveryClientRouteLocator.class) public DiscoveryClientRouteLocator discoveryRouteLocator() { return new DiscoveryClientRouteLocator(this.server.getServletPrefix(), this.discovery, this.zuulProperties, this.serviceRouteMapper); } // 依然是注册了这么个ApplicationEvent来触发上文中的dirty状态. @Bean public ApplicationListener&lt;ApplicationEvent&gt; zuulDiscoveryRefreshRoutesListener() { return new ZuulDiscoveryRefreshListener(); } private static class ZuulDiscoveryRefreshListener implements ApplicationListener&lt;ApplicationEvent&gt; { private HeartbeatMonitor monitor = new HeartbeatMonitor(); @Autowired private ZuulHandlerMapping zuulHandlerMapping; @Override public void onApplicationEvent(ApplicationEvent event) { if (event instanceof InstanceRegisteredEvent) { reset(); } else if (event instanceof ParentHeartbeatEvent) { ParentHeartbeatEvent e = (ParentHeartbeatEvent) event; resetIfNeeded(e.getValue()); } else if (event instanceof HeartbeatEvent) { HeartbeatEvent e = (HeartbeatEvent) event; resetIfNeeded(e.getValue()); } } private void resetIfNeeded(Object value) { if (this.monitor.update(value)) { reset(); } } private void reset() { this.zuulHandlerMapping.setDirty(true); } } //其余省略} DiscoveryClientRouteLocator类中的locateRoutes()方法，将path与上文的ZuulRoute通过DiscoveryClientRouteLocator.locateRoutes()的对应在一起.点击查看其父类，org.springframework.cloud.netflix.zuul.ZuulConfiguration,如下我们可以看到Netflix的Zuul-core的入口，ZuulServlet。 1.4 DiscoveryClientRouteLocator中locateRoutesDiscoveryClientRouteLocator类中的locateRoutes的大概流程 将上文SimpleRouteLocator中解析出来的Route列表灌入内部的LinkedHashMap 抽取Route自带的serviceId,将其作为key,形成一个staticServices的map 遍历DiscoveryClient拿到的serviceId列表,匹配正则形式定义的serviceId并将对应的ZuulRoute与之对应 调整LinkedHashMap内路由顺序,将/**挪到最后 微调map内容,将key值加上/或者自定义prefix 1.5 ZuulConfiguration1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071@Configuration@EnableConfigurationProperties({ ZuulProperties.class })@ConditionalOnClass(ZuulServlet.class)// Make sure to get the ServerProperties from the same place as a normal web app would@Import(ServerPropertiesAutoConfiguration.class)public class ZuulConfiguration { //zuulProperties 对应配置文件的内容 @Autowired protected ZuulProperties zuulProperties; @Autowired protected ServerProperties server; @Autowired(required = false) private ErrorController errorController; //告知actuator监控当前模式:Simple/Discovery @Override public HasFeatures zuulFeature() { return HasFeatures.namedFeature(\"Zuul (Discovery)\", ZuulProxyConfiguration.class); } //通过继承ServletWrappingController接管了上文定义的ZuulServlet,因此ZuulController就是Zuul的入口 @Bean public ZuulController zuulController() { return new ZuulController(); } /** *ZuulHandlerMapping,响应器模式,其实目前就是把所有路径的请求导入到ZuulController上.&lt;/br&gt; *另外的功效是当觉察RouteLocator路由表变更,则更新自己dirty状态,重新注册所有Route到ZuulController. */ @Bean public ZuulHandlerMapping zuulHandlerMapping(RouteLocator routes) { ZuulHandlerMapping mapping = new ZuulHandlerMapping(routes, zuulController()); mapping.setErrorController(this.errorController); return mapping; } /** * ZuulRefreshListener, */ private static class ZuulRefreshListener implements ApplicationListener&lt;ApplicationEvent&gt; { @Autowired private ZuulHandlerMapping zuulHandlerMapping; private HeartbeatMonitor heartbeatMonitor = new HeartbeatMonitor(); @Override public void onApplicationEvent(ApplicationEvent event) { // Simple模式下注册RoutesRefreshedEvent,解析配置文件, // 维护路由表并监听变化,将请求都导向ZuulController去历经filters if (event instanceof ContextRefreshedEvent || event instanceof RefreshScopeRefreshedEvent || event instanceof RoutesRefreshedEvent) { this.zuulHandlerMapping.setDirty(true); } // Endpoint模式下又添加了HeartbeatEvent else if (event instanceof HeartbeatEvent) { if (this.heartbeatMonitor.update(((HeartbeatEvent) event).getValue())) { this.zuulHandlerMapping.setDirty(true); } } } } //其余省略} 从ZuulConfiguration中可以拿到Simple模式下所有bean. 1.6 ZuulController整合访问的桥梁 ZuulController继承了ServletWrappingController，将当前应用中的某个Servlet直接包装为一个Controller，所有到ServletWrappingController的请求实际上是由它内部所包装的这个Servlet 实例来处理的，也就是说内部封装的Servlet实例并不对外开放，对于程序的其他范围是不可见的，适配所有的HTTP请求到内部封装的Servlet实例进行处理。它通常用于对已存的Servlet的逻辑重用上。其实这也就是Spring Cloud与Netflix Zuul整合的关键点。 12345678910111213141516171819202122public class ZuulController extends ServletWrappingController { public ZuulController() { setServletClass(ZuulServlet.class); setServletName(\"zuul\"); setSupportedMethods((String[]) null); // Allow all } @Override public ModelAndView handleRequest(HttpServletRequest request, HttpServletResponse response) throws Exception { try { // We don't care about the other features of the base class, just want to // handle the request return super.handleRequestInternal(request, response); } finally { // @see com.netflix.zuul.context.ContextLifecycleFilter.doFilter RequestContext.getCurrentContext().unset(); } }} 1.7 ZuulProperties123456zuul.ignoredServiceszuul.routeszuul: ignored-services: routes: 其中routes对应着内部类定义ZuulRoute. 1.8 其它补充说明org.springframework.cloud.netflix.zuul.filters.Route,是Spring Cloud 的抽象,就是上文RouteLocator潜移默化转换的部分. org.springframework.cloud.netflix.zuul.ZuulFilterInitializer,实现ServletContextListener,servlet内容来自tomcat。","link":"/sc/sc-zuul-s1/"},{"title":"基于Spring Cloud的几个自研微服务组件","text":"摘要:本文由宜信-技术研发中心-高级架构师-梁鑫投稿分享。投稿请加微信Software_King,之前分享了一下我在公司项目中搭建Spring Cloud框架的经验，在此基础之上，为了更好的满足业务功能需求和便捷运维的需要，我们开发了几个基于springcloud的微服务组件，在此做个总结跟大家共同探讨一下。 基于SpringCloud的几个自研微服务组件一.应用管理中心采用微服务架构以后，把原先单一的节点拆解成了多个微服务节点。公司虽然有一键发布平台，但是是针对每一个节点采取单独的发布，启动，停止操作，没有全局化统一管理功能。上线运维的工作量就变的非常庞大，因此我们开发了基于springcloud的应用管理中心来方便我们的工作。 1.1 实现机制 每个微服务启动时，将自身的进程ID，当前路径，JDK路径，jar名称，系统用户，IP地址，端口号注册到zookeeper; 应用管理中心从zookeeper中查询到所有的微服务进程信息； 获取信息后构造启动命令，停止命令； 在数据库保存系统的用户名和密码； 在部署时指定git地址，分支，IP等调用jenkins，编译生成最新jar包拷贝到目标服务器指定位置； 通过远程jsch远程执行shell命令对微服务进程进行操作。 1.2 功能原理 1.3 效果图 二.微服务健康检测中心基于actuator我们可以很好的针对每个微服务节点进行监控，当出现问题时及时报警。 2.1 实现机制 保证所有的微服务节点都加载了actuator; 从eureka中获取所有的微服务注册信息； 定时任务轮询请求每个微服务的health信息； Health返回status树壮结构信息； 如果status状态为down发送报警并包含health完整信息。 2.2 功能原理 2.3 效果图我们在健康检测中心中同时加载了spring boot admin,可以随时查看微服务节点的所有运行信息。 2.4 部分源码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950@Scheduled(initialDelay = 10000L, fixedRate = 60000L)public void scheduledTaskHandler() { long begin = System.currentTimeMillis(); List&lt;String&gt; items = getIPAndPorts(); for (String IPAndPort : items) { LOGGER.info(\"prepare checking \" + IPAndPort); if (IPAndPort.isEmpty()) { LOGGER.warn(\"checking \" + IPAndPort + \" is empty\"); continue; } try { String[] item = IPAndPort.split(\":\"); String info = healthService.getHealthInfo(item[0], item[1]); String prettyjson = getPrettyJSON(info); ObjectMapper mapper = new ObjectMapper(); @SuppressWarnings(\"rawtypes\") Map&lt;?, ?&gt; infoMap = mapper.readValue(info, new TypeReference&lt;Map&gt;() { }); if (infoMap.containsKey(STATUS)) { String status = infoMap.get(STATUS).toString(); if (status.equals(UP)) { LOGGER.info(\"checking \" + IPAndPort + \" is UP:\\n\" + prettyjson); continue; } } emailService.sendLimitedEmail(prettyjson, IPAndPort, IPAndPort, 10 * 60 * 1000L); LOGGER.info(\"checking \" + IPAndPort + \" is DOWN:\\n\" + prettyjson); } catch (feign.RetryableException ex) { String content = exception2String(ex); emailService.sendEmail(content, \"程序运行异常\"); LOGGER.info(\"checking \" + IPAndPort + \" is DOWN\"); LOGGER.error(\"\", ex); } catch (FeignException fex) { String body = getBodyFromFeignException(fex); String prettybody = getPrettyJSON(body); emailService.sendLimitedEmail(prettybody, IPAndPort, IPAndPort, 10 * 60 * 1000L); LOGGER.info(\"checking \" + IPAndPort + \" is DOWN:\\n\" + prettybody); LOGGER.error(\"\", fex); } catch (Exception ex) { String content = exception2String(ex); emailService.sendEmail(content, \"程序运行异常\"); LOGGER.info(\"checking \" + IPAndPort + \" is DOWN\"); LOGGER.error(\"\", ex); } } LOGGER.info(\"SkytrainHealthChecking cost: \" + (System.currentTimeMillis() - begin) + \" Millis\");} 三.定时任务管理中心我们需要建立定时任务全局视图，并希望对每一个定时任务具备启停的能力。我们采用了通过继承统一的AbstractScheduledTask，暴露定时任务的启动，停止接口。让每一个定时任务自动具备的启停功能。 3.1 实现机制 通过BeanPostProcessor在bean初始完成后拦截所有的@Scheduled注解，获取ip，port，applicationName，className，beanName，scheduled等信息注册到zookeeper； 定时任务实现继承AbstractScheduledTaskInter接口，暴露startScheduledTask和stopScheduledTask，可以针对定时任务进行启动停止； 实现基准TaskScheduledController类，通过beanName获取定时任务类，调用该类的启动停止方法； 定时任务管理中心查询zookeeper展示全局注册的定时任务，提供启动停止操作对定时任务进行控制； 定时任务分为全局唯一定时任务和非唯一定时任务。 3.2 功能原理 3.3 效果图 3.4 部分源码 获取定时任务 12345678910111213141516171819202122232425262728public Object postProcessAfter(Object bean, String beanName) { Class&lt;?&gt; targetClass = AopUtils.getTargetClass(bean); Map&lt;Method, Set&lt;Scheduled&gt;&gt; annotatedMethods = MethodIntrospector.selectMethods(targetClass, new MethodIntrospector.MetadataLookup&lt;Set&lt;Scheduled&gt;&gt;() { public Set&lt;Scheduled&gt; inspect(Method method) { Set&lt;Scheduled&gt; scheduledMethods = AnnotatedElementUtils.getMergedRepeatableAnnotations(method, Scheduled.class, Schedules.class); return (!scheduledMethods.isEmpty() ? scheduledMethods : null); } }); if (!annotatedMethods.isEmpty()) { String className = targetClass.getName(); className = SpringBeanUtil.getNormalClassName(className); for (Map.Entry&lt;Method, Set&lt;Scheduled&gt;&gt; entry : annotatedMethods.entrySet()) { Method method = entry.getKey(); for (Scheduled scheduled : entry.getValue()) { String key = className + \":\" + method.getName(); Map&lt;String, String&gt; scheduledMap = new HashMap&lt;String, String&gt;(); scheduledMap.put(\"className\", className); scheduledMap.put(\"methodName\", method.getName()); scheduledMap.put(\"beanName\", beanName); scheduledMap.put(\"scheduled\", scheduled.toString()); taskInfos.put(key, scheduledMap); } } } return null;} AbstractScheduledTask 123456789101112131415161718192021222324252627282930313233343536373839public abstract class AbstractScheduledTask implements AbstractScheduledTaskInter { ... public boolean scheduledTaskStatus = true; public Object startScheduledTask() { scheduledTaskStatus = true; updateRegisterTaskStatus(scheduledTaskStatus); return String.valueOf(scheduledTaskStatus); } public Object stopScheduledTask() { scheduledTaskStatus = false; updateRegisterTaskStatus(scheduledTaskStatus); return String.valueOf(scheduledTaskStatus); } public void updateRegisterTaskStatus(boolean status) { try { String className = this.getClass().getName(); className=SpringBeanUtil.getNormalClassName(className); ... } catch (JSONException e) { LOGGER.error(e.getMessage(), e); } } public boolean isRegister = false; public boolean isRegister() { if (isRegister) { return true; } ... } public void scheduledTaskController() { if (isRegister()) { if (scheduledTaskStatus) { scheduledTaskHandler(); } } } public abstract void scheduledTaskHandler();} 具备启停能力 123456789101112131415@Controllerpublic class TaskScheduledController { @RequestMapping(value = \"/start_scheduled_task\", produces = \"application/json;charset=UTF-8\") @ResponseBody public Object start(@RequestParam() String beanName) { AbstractScheduledTaskInter scheduledTask = SpringBeanUtil.getBean(beanName); return scheduledTask.startScheduledTask(); } @RequestMapping(value = \"/stop_scheduled_task\", produces = \"application/json;charset=UTF-8\") @ResponseBody public Object stop(@RequestParam() String beanName) { AbstractScheduledTaskInter scheduledTask = SpringBeanUtil.getBean(beanName); return scheduledTask.stopScheduledTask(); }} 四.全局热备锁无论定时任务还是普通跑批任务，我们需要对这些任务实现热备，以便在单点故障时任务依然可以顺利的执行。 4.1 实现机制 全局热备锁包括普通任务（例如监听rabbitmq消息）和定时任务； 任务以applicationName和className标识唯一，任务启动时把相关信息注册到zookeeper； 其他节点的任务启动时发现已经有任务运行，则监听zookeeper； 运行任务停止后，其它节点根据监听状态启动自身任务； 定时任务和普通任务不同，定时任务需要注册非运行节点，并对子节点数目变化和子节点数据变化都做监听。 4.2 功能原理 4.3 效果图 4.4 部分源码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253@Componentpublic abstract class AbstractGlobalLockTask implements CommandLineRunner { ... public void register(final String... strings) { String className = getClass().getName(); className = SpringBeanUtil.getNormalClassName(className); final String alarmConfigPath = SKYTRAIN_GlOBAL_LOCK_TASK_PREFIX + applicationName + \":\" + className; boolean exists = zooKeeperExecutor.isExists(alarmConfigPath); if (!exists) { JSONObject info = new JSONObject(); try { info.put(\"applicationName\", applicationName); info.put(\"className\", className); info.put(\"ip\", ipAddress); info.put(\"port\", serverPort); info.put(\"date\", new Date()); } catch (JSONException e) { LOGGER.error(e.getMessage(), e); } createGlobalLockNode(alarmConfigPath, info.toString(), strings); } else { try { zooKeeperExecutor.getZooKeeper().exists(alarmConfigPath, new Watcher() { public void process(WatchedEvent watchedEvent) { LOGGER.info(\"事件类型\" + watchedEvent.getType() + \"，路径\" + watchedEvent.getPath()); try { register(strings); } catch (Exception e) { LOGGER.error(\"\", e); } } }); } catch (KeeperException e) { LOGGER.error(e.getMessage(), e); } catch (InterruptedException e) { LOGGER.error(e.getMessage(), e); } } } public void createGlobalLockNode(String path, String value, String... strings) { zooKeeperExecutor.createZKNode(path, value); handler(strings); } public void run(String... strings) throws Exception { register(strings); } public abstract void handler(String... strings);} 作者：宜信-技术研发中心-高级架构师-梁鑫","link":"/sc/sq/sc-zyzj/"},{"title":"Spring Cloud中基于Sleuth的参数透传功能探索","text":"摘要:本文由郭芳碧投稿分享。投稿请加微信Software_King,本篇文章主要介绍Spring Cloud中基于Sleuth的参数透传功能探索的经历和相关解决方案。 一.需求微服务环境，有A，B，C，D四个服务，调用关系为：A-&gt;B-&gt;C-&gt;D。用户在A的页面选择当前“语言”环境为“英文”,在某些业务场景下，其它几个服务需获取到这个“语言”信息。 二.分析这个需求还是很简单的，类似于“击鼓传花”：当前服务从上一个服务中获取参数，并传给下一个服务。个人感觉基本上所有的RPC框架都会遇到这个问题，只是以前SOA架构下，服务层级比较少，将“语言”、“登陆”等附加信息放在参数列表中并不会带来太多工作量，所以这个问题并不是太突出。而引入了微服务架构思想后，服务调用层级急剧增长，这就需要一个更加优雅的方式来解决附加信息的传递问题。 三.方案探索3.1 方案一：参数放在接口参数列表中优点：思路简单，开发没有学习成本 缺点： 代码高度耦合：附加信息却要每个接口都显式维护 升级困难：如果将来再加一个参数，所有层级的接都要改动 引起迷惑：如果B服务的逻辑不需要“语言“参数，但是因为D需要，它也必须维护 太傻了，Big不够 思考：微服务之间绝大多数情况是通过HTTP调用的，HTTP的header中也可以放参数信息。这样，接口参数中就不用维护这些附加信了。 3.2 方案二：参数放在httpRequest的header中实现： 1.自定义一个Filter，获取Request中自己需要的附加信息， 2.将这些信息放入ThreadLocal中, 3.实现feign.Client(这里先忽略RestTemplate)的execute()方法，将附件信息在调用下一层服务前塞入request的header中 优点：参数解耦 缺点：如果B在获取到附加信息后，新起了一个线程”T1“来调用服务C，这时T1就无法从HhreaLocal拿到附加信息了 思考： 如果我知道怎么用无侵入的方式，在当前线程”T”创建子孙线程”T1”、”T1-1”时，将数据传给后代，就能解决这个问题了 微服务调用链框架Sleuth的核心功能即是跟踪一次请求从A到D的全过程，它肯定支持多线程调用下的traceId的传递。因此，我可以复用Sleuth的相关功能夹带私货 3.3 方案三：修改Sleuth源码，将附加信息跟着TraceId一起往后传递优点： 原理简单，不用考虑底层实现 不用考虑兼容性等问题，Sleuth都已经实现好 快(对，就是这一个字)缺点： 维护困难，很容易忘记以前修改了哪些地方，更别提移交给别人维护了 升级困难，以后每次Spring或者Sleuth升级，都要重新下载源码修改 思考： 目前获取参数的问题解决了，用Filter，只剩下保存并传给下一层的问题 既然Sleuth已经解决了多线程下traceId的传递问题，那我就直接用traceId来解决我的问题 3.4 方案四：充分利用traceId实现： 自定义Filter(优先级要低于TraceFilter,因为你要获取TraceFilter里的traceId)，拿到traceId和附加信息后，将它们存在本地缓存中，traceId为key，附加信息为value 参考方案二的实现3。重写execute()方法，获取当前线程的traceId(这个Sleuth有接口，不再介绍)，然后再通过traceId去本地缓存中拿到附加信息，放进Request的header中 优点：拥有上述方案所有的优点,解决上述方案所有缺点 缺点：看着很完美，但是你忽略了一件事：Sleuth要想传递自己的traceId，想必它已经重写了execute()方法(肯定的，那就是TraceFeignClient)，你要想用，那就要想办法在复用TraceFeignClient.execute()的同时，将自己的私货带进去 3.5 方案五：重写TraceFeignClient实现：有时候，改动源码并不需要直接在原有包里修改。比如：A-&gt;B-&gt;C-&gt;D，如果你要修改C的源码，那就将AB源码也copy出，作为A1,B1,C#，然后重写组件的入口，将组件加载顺序变为：A1-&gt;B1-&gt;C#-&gt;D，即可达到重写源码的目的。这时候注意的是，加载A1的条件必须跟加载A的相反。具体可参考我之前重写Consul的入口例子，示例代码如下 123456@ConditionalOnExpression(\"${spring.cloud.consul.ribbon.enabled:true}==false\")public class MyRibbonConsulAutoConfiguration {}// 原有入口：@ConditionalOnProperty(value = \"spring.cloud.consul.ribbon.enabled\", matchIfMissing = true)public class RibbonConsulAutoConfiguration {} 综上，可以重写TraceFeigClient的入口 TraceFeignClientAutoConfiguration-&gt;TraceFeignObjectWrapper&gt;TraceFeignClient,即可达到自己的目的. 优点：感觉事儿基本就成了 缺点：配置为false生效，使用者会觉得比较怪,Sleuth仿佛知道别人会这么干似的，它的类的访问权限基本都是default，为了copy过来的几个类能正常编译通过，你还要再copy九个它们的依赖类,程序太丑 思考:突然想起来，还有一种改代码的方式叫字节码替换，如果我能在程序启动的时，将我的execute()直接替换掉Sleuth的execute(),就一劳永逸了 3.6 方案六：字节码替换代源码修改优点：高大上,不在源码级替换，却在字节码级替换，虚虚实实 缺点：没这么干过，总觉得说着容易做着难 思考：基本上觉得方案五已经能解决问题了。本着精益求精的态度，去技术群里问了下，很快有大神发来Demo,看过代码后顿觉惭愧：我一直在想怎么重写TraceFeignClient的execute()，其实这个execute()真正做http请求时，调用的是feign.Client的另外一个实现类,注意那句”this.delegate.execute”，只要想办法用自己的Client替换掉delegate即可 123456789101112131415161718192021222324252627282930private static final Log log = LogFactory.getLog(MethodHandles.lookup().lookupClass());private final Client delegate; @Overridepublic Response execute(Request request, Request.Options options) throws IOException { String spanName = getSpanName(request); Span span = getTracer().createSpan(spanName); if (log.isDebugEnabled()) { log.debug(\"Created new Feign span \" + span); } try { AtomicReference&lt;Request&gt; feignRequest = new AtomicReference&lt;&gt;(request); spanInjector().inject(span, new FeignRequestTextMap(feignRequest)); span.logEvent(Span.CLIENT_SEND); addRequestTags(request); Request modifiedRequest = feignRequest.get(); if (log.isDebugEnabled()) { log.debug(\"The modified request equals \" + modifiedRequest); } Response response = this.delegate.execute(modifiedRequest, options); logCr(); return response; } catch (RuntimeException | IOException e) { logCr(); logError(e); throw e; } finally { closeSpan(span); }} 3.7 方案七：替换掉TraceFeigClient的delegate即可 实现:通过再次认真Debug源码知道，TraceFeignClient默认会加载你的Client实现类作为delegate(汗！)，因此你只要直接实现feign.Client接口即可。我偷懒了一把，自己写个实现类，直接复用了LoadBalancerFeignClient.execute() 优点:基本什么都有了吧 缺点:如果你以为只是简单地重写个execute()就行，那就大错特了。因为TraceFeignClient直接用了你的方法post过去，因此你要想办法把ribbon手动集成进来。如果不觉得麻烦的话，可以好好看下TraceFeignClient怎么生成Client的实例：TraceFeignObjectWrapper.wrap(Object bean) 思考:既然你可以在程序里获取到trace和span，那为何不将你的信息放到span里呢。如果span中能放点额外信息就好了，就不用自己写这么多东西。经大神提醒，Sleuth中有个baggage可以试试 3.8 方案八：使用baggage 实现:获取参数的方式不变，取得的参数放在baggage中 优点:简单,支持RestTemplate调用的情况,跟其他组件兼容性好 缺点:Sleuth的缺点 四.项目源码4.1 基于slueth的参数透传插件Github地址:https://github.com/bishion/sleuth-plugin 简介:微服务下使用,调用过程中用户信息，页面语言信息的透传使用方式 1234bizi: sleuth: config: headers: lang_info #如果由多个，逗号隔开.这里配置从filter里需要获取的headerName 调用方式 first_line:22 123456789101112@Servicepublic class SessionInfoService { @Resource private SessionInfoOperator sessionInfoOperator; public String getLangInfo(){ return sessionInfoOperator.getSessionInfo(\"lang_info\"); } public void setUserId(){ sessionInfoOperator.setSessionInfo(\"user_id\",\"bishion\"); }} 五.留下的坑 Sleuth通过LazyTraceExecutor解决多线程下的问题，但是它并没有解决给手动创建的Thread传递信息的问题 有机会试试java字节码替换怎么操作 Sleuth如何重写RestTemplate的 TraceFeignClient怎么生成Client的实例 六.后记因为附加信息的传递在RPC中扮演了很重要的角色，我潜意识里觉得，肯定会有更加简洁的方法或者框架我还没有了解到。希望各位各位读者老师能不吝珠玉，批评指正","link":"/sc/sq/sc-gfb/"},{"title":"Spring Boot杂谈总结(一)","text":"摘要 本篇文章主要介绍在Spring Boot中使用Fastjson代替Jackson，以及实现自己的自定义异常和扩展Spring MVC全局异常解析器，以及为了给前端测试提供接口文档Spring Boot集成swagger，以及集成swagger遇到问题的处理。 一.Spring Boot中使用Fastjson代替Jackson1.1 为什么使用Fastjson代替Jackson Jackson最主要的原因是Jackson在处理对象之前的循环嵌套关系时不便。什么是对象间的循环嵌套？比如A有一个List，B对象里又有一个A对象，当然返回A对象的Json字符串时，如果是Jackson就会发生异常，因为Jackson天生不具备处理这种关系的能力，而Fastjson正好具备了这种能力。 如果你用的是 Jackson，可以使用相应的注解来支持对象间的循环嵌套。可以百度Jackson循环嵌套。 1.2 使用Fastjson代替Jackson过程1.引入依赖 12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.29&lt;/version&gt;&lt;/dependency&gt; 三种实现方式 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152package org.xujin.janus.admin.exception;import java.util.ArrayList;import java.util.List;import org.springframework.context.annotation.Configuration;import org.springframework.http.MediaType;import org.springframework.http.converter.HttpMessageConverter;import org.springframework.web.servlet.HandlerExceptionResolver;import org.springframework.web.servlet.config.annotation.EnableWebMvc;import org.springframework.web.servlet.config.annotation.WebMvcConfigurerAdapter;import com.alibaba.fastjson.serializer.SerializerFeature;import com.alibaba.fastjson.support.config.FastJsonConfig;import com.alibaba.fastjson.support.spring.FastJsonHttpMessageConverter;/** * Spring MVC全局一场解析器 * @author xujin * */@Configuration@EnableWebMvcpublic class ApplicationExceptionAdapter extends WebMvcConfigurerAdapter { /** * 配置fastJson 用于替代jackson */ @Override public void configureMessageConverters(List&lt;HttpMessageConverter&lt;?&gt;&gt; converters) { super.configureMessageConverters(converters); // 1.定义一个convert 转换消息的对象 FastJsonHttpMessageConverter fastConverter = new FastJsonHttpMessageConverter(); // 2 添加fastjson 的配置信息 比如 是否要格式化 返回的json数据 FastJsonConfig fastJsonConfig = new FastJsonConfig(); fastJsonConfig.setSerializerFeatures(SerializerFeature.PrettyFormat); fastConverter.setFastJsonConfig(fastJsonConfig); // 解决乱码的问题 List&lt;MediaType&gt; fastMediaTypes = new ArrayList&lt;&gt;(); fastMediaTypes.add(MediaType.APPLICATION_JSON_UTF8); fastConverter.setSupportedMediaTypes(fastMediaTypes); converters.add(fastConverter); } /** 用自己的全局异常解析器替换Spring MVC本身的异常解析器 **/ @Override public void configureHandlerExceptionResolvers( List&lt;HandlerExceptionResolver&gt; exceptionResolvers) { exceptionResolvers.add(new ApplicationExceptionResolver()); super.configureHandlerExceptionResolvers(exceptionResolvers); }} 或者 1234567891011121314151617181920212223242526@EnableWebMvcpublic class JanusAdminApplication extends WebMvcConfigurerAdapter { /** * 配置fastJson 用于替代jackson */ @Override public void configureMessageConverters(List&lt;HttpMessageConverter&lt;?&gt;&gt; converters) { super.configureMessageConverters(converters); // 1.定义一个convert 转换消息的对象 FastJsonHttpMessageConverter fastConverter = new FastJsonHttpMessageConverter(); // 2 添加fastjson 的配置信息 比如 是否要格式化 返回的json数据 FastJsonConfig fastJsonConfig = new FastJsonConfig(); fastJsonConfig.setSerializerFeatures(SerializerFeature.PrettyFormat); fastConverter.setFastJsonConfig(fastJsonConfig); // 解决乱码的问题 List&lt;MediaType&gt; fastMediaTypes = new ArrayList&lt;&gt;(); fastMediaTypes.add(MediaType.APPLICATION_JSON_UTF8); fastConverter.setSupportedMediaTypes(fastMediaTypes); converters.add(fastConverter); } public static void main(String[] args) { SpringApplication.run(JanusAdminApplication.class, args); }} 二.Spring Boot自定义Spring MVC异常解析器123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109package org.xujin.janus.admin.exception;import java.io.IOException;import java.util.Arrays;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import org.apache.log4j.Logger;import org.apache.shiro.authz.UnauthenticatedException;import org.springframework.web.servlet.HandlerExceptionResolver;import org.springframework.web.servlet.ModelAndView;import org.xujin.janus.admin.base.ResultData;import org.xujin.janus.admin.constant.Config;import org.xujin.janus.admin.utils.FastjsonFilterUtil;import org.xujin.janus.admin.utils.ResourcesUtil;import com.alibaba.fastjson.JSON;import com.alibaba.fastjson.serializer.SerializerFeature;/** * @author xujin * @Description: 全局异常处理器 */public class ApplicationExceptionResolver implements HandlerExceptionResolver { /** * Log类 */ private Logger logger = Logger.getLogger(getClass()); @Override public ModelAndView resolveException(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) { logger.info(\"异常拦截器执行开始。\"); // 输出 异常信息 String msgContent = ResourcesUtil.getValue(Config.MESSAGE, ex.getMessage()); logger.error(\"发生异常:\" + msgContent, ex); // 将异常信息转json输出 this.writeJsonByFilter(response, this.resolveExceptionCustom(ex), null, null); logger.info(\"异常拦截器执行结束。\"); return new ModelAndView(); } /** * 异常信息解析方法 * * @param ex */ private ResultData resolveExceptionCustom(Exception ex) { ResultData model = new ResultData(); if (ex instanceof ApplicationException) { // 抛出的是系统自定义异常 model.setMsgCode(this.getMsgCode(ex)); } else if (ex instanceof UnauthenticatedException) { // 没有权限的异常 model.setMsgCode(\"ECOMMON00002\"); } else { // 未知错误 model.setMsgCode(\"ECOMMON00001\"); } return model; } private String getMsgCode(Exception ex) { // 输出 异常信息 String msgCode = ex.getMessage(); // 若返回的异常不直接是自定义异常，而是经过封装的异常 if (msgCode.charAt(0) != 'E' &amp;&amp; msgCode.charAt(0) != 'W' &amp;&amp; msgCode.charAt(0) != 'I') { msgCode = ex.getCause().getMessage(); } return msgCode; } /** * 将对象转换成JSON字符串，并响应回前台 */ protected void writeJsonByFilter(HttpServletResponse response, Object object, String[] includesProperties, String[] excludesProperties) { try { // excludes优先于includes FastjsonFilterUtil filter = new FastjsonFilterUtil(); if (excludesProperties != null &amp;&amp; excludesProperties.length &gt; 0) { filter.getExcludes().addAll(Arrays.&lt;String&gt; asList(excludesProperties)); } if (includesProperties != null &amp;&amp; includesProperties.length &gt; 0) { filter.getIncludes().addAll(Arrays.&lt;String&gt; asList(includesProperties)); } // 使用SerializerFeature.WriteDateUseDateFormat特性来序列化日期格式的类型为yyyy-MM-dd // hh24:mi:ss // 使用SerializerFeature.DisableCircularReferenceDetect特性关闭引用检测和生成 String json = JSON.toJSONString(object, filter, SerializerFeature.WriteDateUseDateFormat, SerializerFeature.DisableCircularReferenceDetect); logger.info(\"JSON String is:\" + json); response.setContentType(\"text/html;charset=utf-8\"); response.getWriter().write(json); response.getWriter().flush(); response.getWriter().close(); } catch (IOException e) { logger.error(\"An error occurred when object was converted to JSON\", e); } }} 三 Spring Boot集成swagger3.1 Spring Boot集成swagger12345678910&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.5.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.5.0&lt;/version&gt;&lt;/dependency&gt; 123456789101112131415161718192021222324252627282930313233343536373839package org.xujin.janus.admin.configuration;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.context.annotation.Profile;import springfox.documentation.builders.ApiInfoBuilder;import springfox.documentation.builders.PathSelectors;import springfox.documentation.builders.RequestHandlerSelectors;import springfox.documentation.service.ApiInfo;import springfox.documentation.spi.DocumentationType;import springfox.documentation.spring.web.plugins.Docket;import springfox.documentation.swagger2.annotations.EnableSwagger2;/** * Swagger2 配置 * @author xujin * */@Configuration@EnableSwagger2// 在生产环境不开启@Profile({ \"dev\", \"local\" })public class Swagger2Config { @Bean public Docket createRestApi() { return new Docket(DocumentationType.SWAGGER_2).apiInfo(apiInfo()).select() .apis(RequestHandlerSelectors .basePackage(\"org.xujin.janus.admin.controller\")) .paths(PathSelectors.any()).build(); } private ApiInfo apiInfo() { return new ApiInfoBuilder().title(\"Janus网关管控平台\").description(\"Janus网关管控平台\") .contact(\"Software_King@qq.com\").version(\"1.0\").build(); }} 3.2 遇到的问题访问http://localhost:8080/swagger-ui.html，控制台出现错误 1.页面显示默认报错页面。后台报错：1No handler found for GET /swagger-ui.html 2.显示Swagger空白页面 原因分析:在访问http://localhost:8080/swagger-ui.html 时，这个swagger-ui.html相关的所有前端静态文件都在springfox-swagger-ui-2.6.1.jar里面。Spring Boot自动配置本身不会自动把/swagger-ui.html这个路径映射到对应的目录META-INF/resources/下面。我们加上这个映射即可。 1234567891011121314@Configuration@EnableWebMvcpublic class ApplicationExceptionAdapter extends WebMvcConfigurerAdapter { @Override public void addResourceHandlers(ResourceHandlerRegistry registry) { registry.addResourceHandler(\"swagger-ui.html\") .addResourceLocations(\"classpath:/META-INF/resources/\"); registry.addResourceHandler(\"/webjars/**\") .addResourceLocations(\"classpath:/META-INF/resources/webjars/\"); }} 四.参考文章 http://www.cnblogs.com/bingshu/p/6864131.html http://www.jianshu.com/p/840320d431a1","link":"/sb/sb-01/"},{"title":"使用Nacos实现Spring Cloud Gateway的动态路由","text":"摘要:本文主要介绍通过Nacos下发路由配置实现Spring Cloud Gateway的动态路由。 1.前言 网关中有两个重要的概念，那就是路由配置和路由规则，路由配置是指配置某请求路径路由到指定的目的地址。而路由规则是指匹配到路由配置之后，再根据路由规则进行转发处理。 Spring Cloud Gateway作为所有请求流量的入口，在实际生产环境中为了保证高可靠和高可用，尽量避免重启,需要实现Spring Cloud Gateway动态路由配置。前面章节介绍了Spring Cloud Gateway提供的两种方法去配置路由规则，但都是在Spring Cloud Gateway启动时候，就将路由配置和规则加载到内存里，无法做到不重启网关就可以动态的对应路由的配置和规则进行增加，修改和删除。本文是基于Spring Cloud Gateway的动态路由实现基础之上编写，通过Nacos配置服务下发路由配置实现动态路由。 2. Spring Cloud Gateway简单的动态路由实现Spring Cloud Gateway的官方文档并没有讲如何动态配置，查看 Spring Cloud Gateway的源码，发现在org.springframework.cloud.gateway.actuate.GatewayControllerEndpoint类中提供了动态配置的Rest接口，但是需要开启Gateway的端点，而且提供的功能不是很强大。通过参考和GatewayControllerEndpoint相关的代码，可以自己编码实际动态路由配置。下面通过案例的方式去讲解怎么通Nacos实现Spring Cloud Gateway的动态路由。案例工程如spring-cloud-gateway-nacos所示。 代码地址:https://github.com/SpringCloud/spring-cloud-gateway-nacos 3. 简单动态路由的实现3.1 新建Maven工程sc-gateway-server 配置主要的核心依赖如代码清单所示： 代码清单: spring-cloud-gateway-nacos/sc-gateway-server/pom.xml123456789101112131415161718192021222324252627&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.nacos&lt;/groupId&gt; &lt;artifactId&gt;nacos-client&lt;/artifactId&gt; &lt;version&gt;0.4.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-webflux&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.47&lt;/version&gt;&lt;/dependency&gt; 3.2 根据Spring Cloud Gateway的路由模型定义数据传输模型 分别创建GatewayRouteDefinition.java, GatewayPredicateDefinition.java, GatewayFilterDefinition.java这三个类。(1) 创建路由定义模型 12345678910111213public class GatewayRouteDefinition { //路由的Id private String id; //路由断言集合配置 private List&lt;GatewayPredicateDefinition&gt; predicates = new ArrayList&lt;&gt;(); //路由过滤器集合配置 private List&lt;GatewayFilterDefinition&gt; filters = new ArrayList&lt;&gt;(); //路由规则转发的目标uri private String uri; //路由执行的顺序 private int order = 0; //此处省略get和set方法} (2)创建过滤器定义模型 1234567public class GatewayFilterDefinition { //Filter Name private String name; //对应的路由规则 private Map&lt;String, String&gt; args = new LinkedHashMap&lt;&gt;(); //此处省略Get和Set方法} (3)创建路由断言定义模型 1234567public class GatewayPredicateDefinition { //断言对应的Name private String name; //配置的断言规则 private Map&lt;String, String&gt; args = new LinkedHashMap&lt;&gt;(); //此处省略Get和Set方法} 3.3 编写动态路由实现类编写DynamicRouteServiceImpl并实现ApplicationEventPublisherAware接口，代码如下所示 12345678910111213141516171819202122232425262728293031323334353637@Servicepublic class DynamicRouteServiceImpl implements ApplicationEventPublisherAware { @Autowired private RouteDefinitionWriter routeDefinitionWriter; private ApplicationEventPublisher publisher; //增加路由 public String add(RouteDefinition definition) { routeDefinitionWriter.save(Mono.just(definition)).subscribe(); this.publisher.publishEvent(new RefreshRoutesEvent(this)); return \"success\"; } //更新路由 public String update(RouteDefinition definition) { try { this.routeDefinitionWriter.delete(Mono.just(definition.getId())); } catch (Exception e) { return \"update fail,not find route routeId: \"+definition.getId(); } try { routeDefinitionWriter.save(Mono.just(definition)).subscribe(); this.publisher.publishEvent(new RefreshRoutesEvent(this)); return \"success\"; } catch (Exception e) { return \"update route fail\"; } } //删除路由 public Mono&lt;ResponseEntity&lt;Object&gt;&gt; delete(String id) { return this.routeDefinitionWriter.delete(Mono.just(id)) .then(Mono.defer(() -&gt; Mono.just(ResponseEntity.ok().build()))) .onErrorResume(t -&gt; t instanceof NotFoundException, t -&gt; Mono.just(ResponseEntity.notFound().build())); } @Override public void setApplicationEventPublisher(ApplicationEventPublisher applicationEventPublisher) { this.publisher = applicationEventPublisher; }} 3.4 编写Nacos监听接收下发的路由配置3.4.1 使用Nacos监听下发的配置监听Nacos Config Server下发配置的代码如下所示： 1234567891011121314151617181920212223242526272829303132333435363738@Componentpublic class DynamicRouteServiceImplByNacos { @Autowired private DynamicRouteServiceImpl dynamicRouteService; public DynamicRouteServiceImplByNacos() { dynamicRouteByNacosListener(\"sc-gateway\",\"xujin_test\"); } /** * 监听Nacos Server下发的动态路由配置 * @param dataId * @param group */ public void dynamicRouteByNacosListener (String dataId, String group){ try { ConfigService configService=NacosFactory.createConfigService(\"127.0.0.1:8848\"); String content = configService.getConfig(dataId, group, 5000); System.out.println(content); configService.addListener(dataId, group, new Listener() { @Override public void receiveConfigInfo(String configInfo) { RouteDefinition definition= JSON.parseObject(configInfo,RouteDefinition.class); dynamicRouteService.update(definition); } @Override public Executor getExecutor() { return null; } }); } catch (NacosException e) { //todo 提醒:异常自行处理此处省略 } }} 3.4.2 两种方式创建ConfigService使用两种方式创建com.alibaba.nacos.api.config.ConfigService 1.构建Properties创建 使用createConfigService(Properties properties)，代码如下所示:1234Properties properties = new Properties(); properties.put(\"nacos.server-addr\", \"\"); properties.put(PropertyKeyConst.SERVER_ADDR, \"127.0.0.1:8848\"); ConfigService configService=NacosFactory.createConfigService(properties); 注意:PropertyKeyConst是com.alibaba.nacos.api.PropertyKeyConst 2.只传递Nacos Config Server的地址 1ConfigService configService=NacosFactory.createConfigService(\"127.0.0.1:8848\"); 4. 使用Nacos下发配置4.1 Nacos概述 Naocs由阿里开源，Nacos 致力于帮助您发现、配置和管理微服务。Nacos 提供了一组简单易用的特性集，帮助您快速实现动态服务发现、服务配置、服务元数据及流量管理。 Nacos 帮助您更敏捷和容易地构建、交付和管理微服务平台。 Nacos 是构建以“服务”为中心的现代应用架构 (例如微服务范式、云原生范式) 的服务基础设施。github地址:https://github.com/alibaba/nacos 更多Nacos的介绍，请访问官方网站:https://nacos.io/ 4.2 在IDE中启动 Nacos访问https://github.com/alibaba/nacos ,使用Git克隆Nacos代码，直接导入到IDEA中，如下所示设置启动参数，直接启动。 从IDE中启动Nacos是我比较推荐的方式，因为可以随时Debug Nacos任何代码，其它启动方式请参考官网。 5.测试5.1 Nacos中下发Spring Cloud Gateway的路由配置 1.打开浏览器访问URL:http://localhost:8848/nacos/index.html ,Nacos的管控平台如下所示: 2.在Nacos的配置列表点击+按钮，下发Spring Cloud Gateway的路由配置，如下所示: 用于测试的示例数据，如下所示: 123456789101112{ \"filters\": [], \"id\": \"jd_route\", \"order\": 0, \"predicates\": [{ \"args\": { \"pattern\": \"/jd\" }, \"name\": \"Path\" }], \"uri\": \"http://www.jd.com\"} 5.2 启动sc-gateway-server 1.Debug启动sc-gateway-server,调试截图如下所示: 2.通过Spring Cloud gateway的端点，查看路由信息 3.通过访问http://localhost:8080/jd ,可以转发到京东商城主页 5.3 更新路由配置 1.通过Nacos下发配置，修改Spring Cloud Gateway的动态路由规则 2.查看访问Spring Cloud gateway的端点配置，可以看到动态路由修改如下: 3.通过访问http://localhost:8080/jd ,可以转发到百度相关页面","link":"/sc/gw/gw10/"},{"title":"Spring Cloud Gateway基于服务发现的默认路由规则","text":"摘要:本篇文章主要介绍了Spring Cloud Gateway的基于服务发现的默认路由规则，从中可以看出Gateway的路由规则:http://Gateway_HOST:Gateway_PORT/大写的serviceId/ 和 zuul的默认路由规则http://ZUUL_HOST:ZUUL_PORT/微服务在Eureka上的serviceId/差不多。 1.Spring Gateway概述1.1 什么是Spring Cloud Gateway Spring Cloud Gateway是Spring官方基于Spring 5.0，Spring Boot 2.0和Project Reactor等技术开发的网关，Spring Cloud Gateway旨在为微服务架构提供一种简单而有效的统一的API路由管理方式。Spring Cloud Gateway作为Spring Cloud生态系中的网关，目标是替代Netflix ZUUL，其不仅提供统一的路由方式，并且基于Filter链的方式提供了网关基本的功能，例如：安全，监控/埋点，和限流等。 1.2 Spring Cloud Gateway的功能Spring Cloud Gateway 的特征： 基于 Spring Framework 5，Project Reactor 和 Spring Boot 2.0动态路由 Predicates 和 Filters 作用于特定路由 集成 Hystrix 断路器 集成 Spring Cloud DiscoveryClient 易于编写的 Predicates 和 Filters 限流 路径重写 2. Spring Cloud Gateway的工程流程 客户端向 Spring Cloud Gateway 发出请求。然后在 Gateway Handler Mapping 中找到与请求相匹配的路由，将其发送到 Gateway Web Handler。Handler 再通过指定的过滤器链来将请求发送到我们实际的服务执行业务逻辑，然后返回。过滤器之间用虚线分开是因为过滤器可能会在发送代理请求之前（“pre”）或之后（“post”）执行业务逻辑。 2.1 Pre和POST两种类型的过滤器3.基于服务发现的默认路由规则3.1 zuul和gateway的默认路由规则3.1.1 zuul的默认路由规则说明默认情况下，Zuul会代理所有注册到Eureka Server的微服务，并且Zuul的路由规则如下： http://ZUUL_HOST:ZUUL_PORT/微服务在Eureka上的serviceId/** 会被转发到serviceId对应的微服务。 http://localhost:8040/sc-zuul-first-provider/sc/order/2 3.1.2 gateway的默认路由规则下面的案例中会演示：http://localhost:9000/SC-CONSUMER/hello/xujin http://Gateway_HOST:Gateway_PORT/大写的serviceId/**，其中微服务应用名默认大写访问。 3.2 案例示例代码https://github.com/SoftwareKing/sc-gateway/tree/master/ch1 模块 说明 端口 ch1-sc-consumer 服务消费者 8000 ch1-sc-eureka Eureka Server注册中心 8761 ch1-sc-gateway Spring Cloud Gateway Sever 9000 ch1-sc-provider 服务提供者 8001 3.2.1 ch1-sc-gateway工程说明3.2.1.1 Maven依赖Spring Cloud Gateway sever主要的maven依赖如下所示 12345678910&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 3.2.1.2 yml文件配置12345678910111213141516171819spring: application: name: sc-gateway-server cloud: gateway: discovery: locator: enabled: trueserver: port: 9000eureka: client: service-url: defaultZone: http://localhost:8761/eureka/logging: level: org.springframework.cloud.gateway: debug 配置说明： spring.cloud.gateway.discovery.locator.enabled：是否与服务发现组件进行结合，通过 serviceId 转发到具体的服务实例。默认为false，设为true便开启通过服务中心的自动根据 serviceId 创建路由的功能。 修改spring cloud gateway server监听的端口为9000 eureka.client.service-url.defaultZone: http://localhost:8761/eureka/,指定注册中心的地址，Spring Cloud Gateway从注册中心获取已经注册的服务列表。 logging.level.org.springframework.cloud.gateway: debug,开启spring-Cloud-gateway的日志级别为debug，方便debug调试。 3.3 启动测试3.3.1 错误的路由规则访问访问Spring Cloud Gateway对应的server，当访问http://localhost:9000/sc-consumer/hello/xujin的时候，报错如下所示，正确的Spring Cloud Gateway的默认路由规则:http://Gateway_HOST:Gateway_PORT/大写的serviceId/** 1234567891011122018-05-18 01:10:49.742 DEBUG 6462 --- [ctor-http-nio-5] o.s.c.g.r.RouteDefinitionRouteLocator : RouteDefinition CompositeDiscoveryClient_SC-CONSUMER applying {pattern=/SC-CONSUMER/**} to Path2018-05-18 01:10:49.743 DEBUG 6462 --- [ctor-http-nio-5] o.s.c.g.r.RouteDefinitionRouteLocator : RouteDefinition CompositeDiscoveryClient_SC-CONSUMER applying filter {regexp=/SC-CONSUMER/(?&lt;remaining&gt;.*), replacement=/${remaining}} to RewritePath2018-05-18 01:10:49.743 DEBUG 6462 --- [ctor-http-nio-5] o.s.c.g.r.RouteDefinitionRouteLocator : RouteDefinition matched: CompositeDiscoveryClient_SC-CONSUMER2018-05-18 01:10:49.744 DEBUG 6462 --- [ctor-http-nio-5] o.s.c.g.r.RouteDefinitionRouteLocator : RouteDefinition CompositeDiscoveryClient_SC-PRODUCER applying {pattern=/SC-PRODUCER/**} to Path2018-05-18 01:10:49.744 DEBUG 6462 --- [ctor-http-nio-5] o.s.c.g.r.RouteDefinitionRouteLocator : RouteDefinition CompositeDiscoveryClient_SC-PRODUCER applying filter {regexp=/SC-PRODUCER/(?&lt;remaining&gt;.*), replacement=/${remaining}} to RewritePath2018-05-18 01:10:49.745 DEBUG 6462 --- [ctor-http-nio-5] o.s.c.g.r.RouteDefinitionRouteLocator : RouteDefinition matched: CompositeDiscoveryClient_SC-PRODUCER2018-05-18 01:10:49.745 DEBUG 6462 --- [ctor-http-nio-5] o.s.c.g.r.RouteDefinitionRouteLocator : RouteDefinition CompositeDiscoveryClient_SC-GATEWAY-SERVER applying {pattern=/SC-GATEWAY-SERVER/**} to Path2018-05-18 01:10:49.747 DEBUG 6462 --- [ctor-http-nio-5] o.s.c.g.r.RouteDefinitionRouteLocator : RouteDefinition CompositeDiscoveryClient_SC-GATEWAY-SERVER applying filter {regexp=/SC-GATEWAY-SERVER/(?&lt;remaining&gt;.*), replacement=/${remaining}} to RewritePath2018-05-18 01:10:49.748 DEBUG 6462 --- [ctor-http-nio-5] o.s.c.g.r.RouteDefinitionRouteLocator : RouteDefinition matched: CompositeDiscoveryClient_SC-GATEWAY-SERVER2018-05-18 01:10:49.748 DEBUG 6462 --- [ctor-http-nio-5] o.s.c.g.h.RoutePredicateHandlerMapping : Route matched: CompositeDiscoveryClient_SC-CONSUMER2018-05-18 01:10:49.749 DEBUG 6462 --- [ctor-http-nio-5] o.s.c.g.h.RoutePredicateHandlerMapping : Mapping [Exchange: GET http://localhost:9000/SC-CONSUMER/hello/xujin] to Route{id='CompositeDiscoveryClient_SC-CONSUMER', uri=lb://SC-CONSUMER, order=0, predicate=org.springframework.cloud.gateway.handler.predicate.PathRoutePredicateFactory$$Lambda$707/751096818@7f4c6373, gatewayFilters=[OrderedGatewayFilter{delegate=org.springframework.cloud.gateway.filter.factory.RewritePathGatewayFilterFactory$$Lambda$709/672603106@293895d2, order=1}]}2018-05-18 01:10:49.749 DEBUG 6462 --- [ctor-http-nio-5] o.s.c.g.handler.FilteringWebHandler : Sorted gatewayFilterFactories: [OrderedGatewayFilter{delegate=GatewayFilterAdapter{delegate=org.springframework.cloud.gateway.filter.NettyWriteResponseFilter@5e85c21b}, order=-1}, OrderedGatewayFilter{delegate=org.springframework.cloud.gateway.filter.factory.RewritePathGatewayFilterFactory$$Lambda$709/672603106@293895d2, order=1}, OrderedGatewayFilter{delegate=GatewayFilterAdapter{delegate=org.springframework.cloud.gateway.filter.RouteToRequestUrlFilter@38e83838}, order=10000}, OrderedGatewayFilter{delegate=GatewayFilterAdapter{delegate=org.springframework.cloud.gateway.filter.LoadBalancerClientFilter@6ef2f7ad}, order=10100}, OrderedGatewayFilter{delegate=GatewayFilterAdapter{delegate=org.springframework.cloud.gateway.filter.AdaptCachedBodyGlobalFilter@41def031}, order=2147483637}, OrderedGatewayFilter{delegate=GatewayFilterAdapter{delegate=org.springframework.cloud.gateway.filter.WebsocketRoutingFilter@4966bab1}, order=2147483646}, OrderedGatewayFilter{delegate=GatewayFilterAdapter{delegate=org.springframework.cloud.gateway.filter.NettyRoutingFilter@22d477c2}, order=2147483647}, OrderedGatewayFilter{delegate=GatewayFilterAdapter{delegate=org.springframework.cloud.gateway.filter.ForwardRoutingFilter@39832280}, order=2147483647}] 从上面的log，看到返回了 404 错误，进一步可以看到 Spring Cloud Gateway 已经为我们的 provider 和 consumer 自动创建了对应的路由转发规则，但是这里的 pattern/regexp 里都是大写的，下面换成大写的测试一下。 3.3.2 Gateway正确的路由规则测试访问正确的http://localhost:9000/SC-CONSUMER/hello/xujin，可以成功访问。 1234567891011122018-05-22 09:04:21.204 DEBUG 1677 --- [ctor-http-nio-2] o.s.c.g.r.RouteDefinitionRouteLocator : RouteDefinition CompositeDiscoveryClient_SC-CONSUMER applying {pattern=/SC-CONSUMER/**} to Path2018-05-22 09:04:21.205 DEBUG 1677 --- [ctor-http-nio-2] o.s.c.g.r.RouteDefinitionRouteLocator : RouteDefinition CompositeDiscoveryClient_SC-CONSUMER applying filter {regexp=/SC-CONSUMER/(?&lt;remaining&gt;.*), replacement=/${remaining}} to RewritePath2018-05-22 09:04:21.205 DEBUG 1677 --- [ctor-http-nio-2] o.s.c.g.r.RouteDefinitionRouteLocator : RouteDefinition matched: CompositeDiscoveryClient_SC-CONSUMER2018-05-22 09:04:21.206 DEBUG 1677 --- [ctor-http-nio-2] o.s.c.g.r.RouteDefinitionRouteLocator : RouteDefinition CompositeDiscoveryClient_SC-PRODUCER applying {pattern=/SC-PRODUCER/**} to Path2018-05-22 09:04:21.207 DEBUG 1677 --- [ctor-http-nio-2] o.s.c.g.r.RouteDefinitionRouteLocator : RouteDefinition CompositeDiscoveryClient_SC-PRODUCER applying filter {regexp=/SC-PRODUCER/(?&lt;remaining&gt;.*), replacement=/${remaining}} to RewritePath2018-05-22 09:04:21.207 DEBUG 1677 --- [ctor-http-nio-2] o.s.c.g.r.RouteDefinitionRouteLocator : RouteDefinition matched: CompositeDiscoveryClient_SC-PRODUCER2018-05-22 09:04:21.208 DEBUG 1677 --- [ctor-http-nio-2] o.s.c.g.r.RouteDefinitionRouteLocator : RouteDefinition CompositeDiscoveryClient_SC-GATEWAY-SERVER applying {pattern=/SC-GATEWAY-SERVER/**} to Path2018-05-22 09:04:21.208 DEBUG 1677 --- [ctor-http-nio-2] o.s.c.g.r.RouteDefinitionRouteLocator : RouteDefinition CompositeDiscoveryClient_SC-GATEWAY-SERVER applying filter {regexp=/SC-GATEWAY-SERVER/(?&lt;remaining&gt;.*), replacement=/${remaining}} to RewritePath2018-05-22 09:04:21.209 DEBUG 1677 --- [ctor-http-nio-2] o.s.c.g.r.RouteDefinitionRouteLocator : RouteDefinition matched: CompositeDiscoveryClient_SC-GATEWAY-SERVER2018-05-22 09:04:21.209 DEBUG 1677 --- [ctor-http-nio-2] o.s.c.g.h.RoutePredicateHandlerMapping : Route matched: CompositeDiscoveryClient_SC-CONSUMER2018-05-22 09:04:21.209 DEBUG 1677 --- [ctor-http-nio-2] o.s.c.g.h.RoutePredicateHandlerMapping : Mapping [Exchange: GET http://localhost:9000/SC-CONSUMER/hello/xujin] to Route{id='CompositeDiscoveryClient_SC-CONSUMER', uri=lb://SC-CONSUMER, order=0, predicate=org.springframework.cloud.gateway.handler.predicate.PathRoutePredicateFactory$$Lambda$706/57023854@24f1a91e, gatewayFilters=[OrderedGatewayFilter{delegate=org.springframework.cloud.gateway.filter.factory.RewritePathGatewayFilterFactory$$Lambda$708/2036079541@cbb7393, order=1}]}2018-05-22 09:04:21.209 DEBUG 1677 --- [ctor-http-nio-2] o.s.c.g.handler.FilteringWebHandler : Sorted gatewayFilterFactories: [OrderedGatewayFilter{delegate=GatewayFilterAdapter{delegate=org.springframework.cloud.gateway.filter.NettyWriteResponseFilter@29a98d9f}, order=-1}, OrderedGatewayFilter{delegate=org.springframework.cloud.gateway.filter.factory.RewritePathGatewayFilterFactory$$Lambda$708/2036079541@cbb7393, order=1}, OrderedGatewayFilter{delegate=GatewayFilterAdapter{delegate=org.springframework.cloud.gateway.filter.RouteToRequestUrlFilter@544e8149}, order=10000}, OrderedGatewayFilter{delegate=GatewayFilterAdapter{delegate=org.springframework.cloud.gateway.filter.LoadBalancerClientFilter@55d58825}, order=10100}, OrderedGatewayFilter{delegate=GatewayFilterAdapter{delegate=org.springframework.cloud.gateway.filter.AdaptCachedBodyGlobalFilter@2da3b078}, order=2147483637}, OrderedGatewayFilter{delegate=GatewayFilterAdapter{delegate=org.springframework.cloud.gateway.filter.WebsocketRoutingFilter@1a96d94c}, order=2147483646}, OrderedGatewayFilter{delegate=GatewayFilterAdapter{delegate=org.springframework.cloud.gateway.filter.NettyRoutingFilter@19a64eae}, order=2147483647}, OrderedGatewayFilter{delegate=GatewayFilterAdapter{delegate=org.springframework.cloud.gateway.filter.ForwardRoutingFilter@7fb66650}, order=2147483647}] 可以看出，Spring Cloud Gateway 自动的为我们的 consumer 创建了一个路由，类似于下边这样12345678routes: - id: CompositeDiscoveryClient_SC-CONSUMER uri: lb://SC-CONSUMER order: 0 predicates: - Path=/SC-CONSUMER/** filters: - RewritePath=/SC-CONSUMER/(?&lt;segment&gt;.*), /$\\{segment} 所以从zuul迁移到gateway的时候，服务路由规则中的微服务应用Id默认从小写变为大写。","link":"/sc/gw/gw05/"},{"title":"Spring Cloud Gateway的动态路由实现","text":"摘要:本文主要介绍了Spring Cloud Gateway的动态路由的简单实现方式。 1.前言 网关中有两个重要的概念，那就是路由配置和路由规则，路由配置是指配置某请求路径路由到指定的目的地址。而路由规则是指匹配到路由配置之后，再根据路由规则进行转发处理。 Spring Cloud Gateway作为所有请求流量的入口，在实际生产环境中为了保证高可靠和高可用，尽量避免重启,需要实现Spring Cloud Gateway动态路由配置。前面章节介绍了Spring Cloud Gateway提供的两种方法去配置路由规则，但都是在Spring Cloud Gateway启动时候，就将路由配置和规则加载到内存里，无法做到不重启网关就可以动态的对应路由的配置和规则进行增加，修改和删除。本篇文章简单介绍如何实现Spring Cloud Gateway的动态路由。 2. Spring Cloud Gateway简单的动态路由实现Spring Cloud Gateway的官方文档并没有讲如何动态配置，查看 Spring Cloud Gateway的源码，发现在org.springframework.cloud.gateway.actuate.GatewayControllerEndpoint类中提供了动态配置的Rest接口，但是需要开启Gateway的端点，而且提供的功能不是很强大。通过参考和GatewayControllerEndpoint相关的代码，可以自己编码实际动态路由配置。下面通过案例的方式去讲解怎么实现Gateway的动态路由配置。案例工程如ch18-7-gateway所示。 代码地址:https://github.com/SpringCloud/spring-cloud-code/blob/master/ch18-7/ch18-7-gateway 3. 简单动态路由的实现3.1 新建Maven工程ch18-7-gateway 配置主要的核心依赖如代码清单18-33所示： 代码清单: ch18-7/ch18-7-gateway/pom.xml1234567891011121314&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-webflux&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 3.2 根据Spring Cloud Gateway的路由模型定义数据传输模型 分别创建GatewayRouteDefinition.java, GatewayPredicateDefinition.java, GatewayFilterDefinition.java这三个类。(1) 创建路由定义模型如下代码清单18-34所示：代码清单 18-34: ch18-7/ch18-7-gateway/src/main/java/cn/springcloud/book/gateway/model/GatewayRouteDefinition.java 12345678910111213public class GatewayRouteDefinition { //路由的Id private String id; //路由断言集合配置 private List&lt;GatewayPredicateDefinition&gt; predicates = new ArrayList&lt;&gt;(); //路由过滤器集合配置 private List&lt;GatewayFilterDefinition&gt; filters = new ArrayList&lt;&gt;(); //路由规则转发的目标uri private String uri; //路由执行的顺序 private int order = 0; //此处省略get和set方法} (2)创建过滤器定义模型,代码如代码清单18-35所示：代码清单18-35: ch18-7/ch18-7-gateway/src/main/java/cn/springcloud/book/gateway/model/GatewayFilterDefinition.java 1234567public class GatewayFilterDefinition { //Filter Name private String name; //对应的路由规则 private Map&lt;String, String&gt; args = new LinkedHashMap&lt;&gt;(); //此处省略Get和Set方法} (3)路由断言定义模型，代码如代码清单18-36所示:代码清单18-36: ch18-7/ch18-7-gateway/src/main/java/cn/springcloud/book/gateway/model/GatewayPredicateDefinition.java 1234567public class GatewayPredicateDefinition { //断言对应的Name private String name; //配置的断言规则 private Map&lt;String, String&gt; args = new LinkedHashMap&lt;&gt;(); //此处省略Get和Set方法} 3.3 编写动态路由实现类编写DynamicRouteServiceImpl并实现ApplicationEventPublisherAware接口，代码如代码清单18-37所示: ch18-37/ch18-7-gateway/src/main/java/cn/springcloud/book/gateway/route/DynamicRouteServiceImpl.java 12345678910111213141516171819202122232425262728293031323334353637@Servicepublic class DynamicRouteServiceImpl implements ApplicationEventPublisherAware { @Autowired private RouteDefinitionWriter routeDefinitionWriter; private ApplicationEventPublisher publisher; //增加路由 public String add(RouteDefinition definition) { routeDefinitionWriter.save(Mono.just(definition)).subscribe(); this.publisher.publishEvent(new RefreshRoutesEvent(this)); return \"success\"; } //更新路由 public String update(RouteDefinition definition) { try { this.routeDefinitionWriter.delete(Mono.just(definition.getId())); } catch (Exception e) { return \"update fail,not find route routeId: \"+definition.getId(); } try { routeDefinitionWriter.save(Mono.just(definition)).subscribe(); this.publisher.publishEvent(new RefreshRoutesEvent(this)); return \"success\"; } catch (Exception e) { return \"update route fail\"; } } //删除路由 public Mono&lt;ResponseEntity&lt;Object&gt;&gt; delete(String id) { return this.routeDefinitionWriter.delete(Mono.just(id)) .then(Mono.defer(() -&gt; Mono.just(ResponseEntity.ok().build()))) .onErrorResume(t -&gt; t instanceof NotFoundException, t -&gt; Mono.just(ResponseEntity.notFound().build())); } @Override public void setApplicationEventPublisher(ApplicationEventPublisher applicationEventPublisher) { this.publisher = applicationEventPublisher; }} 3.4 编写Rest接口编写RouteController类的提供Rest接口，用于动态路由配置。代码如代码清单18-38所示:代码清单 18-38: ch18-7/ch18-7-gateway/src/main/java/cn/springcloud/book/gateway/controller/RouteController.java 1234567891011121314151617181920212223242526272829@RestController@RequestMapping(\"/route\")public class RouteController { @Autowired private DynamicRouteServiceImpl dynamicRouteService; //增加路由 @PostMapping(\"/add\") public String add(@RequestBody GatewayRouteDefinition gwdefinition) { try { RouteDefinition definition = assembleRouteDefinition(gwdefinition); return this.dynamicRouteService.add(definition); } catch (Exception e) { e.printStackTrace(); } return \"succss\"; } //删除路由 @DeleteMapping(\"/routes/{id}\") public Mono&lt;ResponseEntity&lt;Object&gt;&gt; delete(@PathVariable String id) { return this.dynamicRouteService.delete(id); } //更新路由 @PostMapping(\"/update\") public String update(@RequestBody GatewayRouteDefinition gwdefinition) { RouteDefinition definition = assembleRouteDefinition(gwdefinition); return this.dynamicRouteService.update(definition); }} 3.5 配置application.yml文件在application.yml文件配置应用的配置信息，并开启Spring Cloud Gateway对外提供的端点Rest接口。代码如代码清单18-39所示:代码清单 18-39: ch18-7/ch18-7-gateway/src/main/resources/application.yml配置输出日志如下所示:123456789101112131415# 配置输出日志logging: level: org.springframework.cloud.gateway: TRACE org.springframework.http.server.reactive: DEBUG org.springframework.web.reactive: DEBUG reactor.ipc.netty: DEBUG#开启端点management: endpoints: web: exposure: include: '*' security: enabled: false 3.6 启动ch18-7-gateway应用测试(1) 启动ch18-7-gateway应用之后，由于开启了端点，首先打开浏览器访问端点URL:http://localhost:8080/actuator/gateway/routes ,查看路由信息返回为空，如下图所示: (2)打开PostMan，访问http://localhost:8080/route/add, 发起Post请求，如下图所示,返回success说明向Gateway增加路由配置成功。 然后再打开PostMan访问端点URL:http://localhost:8080/actuator/gateway/routes , 查看路由信息返回如下图所示，可以看到已经添加的路由配置。 (3) 打开浏览器访问http://localhost:8080/jd, 可以正常转发https://www.jd.com/对应的京东商城首页。(4) 通过访问http://localhost:8080/route/update, 对id为jd_route的路由更新配置，如下图所示： 然后再访问路由端点URL,发现路由配置已经被更新，如下图所示: 然后通过浏览器访问http://localhost:8080/taobao ,可以成功转发到淘宝网。(5) 通过访问http: //localhost:8080/route/delete/jd_route,其中的id为路由对应的id，删除路由结果如下图所示: 4.Spring Cloud Gateway推荐文章Spring Cloud Gateway中的权重路由Spring Cloud Gateway中的GatewayFilter和GlobalFilterSpring Cloud Gateway只有Pre和POST两种类型的FilterSpring Cloud Gateway基于服务发现的默认路由规则Spring Cloud Gateway的Before路由断言工厂Spring Cloud Gateway的After路由断言工厂Spring Cloud Gateway揭秘之处理请求流程Spring Cloud Gateway入门案例 5.《重新定义Spring Cloud实战》中的Spring Cloud Gateway第17章Spring Cloud Gateway上篇39917.1 Spring Cloud Gateway概述39917.1.1 什么是Spring Cloud Gateway39917.1.2 Spring Cloud Gateway的核心概念39917.2 Spring Cloud Gateway的工作原理40017.3 Spring Cloud Gateway入门案例40117.4 Spring Cloud Gateway的路由断言40417.4.1 After路由断言工厂40417.4.2 Before路由断言工厂40617.4.3 Between路由断言工厂40617.4.4 Cookie路由断言工厂40717.4.5 Header路由断言工厂40817.4.6 Host路由断言工厂41017.4.7 Method路由断言工厂41117.4.8 Query路由断言工厂41117.4.9 RemoteAddr路由断言工厂41217.5 Spring Cloud Gateway的内置Filter41317.5.1 AddRequestHeader过滤器工厂41317.5.2 AddRequestParameter过滤器41317.5.3 RewritePath过滤器41417.5.4 AddResponseHeader过滤器41517.5.5 StripPrefix过滤器41617.5.6 Retry过滤器41717.5.7 Hystrix过滤器41817.6 本章小结420第18章 Spring Cloud Gateway下篇42118.1 Gateway基于服务发现的路由规则42118.1.1 Gateway的服务发现路由概述42118.1.2 服务发现的路由规则案例42218.2 Gateway Filter和Global Filter42518.2.1 Gateway Filter和Global Filter概述42518.2.2 自定义Gateway Filter案例42518.2.3 自定义Global Filter案例42718.3 Spring Cloud Gateway实战42818.3.1 Spring Cloud Gateway权重路由42818.3.2 Spring Cloud Gateway中Https的使用技巧43118.3.3 Spring Cloud Gateway集成Swagger43618.3.4 Spring Cloud Gateway限流44218.3.5 Spring Cloud Gateway的动态路由45018.4 Spring Cloud Gateway源码篇45818.4.1 Spring Cloud Gateway的处理流程45818.4.2 Gateway中ServerWebExchange构建分析45918.4.3 DispatcherHandler源码分析46018.4.4 RoutePredicateHandlerMapping源码分析46118.4.5 FilteringWebHandler源码分析46218.4.6 执行Filter源码分析46318.5 本章小结465 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273├── ch17-1│ ├── ch17-1-1-gateway│ ├── ch17-1-2-gateway│ ├── ch17-1.iml│ └── pom.xml├── ch17-2│ ├── ch17-2-1-gateway│ ├── ch17-2-2-gateway│ ├── ch17-2-3-gateway│ ├── ch17-2-4-gateway│ ├── ch17-2-5-gateway│ ├── ch17-2-6-gateway│ ├── ch17-2-7-gateway│ ├── ch17-2-8-gateway│ ├── ch17-2-9-gateway│ ├── ch17-2-service│ ├── ch17-2.iml│ └── pom.xml├── ch17-3│ ├── ch17-3-1-gateway│ ├── ch17-3-2-gateway│ ├── ch17-3-3-gateway│ ├── ch17-3-4-gateway│ ├── ch17-3-5-gateway│ ├── ch17-3-6-gateway│ ├── ch17-3-7-gateway│ ├── ch17-3-service│ ├── ch17-3.iml│ └── pom.xml├── ch18-1│ ├── ch18-1-consumer│ ├── ch18-1-eureka│ ├── ch18-1-gateway│ ├── ch18-1-provider│ ├── ch18-1.iml│ └── pom.xml├── ch18-2│ ├── ch18-2-gateway│ ├── ch18-2-provider│ ├── ch18-2.iml│ ├── pom.xml│ └── reademe.txt├── ch18-3│ ├── ch18-3-gateway│ ├── ch18-3-provider│ ├── ch18-3.iml│ └── pom.xml├── ch18-4│ ├── ch18-4-eureka│ ├── ch18-4-gateway-https│ ├── ch18-4-service-a│ ├── ch18-4-service-b│ ├── ch18-4.iml│ ├── pom.xml│ └── reademe.md├── ch18-5│ ├── ch18-5-eureka│ ├── ch18-5-gateway│ ├── ch18-5-service│ ├── ch18-5.iml│ └── pom.xml├── ch18-6│ ├── ch18-6-1-gateway│ ├── ch18-6-2-gateway│ ├── ch18-6-3-gateway│ ├── ch18-6-provider│ ├── ch18-6.iml│ └── pom.xml├── ch18-7│ ├── ch18-7-gateway│ ├── ch18-7.iml│ ├── pom.xml│ └── readme.md Spring Cloud Gateway所有示例代码地址:https://github.com/SpringCloud/spring-cloud-code","link":"/sc/gw/gw09/"},{"title":"Spring Cloud Gateway中的GatewayFilter和GlobalFilter","text":"摘要:本文主要介绍了什么是GatewayFilter和GlobalFilter，以及区别和联系。然后介绍如何在Spring Cloud Gateway中自定义使用GatewayFilter和GlobalFilter。 1. Spring Cloud gateway的FilterSpring Cloud gateway中的Filter从接口实现上分为两种一种是GatewayFilter，另外一种是GlobalFilter。 1.1 GatewayFilter与GlobalFilter的区别区别用英语可以总结如下:At a high level global filters are applied to all routes, while a gateway filter will be applied to an individual route(s) 在一个高的角度来看，Global filters会被应用到所有的路由上，而Gateway filter将应用到单个路由上或者一个分组的路由上。在下面的案例中将会进行说明。 1.2 本文代码地址 https://github.com/SoftwareKing/sc-gateway/tree/master/ch2 2. GatewayFilter和GlobalFilter2.1 GatewayFilter2.1.1 什么是GatewayFilterContract for interception-style, chained processing of Web requests that may be used to implement cross-cutting, application-agnostic requirements such as security, timeouts, and others. Specific to a Gateway Copied from WebFilter GatewayFilter是从WebFilter中Copy过来的，相当于一个Filter过滤器，可以对访问的URL过滤横切处理，应用场景比如超时，安全等。 从Spring Cloud Gateway的源码中如下所示，可以看出GatewayFilter的使用场景: 12345678910111213141516171819202122232425/** * Contract for interception-style, chained processing of Web requests that may * be used to implement cross-cutting, application-agnostic requirements such * as security, timeouts, and others. Specific to a Gateway * * Copied from WebFilter * * @author Rossen Stoyanchev * @since 5.0 */public interface GatewayFilter extends ShortcutConfigurable { String NAME_KEY = \"name\"; String VALUE_KEY = \"value\"; /** * Process the Web request and (optionally) delegate to the next * {@code WebFilter} through the given {@link GatewayFilterChain}. * @param exchange the current server exchange * @param chain provides a way to delegate to the next filter * @return {@code Mono&lt;Void&gt;} to indicate when request processing is complete */ Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain);} GatewayFilter和GlobalFilter两个接口中定义的方法一样都是Mono filter(ServerWebExchange exchange, GatewayFilterChain chain)，唯一的区别就是GatewayFilter继承了ShortcutConfigurable，GlobalFilter没有任何继承。 2.1.2 自定义GatewayFilter(Custom GatewayFilter)如org.xujin.sc.filter.CustomFilter代码所示，通过自定义GatewayFilter对路由转发的处理时长统计。 1234567891011121314151617181920212223242526272829303132333435363738package org.xujin.sc.filter;import org.apache.commons.logging.Log;import org.apache.commons.logging.LogFactory;import org.springframework.cloud.gateway.filter.GatewayFilter;import org.springframework.cloud.gateway.filter.GatewayFilterChain;import org.springframework.core.Ordered;import org.springframework.web.server.ServerWebExchange;import reactor.core.publisher.Mono;/** * 统计某个或者某种路由的的处理时长 * @author xujin */public class CustomFilter implements GatewayFilter, Ordered { private static final Log log = LogFactory.getLog(GatewayFilter.class); private static final String COUNT_Start_TIME = \"countStartTime\"; @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) { exchange.getAttributes().put(COUNT_Start_TIME, System.currentTimeMillis()); return chain.filter(exchange).then( Mono.fromRunnable(() -&gt; { Long startTime = exchange.getAttribute(COUNT_Start_TIME); Long endTime=(System.currentTimeMillis() - startTime); if (startTime != null) { log.info(exchange.getRequest().getURI().getRawPath() + \": \" + endTime + \"ms\"); } }) ); } @Override public int getOrder() { return Ordered.LOWEST_PRECEDENCE; }} 2.1.3 Gateway Filter与RouteLocator绑定使用在org.xujin.sc.GatewayServerApplication中customerRouteLocator如下所示: 1234567891011121314151617181920212223@SpringBootApplicationpublic class GatewayServerApplication { @Bean public RouteLocator customerRouteLocator(RouteLocatorBuilder builder) { return builder.routes() .route(r -&gt; r.path(\"/test/prefix/**\") .filters(f -&gt; f.stripPrefix(2) .filter(new CustomFilter()) .addResponseHeader(\"X-Response-test\", \"test\")) .uri(\"lb://SC-CONSUMER\") .order(0) .id(\"test_consumer_service\") ) .build(); } public static void main(String[] args) { SpringApplication.run(GatewayServerApplication.class, args); }} r.path(“/test/prefix/**”)表示自定义了访问前缀，在真正的Gateway进行路由转发的时候，会用过f.stripPrefix(2)把前缀去掉。 使用场景:可以把对外暴露的URL通过加前缀分组打标。 filter(new CustomFilter() filter(new CustomFilter()，表示把自定义的Filter加到Filter链里面执行，注意一点是自定义GlobalFilter不需要加进去。 uri(“lb://SC-CONSUMER”) uri(“lb://SC-CONSUMER”)表示Spring Cloud Gateway对spring.application.name等于sc-consumer源服务应用中的URL进行协议适配转发。 2.1.4 测试如下:1.访问http://localhost:9000/SC-CONSUMER/hello/xujin 能正常访问。 123DEBUG 31658 --- [ctor-http-nio-2] o.s.c.g.h.RoutePredicateHandlerMapping : Route matched: CompositeDiscoveryClient_SC-CONSUMER2018-05-27 09:58:07.905 DEBUG 31658 --- [ctor-http-nio-2] o.s.c.g.h.RoutePredicateHandlerMapping : Mapping [Exchange: GET http://localhost:9000/SC-CONSUMER/hello/xujin] to Route{id='CompositeDiscoveryClient_SC-CONSUMER', uri=lb://SC-CONSUMER, order=0, predicate=org.springframework.cloud.gateway.handler.predicate.PathRoutePredicateFactory$$Lambda$337/1295338046@f2ff0c8, gatewayFilters=[OrderedGatewayFilter{delegate=org.springframework.cloud.gateway.filter.factory.RewritePathGatewayFilterFactory$$Lambda$717/1168359877@1f74a2b, order=1}]}2018-05-27 09:58:07.905 DEBUG 31658 --- [ctor-http-nio-2] o.s.c.g.handler.FilteringWebHandler : Sorted gatewayFilterFactories: [OrderedGatewayFilter{delegate=GatewayFilterAdapter{delegate=org.springframework.cloud.gateway.filter.NettyWriteResponseFilter@f5bf288}, order=-1}, OrderedGatewayFilter{delegate=org.springframework.cloud.gateway.filter.factory.RewritePathGatewayFilterFactory$$Lambda$717/1168359877@1f74a2b, order=1}, OrderedGatewayFilter{delegate=GatewayFilterAdapter{delegate=org.springframework.cloud.gateway.filter.RouteToRequestUrlFilter@26c77f54}, order=10000}, OrderedGatewayFilter{delegate=GatewayFilterAdapter{delegate=org.springframework.cloud.gateway.filter.LoadBalancerClientFilter@4c38cd16}, order=10100}, OrderedGatewayFilter{delegate=GatewayFilterAdapter{delegate=org.springframework.cloud.gateway.filter.AdaptCachedBodyGlobalFilter@2c1d57bc}, order=2147483637}, OrderedGatewayFilter{delegate=GatewayFilterAdapter{delegate=org.springframework.cloud.gateway.filter.WebsocketRoutingFilter@6e9a0bea}, order=2147483646}, OrderedGatewayFilter{delegate=GatewayFilterAdapter{delegate=org.springframework.cloud.gateway.filter.NettyRoutingFilter@7ddcb0dc}, order=2147483647}, OrderedGatewayFilter{delegate=GatewayFilterAdapter{delegate=org.springframework.cloud.gateway.filter.ForwardRoutingFilter@3e856100}, order=2147483647}] 从上面的控制台打印日志可以看出，没有打印出该URL对应的耗时。 2.加上URL前缀/test/prefix/访问，测试URL为http://localhost:9000/test/prefix/hello/testCustomFilter/xujin 1232018-05-27 10:01:56.057 DEBUG 31658 --- [ctor-http-nio-2] o.s.c.g.h.RoutePredicateHandlerMapping : Mapping [Exchange: GET http://localhost:9000/test/prefix/hello/testCustomFilter/xujin] to Route{id='test_consumer_service', uri=lb://SC-CONSUMER, order=0, predicate=org.springframework.cloud.gateway.handler.predicate.PathRoutePredicateFactory$$Lambda$337/1295338046@6dbaa72e, gatewayFilters=[OrderedGatewayFilter{delegate=org.springframework.cloud.gateway.filter.factory.StripPrefixGatewayFilterFactory$$Lambda$340/1149217113@41fb2078, order=0}, org.xujin.sc.filter.CustomFilter@281885a3, OrderedGatewayFilter{delegate=org.springframework.cloud.gateway.filter.factory.AddResponseHeaderGatewayFilterFactory$$Lambda$342/1099925775@4705cae6, order=0}]}2018-05-27 10:01:56.057 DEBUG 31658 --- [ctor-http-nio-2] o.s.c.g.handler.FilteringWebHandler : Sorted gatewayFilterFactories: [OrderedGatewayFilter{delegate=GatewayFilterAdapter{delegate=org.springframework.cloud.gateway.filter.NettyWriteResponseFilter@f5bf288}, order=-1}, OrderedGatewayFilter{delegate=org.springframework.cloud.gateway.filter.factory.StripPrefixGatewayFilterFactory$$Lambda$340/1149217113@41fb2078, order=0}, OrderedGatewayFilter{delegate=org.springframework.cloud.gateway.filter.factory.AddResponseHeaderGatewayFilterFactory$$Lambda$342/1099925775@4705cae6, order=0}, OrderedGatewayFilter{delegate=GatewayFilterAdapter{delegate=org.springframework.cloud.gateway.filter.RouteToRequestUrlFilter@26c77f54}, order=10000}, OrderedGatewayFilter{delegate=GatewayFilterAdapter{delegate=org.springframework.cloud.gateway.filter.LoadBalancerClientFilter@4c38cd16}, order=10100}, OrderedGatewayFilter{delegate=GatewayFilterAdapter{delegate=org.springframework.cloud.gateway.filter.AdaptCachedBodyGlobalFilter@2c1d57bc}, order=2147483637}, OrderedGatewayFilter{delegate=GatewayFilterAdapter{delegate=org.springframework.cloud.gateway.filter.WebsocketRoutingFilter@6e9a0bea}, order=2147483646}, OrderedGatewayFilter{delegate=GatewayFilterAdapter{delegate=org.springframework.cloud.gateway.filter.NettyRoutingFilter@7ddcb0dc}, order=2147483647}, OrderedGatewayFilter{delegate=GatewayFilterAdapter{delegate=org.springframework.cloud.gateway.filter.ForwardRoutingFilter@3e856100}, order=2147483647}, org.xujin.sc.filter.CustomFilter@281885a3]2018-05-27 10:02:00.347 INFO 31658 --- [ctor-http-nio-8] o.s.cloud.gateway.filter.GatewayFilter : /hello/testCustomFilter/xujin: 859ms 如上日志可以看到/hello/testCustomFilter/xujin: 859ms，Gateway转发的时候去掉了前缀。 2.2 GlobalFilter2.2.1 什么是GlobalFilter The GlobalFilter interface has the same signature as GatewayFilter. These are special filters that are conditionally applied to all routes. (This interface and usage are subject to change in future milestones). Spring Cloud gateway定义了GlobalFilter的接口让我们去自定义实现自己的的GlobalFilter。GlobalFilter是一个全局的Filter，作用于所有的路由。 123456789101112public interface GlobalFilter { /** * Process the Web request and (optionally) delegate to the next * {@code WebFilter} through the given {@link GatewayFilterChain}. * @param exchange the current server exchange * @param chain provides a way to delegate to the next filter * @return {@code Mono&lt;Void&gt;} to indicate when request processing is complete */ Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain);} 2.2.2 自定义全局过滤器(Custom GlobalFilter)在这里简单定义AuthSignatureFilter实现GlobalFilter，使用场景就是Gateway对请求的URL校验权限，判断请求的URL是否是合法请求。通过从ServerWebExchange获取请求上下文中authToken对应的值，进行判null处理，其它的check逻辑可以自定定制。 12345678910111213141516171819202122232425262728293031package org.xujin.sc.filter;import org.springframework.cloud.gateway.filter.GatewayFilterChain;import org.springframework.cloud.gateway.filter.GlobalFilter;import org.springframework.core.Ordered;import org.springframework.http.HttpStatus;import org.springframework.stereotype.Component;import org.springframework.web.server.ServerWebExchange;import reactor.core.publisher.Mono;/** * 调用鉴权 */@Componentpublic class AuthSignatureFilter implements GlobalFilter, Ordered { @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) { String token = exchange.getRequest().getQueryParams().getFirst(\"authToken\"); if (token == null || token.isEmpty()) { exchange.getResponse().setStatusCode(HttpStatus.UNAUTHORIZED); return exchange.getResponse().setComplete(); } return chain.filter(exchange); } @Override public int getOrder() { return -200; }} GlobalFilter写完了，那问题来了？如何让其在Gateway中运行生效，有两种方式一种直接加@Component注解，另外一种可以在 Spring Config 中配置这个 Bean如下所示: 1234@Beanpublic AuthSignatureFilter authSignatureFilter(){ return new AuthSignatureFilter();} 测试1.访问http://localhost:9000/test/prefix/hello/testCustomFilter/xujin 如下所示由于authToken为空401返回. 2.访问http://localhost:9000/test/prefix/hello/testCustomFilter/xujin?authToken=asdasdsddasadsadsadsdadsewew32rg","link":"/sc/gw/gw07/"},{"title":"Spring Cloud Eureka服务注册源码分析","text":"摘要:在上一篇中，介绍了Eureka的相关的知识，解释了Eureka为什么适合做服务发现和注册。接下来，在本篇文章将通过源码分析的方式，看一下Eureka是怎么work的。本章主要介绍Eureka的服务注册。那eureka client如何将本地服务的注册信息发送到远端的注册服务器eureka server上。通过下面的源码分析，看出Eureka Client的定时任务调用Eureka Server的REST接口，而Eureka接收到调用请求后会处理服务的注册以及Eureka Server中的数据同步的问题。 服务注册 服务注册，想必大家并不陌生，就是服务提供者启动的时候，把自己提供的服务信息，例如 服务名，IP，端口号，版本号等信息注册到注册中心，比如注册到ZK中。那eureka client如何将本地服务的注册信息发送到远端的注册服务器eureka server上。通过下面的源码分析，看出服务注册可以认为是Eureka client自己完成，不需要服务本身来关心。 Eureka Client的定时任务调用Eureka Server的提供接口实现思路其实也挺简单，在com.netflix.discovery.DiscoveryClient启动的时候，会初始化一个定时任务，定时的把本地的服务配置信息，即需要注册到远端的服务信息自动刷新到注册服务器上。首先看一下Eureka的代码，在spring-cloud-netflix-eureka-server工程中可以找到这个依赖eureka-client-1.4.11.jar查看代码可以看到，com.netflix.discovery.DiscoveryClient.java中的1240行可以看到Initializes all scheduled tasks，在1277行，可以看到InstanceInfoReplicator定时任务。 在DiscoveryClient中初始化一个InstanceInfoReplicator，其实里面封装了以定时任务。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475/** * Initializes all scheduled tasks. */ private void initScheduledTasks() { if (clientConfig.shouldFetchRegistry()) { // registry cache refresh timer int registryFetchIntervalSeconds = clientConfig.getRegistryFetchIntervalSeconds(); int expBackOffBound = clientConfig.getCacheRefreshExecutorExponentialBackOffBound(); scheduler.schedule( new TimedSupervisorTask( \"cacheRefresh\", scheduler, cacheRefreshExecutor, registryFetchIntervalSeconds, TimeUnit.SECONDS, expBackOffBound, new CacheRefreshThread() ), registryFetchIntervalSeconds, TimeUnit.SECONDS); } if (clientConfig.shouldRegisterWithEureka()) { int renewalIntervalInSecs = instanceInfo.getLeaseInfo().getRenewalIntervalInSecs(); int expBackOffBound = clientConfig.getHeartbeatExecutorExponentialBackOffBound(); logger.info(\"Starting heartbeat executor: \" + \"renew interval is: \" + renewalIntervalInSecs); // Heartbeat timer scheduler.schedule( new TimedSupervisorTask( \"heartbeat\", scheduler, heartbeatExecutor, renewalIntervalInSecs, TimeUnit.SECONDS, expBackOffBound, new HeartbeatThread() ), renewalIntervalInSecs, TimeUnit.SECONDS); // InstanceInfo replicator /**************************封装了定时任务**********************************/ instanceInfoReplicator = new InstanceInfoReplicator( this, instanceInfo, clientConfig.getInstanceInfoReplicationIntervalSeconds(), 2); // burstSize statusChangeListener = new ApplicationInfoManager.StatusChangeListener() { @Override public String getId() { return \"statusChangeListener\"; } @Override public void notify(StatusChangeEvent statusChangeEvent) { if (InstanceStatus.DOWN == statusChangeEvent.getStatus() || InstanceStatus.DOWN == statusChangeEvent.getPreviousStatus()) { // log at warn level if DOWN was involved logger.warn(\"Saw local status change event {}\", statusChangeEvent); } else { logger.info(\"Saw local status change event {}\", statusChangeEvent); } instanceInfoReplicator.onDemandUpdate(); } }; if (clientConfig.shouldOnDemandUpdateStatusChange()) { applicationInfoManager.registerStatusChangeListener(statusChangeListener); } //点击可以查看start方法 instanceInfoReplicator.start(clientConfig.getInitialInstanceInfoReplicationIntervalSeconds()); } else { logger.info(\"Not registering with Eureka server per configuration\"); } } 2.以initialDelayMs为间隔调用。1234567public void start(int initialDelayMs) { if (started.compareAndSet(false, true)) { instanceInfo.setIsDirty(); // for initial register Future next = scheduler.schedule(this, initialDelayMs, TimeUnit.SECONDS); scheduledPeriodicRef.set(next); }} 3.ScheduledExecutorService的task的具体业务定义在com.netflix.discovery.InstanceInfoReplicator.run()中，也就是InstanceInfoReplicator中的98-113行，可以看到调用了了client的register方法。1234567891011121314151617 public void run() { try { discoveryClient.refreshInstanceInfo(); Long dirtyTimestamp = instanceInfo.isDirtyWithTime(); if (dirtyTimestamp != null) { //客户端发送hhtp注册请求的真正入口 discoveryClient.register(); instanceInfo.unsetIsDirty(dirtyTimestamp); } } catch (Throwable t) { logger.warn(\"There was a problem with the instance info replicator\", t); } finally { Future next = scheduler.schedule(this, replicationIntervalSeconds, TimeUnit.SECONDS); scheduledPeriodicRef.set(next); }} 4.com.netflix.discovery.DiscoveryClient中的 register()方法，大概在811行。123456789101112131415161718/** * Register with the eureka service by making the appropriate REST call. */boolean register() throws Throwable { logger.info(PREFIX + appPathIdentifier + \": registering service...\"); EurekaHttpResponse&lt;Void&gt; httpResponse; try { //Eureka Client客户端，调用Eureka服务端的入口 httpResponse = eurekaTransport.registrationClient.register(instanceInfo); } catch (Exception e) { logger.warn(\"{} - registration failed {}\", PREFIX + appPathIdentifier, e.getMessage(), e); throw e; } if (logger.isInfoEnabled()) { logger.info(\"{} - registration status: {}\", PREFIX + appPathIdentifier, httpResponse.getStatusCode()); } return httpResponse.getStatusCode() == 204;} Eureka server端接到请求后的处理打开spring-cloud-netflix-eureka-server工程或spring-cloud-netflix-eureka-client过程，找到相应的maven依赖jar，如下图所示 1.Eureka server服务端请求入口ApplicationResource.java文件中第183行，如下所示，可以看出Eureka是通过http post的方式去服务注册1234567891011121314151617181920212223242526272829303132333435363738394041424344@POST @Consumes({\"application/json\", \"application/xml\"}) public Response addInstance(InstanceInfo info, @HeaderParam(PeerEurekaNode.HEADER_REPLICATION) String isReplication) { logger.debug(\"Registering instance {} (replication={})\", info.getId(), isReplication); // validate that the instanceinfo contains all the necessary required fields if (isBlank(info.getId())) { return Response.status(400).entity(\"Missing instanceId\").build(); } else if (isBlank(info.getHostName())) { return Response.status(400).entity(\"Missing hostname\").build(); } else if (isBlank(info.getAppName())) { return Response.status(400).entity(\"Missing appName\").build(); } else if (!appName.equals(info.getAppName())) { return Response.status(400).entity(\"Mismatched appName, expecting \" + appName + \" but was \" + info.getAppName()).build(); } else if (info.getDataCenterInfo() == null) { return Response.status(400).entity(\"Missing dataCenterInfo\").build(); } else if (info.getDataCenterInfo().getName() == null) { return Response.status(400).entity(\"Missing dataCenterInfo Name\").build(); } // handle cases where clients may be registering with bad DataCenterInfo with missing data DataCenterInfo dataCenterInfo = info.getDataCenterInfo(); if (dataCenterInfo instanceof UniqueIdentifier) { String dataCenterInfoId = ((UniqueIdentifier) dataCenterInfo).getId(); if (isBlank(dataCenterInfoId)) { boolean experimental = \"true\".equalsIgnoreCase(serverConfig.getExperimental(\"registration.validation.dataCenterInfoId\")); if (experimental) { String entity = \"DataCenterInfo of type \" + dataCenterInfo.getClass() + \" must contain a valid id\"; return Response.status(400).entity(entity).build(); } else if (dataCenterInfo instanceof AmazonInfo) { AmazonInfo amazonInfo = (AmazonInfo) dataCenterInfo; String effectiveId = amazonInfo.get(AmazonInfo.MetaDataKey.instanceId); if (effectiveId == null) { amazonInfo.getMetadata().put(AmazonInfo.MetaDataKey.instanceId.getName(), info.getId()); } } else { logger.warn(\"Registering DataCenterInfo of type {} without an appropriate id\", dataCenterInfo.getClass()); } } } //InstanceRegistry.java文件中的88行的405行register方法 registry.register(info, \"true\".equals(isReplication)); return Response.status(204).build(); // 204 to be backwards compatible } 2.如下图所示可以看到，从ApplicationResource.java怎么进入到PeerAwareInstanceRegistryImpl中的register方法InstanceRegistry.java文件中的88行，可以看到调用PeerAwareInstanceRegistryImpl中的405行register方法123456@Overridepublic void register(final InstanceInfo info, final boolean isReplication) { handleRegistration(info, resolveInstanceLeaseDuration(info), isReplication); //调用PeerAwareInstanceRegistryImpl中的405行register方法 super.register(info, isReplication); } 3.PeerAwareInstanceRegistryImpl中的405行register方法，代码如下所示。阅读方法上面的注释，就知道该方法是注册服务信息并把Eureka Server中的配置信息同步。执行注册的动作在com.netflix.eureka.registry.PeerAwareInstanceRegistryImpl.register(InstanceInfo info, boolean isReplication)中，具体代码如下所示： 12345678910111213141516171819202122/** * Registers the information about the {@link InstanceInfo} and replicates * this information to all peer eureka nodes. If this is replication event * from other replica nodes then it is not replicated. * * @param info * the {@link InstanceInfo} to be registered and replicated. * @param isReplication * true if this is a replication event from other replica nodes, * false otherwise. */ @Override public void register(final InstanceInfo info, final boolean isReplication) { int leaseDuration = Lease.DEFAULT_DURATION_IN_SECS; if (info.getLeaseInfo() != null &amp;&amp; info.getLeaseInfo().getDurationInSecs() &gt; 0) { leaseDuration = info.getLeaseInfo().getDurationInSecs(); } //调用父类方法注册 super.register(info, leaseDuration, isReplication); // 同步Eureka中的服务信息 replicateToPeers(Action.Register, info.getAppName(), info.getId(), info, null, isReplication); } 4.AbstractInstanceRegistry.java中192行，可以看到Eureka真正的服务注册实现的代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586/** * Registers a new instance with a given duration. * * @see com.netflix.eureka.lease.LeaseManager#register(java.lang.Object, int, boolean) */ public void register(InstanceInfo registrant, int leaseDuration, boolean isReplication) { try { read.lock(); Map&lt;String, Lease&lt;InstanceInfo&gt;&gt; gMap = registry.get(registrant.getAppName()); REGISTER.increment(isReplication); if (gMap == null) { final ConcurrentHashMap&lt;String, Lease&lt;InstanceInfo&gt;&gt; gNewMap = new ConcurrentHashMap&lt;String, Lease&lt;InstanceInfo&gt;&gt;(); gMap = registry.putIfAbsent(registrant.getAppName(), gNewMap); if (gMap == null) { gMap = gNewMap; } } Lease&lt;InstanceInfo&gt; existingLease = gMap.get(registrant.getId()); // Retain the last dirty timestamp without overwriting it, if there is already a lease if (existingLease != null &amp;&amp; (existingLease.getHolder() != null)) { Long existingLastDirtyTimestamp = existingLease.getHolder().getLastDirtyTimestamp(); Long registrationLastDirtyTimestamp = registrant.getLastDirtyTimestamp(); logger.debug(\"Existing lease found (existing={}, provided={}\", existingLastDirtyTimestamp, registrationLastDirtyTimestamp); if (existingLastDirtyTimestamp &gt; registrationLastDirtyTimestamp) { logger.warn(\"There is an existing lease and the existing lease's dirty timestamp {} is greater\" + \" than the one that is being registered {}\", existingLastDirtyTimestamp, registrationLastDirtyTimestamp); logger.warn(\"Using the existing instanceInfo instead of the new instanceInfo as the registrant\"); registrant = existingLease.getHolder(); } } else { // The lease does not exist and hence it is a new registration synchronized (lock) { if (this.expectedNumberOfRenewsPerMin &gt; 0) { // Since the client wants to cancel it, reduce the threshold // (1 // for 30 seconds, 2 for a minute) this.expectedNumberOfRenewsPerMin = this.expectedNumberOfRenewsPerMin + 2; this.numberOfRenewsPerMinThreshold = (int) (this.expectedNumberOfRenewsPerMin * serverConfig.getRenewalPercentThreshold()); } } logger.debug(\"No previous lease information found; it is new registration\"); } Lease&lt;InstanceInfo&gt; lease = new Lease&lt;InstanceInfo&gt;(registrant, leaseDuration); if (existingLease != null) { lease.setServiceUpTimestamp(existingLease.getServiceUpTimestamp()); } gMap.put(registrant.getId(), lease); synchronized (recentRegisteredQueue) { recentRegisteredQueue.add(new Pair&lt;Long, String&gt;( System.currentTimeMillis(), registrant.getAppName() + \"(\" + registrant.getId() + \")\")); } // This is where the initial state transfer of overridden status happens if (!InstanceStatus.UNKNOWN.equals(registrant.getOverriddenStatus())) { logger.debug(\"Found overridden status {} for instance {}. Checking to see if needs to be add to the \" + \"overrides\", registrant.getOverriddenStatus(), registrant.getId()); if (!overriddenInstanceStatusMap.containsKey(registrant.getId())) { logger.info(\"Not found overridden id {} and hence adding it\", registrant.getId()); overriddenInstanceStatusMap.put(registrant.getId(), registrant.getOverriddenStatus()); } } InstanceStatus overriddenStatusFromMap = overriddenInstanceStatusMap.get(registrant.getId()); if (overriddenStatusFromMap != null) { logger.info(\"Storing overridden status {} from map\", overriddenStatusFromMap); registrant.setOverriddenStatus(overriddenStatusFromMap); } // Set the status based on the overridden status rules InstanceStatus overriddenInstanceStatus = getOverriddenInstanceStatus(registrant, existingLease, isReplication); registrant.setStatusWithoutDirty(overriddenInstanceStatus); // If the lease is registered with UP status, set lease service up timestamp if (InstanceStatus.UP.equals(registrant.getStatus())) { lease.serviceUp(); } registrant.setActionType(ActionType.ADDED); recentlyChangedQueue.add(new RecentlyChangedItem(lease)); registrant.setLastUpdatedTimestamp(); invalidateCache(registrant.getAppName(), registrant.getVIPAddress(), registrant.getSecureVipAddress()); logger.info(\"Registered instance {}/{} with status {} (replication={})\", registrant.getAppName(), registrant.getId(), registrant.getStatus(), isReplication); } finally { read.unlock(); } } 说明:注册信息其实就是存储在一个 ConcurrentHashMap&lt;String, Map&lt;String, Lease&gt;&gt; registry的结构中。12private final ConcurrentHashMap&lt;String, Map&lt;String, Lease&lt;InstanceInfo&gt;&gt;&gt; registry = new ConcurrentHashMap&lt;String, Map&lt;String, Lease&lt;InstanceInfo&gt;&gt;&gt;(); 更多的细节源码内容，大家可以自己阅读。 总结ApplicationResource类接收Http服务请求，调用PeerAwareInstanceRegistryImpl的register方法，PeerAwareInstanceRegistryImpl完成服务注册后，调用replicateToPeers向其它Eureka Server节点（Peer）做状态同步。如下图所示。","link":"/sc/sc-eureka-register/"},{"title":"中小型互联网公司微服务实践-经验和教训","text":"上次写了一篇文章叫Spring Cloud在国内中小型公司能用起来吗?介绍了Spring Cloud是否能在中小公司使用起来，这篇文章是它的姊妹篇。其实我们在这条路上已经走了一年多，从16年初到现在。在使用Spring Cloud之前我们对微服务实践是没有太多的体会和经验的。从最初的开源软件云收藏来熟悉Spring Boot，到项目中的慢慢使用，再到最后全面拥抱Spring Cloud。这篇文章就给大家介绍一下我们使用Spring Boot/Cloud一年多的经验。 在开始之前我们先介绍一下几个概念，什么是微服务，它的特点是什么?Spring Boot/Cloud都做了那些事情？他们三者之间又有什么联系？ 技术背景什么是微服务微服务的概念源于2014年3月Martin Fowler所写的一篇文章“Microservices”。 微服务架构是一种架构模式，它提倡将单一应用程序划分成一组小的服务，服务之间互相协调、互相配合，为用户提供最终价值。每个服务运行在其独立的进程中，服务与服务间采用轻量级的通信机制互相沟通（通常是基于HTTP的RESTful API）。每个服务都围绕着具体业务进行构建，并且能够被独立地部署到生产环境、类生产环境等。另外，应尽量避免统一的、集中式的服务管理机制，对具体的一个服务而言，应根据业务上下文，选择合适的语言、工具对其进行构建。 微服务是一种架构风格，一个大型复杂软件应用由一个或多个微服务组成。系统中的各个微服务可被独立部署，各个微服务之间是松耦合的。每个微服务仅关注于完成一件任务并很好地完成该任务。在所有情况下，每个任务代表着一个小的业务能力。 微服务架构优势复杂度可控：在将应用分解的同时，规避了原本复杂度无止境的积累。每一个微服务专注于单一功能，并通过定义良好的接口清晰表述服务边界。由于体积小、复杂度低，每个微服务可由一个小规模开发团队完全掌控，易于保持高可维护性和开发效率。 独立部署：由于微服务具备独立的运行进程，所以每个微服务也可以独立部署。当某个微服务发生变更时无需编译、部署整个应用。由微服务组成的应用相当于具备一系列可并行的发布流程，使得发布更加高效，同时降低对生产环境所造成的风险，最终缩短应用交付周期。 技术选型灵活：微服务架构下，技术选型是去中心化的。每个团队可以根据自身服务的需求和行业发展的现状，自由选择最适合的技术栈。由于每个微服务相对简单，故需要对技术栈进行升级时所面临的风险就较低，甚至完全重构一个微服务也是可行的。 容错：当某一组建发生故障时，在单一进程的传统架构下，故障很有可能在进程内扩散，形成应用全局性的不可用。在微服务架构下，故障会被隔离在单个服务中。若设计良好，其他服务可通过重试、平稳退化等机制实现应用层面的容错。 扩展：单块架构应用也可以实现横向扩展，就是将整个应用完整的复制到不同的节点。当应用的不同组件在扩展需求上存在差异时，微服务架构便体现出其灵活性，因为每个服务可以根据实际需求独立进行扩展。 什么是Spring BootSpring Boot是由Pivotal团队提供的全新框架，其设计目的是用来简化新Spring应用的初始搭建以及开发过程。该框架使用了特定的方式来进行配置，从而使开发人员不再需要定义样板化的配置。用我的话来理解，就是Spring Boot其实不是什么新的框架，它默认配置了很多框架的使用方式，就像maven整合了所有的jar包，Spring Boot整合了所有的框架（不知道这样比喻是否合适）。 Spring Boot简化了基于Spring的应用开发，通过少量的代码就能创建一个独立的、产品级别的Spring应用。 Spring Boot为Spring平台及第三方库提供开箱即用的设置，这样你就可以有条不紊地开始。Spring Boot的核心思想就是约定大于配置，多数Spring Boot应用只需要很少的Spring配置。采用Spring Boot可以大大的简化你的开发模式，所有你想集成的常用框架，它都有对应的组件支持。 Spring Cloud都做了哪些事Spring Cloud是一系列框架的有序集合。它利用Spring Boot的开发便利性巧妙地简化了分布式系统基础设施的开发，如服务发现注册、配置中心、消息总线、负载均衡、断路器、数据监控等，都可以用Spring Boot的开发风格做到一键启动和部署。Spring并没有重复制造轮子，它只是将目前各家公司开发的比较成熟、经得起实际考验的服务框架组合起来，通过Spring Boot风格进行再封装屏蔽掉了复杂的配置和实现原理，最终给开发者留出了一套简单易懂、易部署和易维护的分布式系统开发工具包 以下为Spring Cloud的核心功能： 分布式/版本化配置 服务注册和发现 路由 服务和服务之间的调用 负载均衡 断路器 分布式消息传递 我们再来看一张图： 通过这张图，我们来了解一下各组件配置使用运行流程： 1、请求统一通过API网关（Zuul）来访问内部服务. 2、网关接收到请求后，从注册中心（Eureka）获取可用服务 3、由Ribbon进行均衡负载后，分发到后端具体实例 4、微服务之间通过Feign进行通信处理业务 5、Hystrix负责处理服务超时熔断 6、Turbine监控服务间的调用和熔断相关指标 Spring Cloud体系介绍上图只是Spring Cloud体系的一部分，Spring Cloud共集成了19个子项目，里面都包含一个或者多个第三方的组件或者框架！ Spring Cloud 工具框架 1、Spring Cloud Config 配置中心，利用git集中管理程序的配置。2、Spring Cloud Netflix 集成众多Netflix的开源软件3、Spring Cloud Bus 消息总线，利用分布式消息将服务和服务实例连接在一起，用于在一个集群中传播状态的变化4、Spring Cloud for Cloud Foundry 利用Pivotal Cloudfoundry集成你的应用程序5、Spring Cloud Cloud Foundry Service Broker 为建立管理云托管服务的服务代理提供了一个起点。6、Spring Cloud Cluster 基于Zookeeper, Redis, Hazelcast, Consul实现的领导选举和平民状态模式的抽象和实现。7、Spring Cloud Consul 基于Hashicorp Consul实现的服务发现和配置管理。8、Spring Cloud Security 在Zuul代理中为OAuth2 rest客户端和认证头转发提供负载均衡9、Spring Cloud Sleuth SpringCloud应用的分布式追踪系统，和Zipkin，HTrace，ELK兼容。10、Spring Cloud Data Flow 一个云本地程序和操作模型，组成数据微服务在一个结构化的平台上。11、Spring Cloud Stream 基于Redis,Rabbit,Kafka实现的消息微服务，简单声明模型用以在Spring Cloud应用中收发消息。12、Spring Cloud Stream App Starters 基于Spring Boot为外部系统提供spring的集成13、Spring Cloud Task 短生命周期的微服务，为SpringBooot应用简单声明添加功能和非功能特性。14、Spring Cloud Task App Starters15、Spring Cloud Zookeeper 服务发现和配置管理基于Apache Zookeeper。16、Spring Cloud for Amazon Web Services 快速和亚马逊网络服务集成。17、Spring Cloud Connectors 便于PaaS应用在各种平台上连接到后端像数据库和消息经纪服务。18、Spring Cloud Starters （项目已经终止并且在Angel.SR2后的版本和其他项目合并）19、Spring Cloud CLI 插件用Groovy快速的创建Spring Cloud组件应用。 当然这个数量还在一直增加… 三者之间的关系微服务是一种架构的理念，提出了微服务的设计原则，从理论为具体的技术落地提供了指导思想。Spring Boot是一套快速配置脚手架，可以基于Spring Boot快速开发单个微服务；Spring Cloud是一个基于Spring Boot实现的服务治理工具包；Spring Boot专注于快速、方便集成的单个微服务个体，Spring Cloud关注全局的服务治理框架。 Spring Boot/Cloud是微服务实践的最佳落地方案。 实战经历遇到问题，寻找方案2015年初的时候，因为公司业务的大量发展，我们开始对原有的业务进行拆分，新上的业务线也全部使用独立的项目来开发，项目和项目之间通过http接口进行访问。15年的业务发展非常迅速，项目数量也就相应急剧扩大，到了15底的时候项目达60多个，当项目数达到30几个的时候，其实我们就遇到了问题，经常某个项目因为扩展增加了新的IP地址，我们就需要被动的更新好几个相关的项目。服务越来越多，服务之间的调用关系也越来越复杂，有时候想画一张图来表示项目和项目之间的依赖关系，线条密密麻麻无法看清。网上有一张图可以表达我们的心情。 这个时候我们就想找一种方案，可以将我们这么多分布式的服务给管理起来，到网上进行了技术调研。我们发现有两款开源软件比较适合我们，一个是Dubbo，一个是Spring Cloud。 其实刚开始我们是走了一些弯路的。这两款框架我们当时都不熟悉，当时国内使用Spring Cloud进行开发的企业非常的少，我在网上也几乎没找到太多应用的案例。但是Dubbo当时在国内的使用还是挺普遍的，相关的资料各方面都比较完善。因此在公司扩展新业务线众筹平台的时候，技术选型就先定了Dubbo，因为也是全新的业务没有什么负担，这个项目我们大概开发了六个月投产，上线之初也遇到了一些问题，但最终还比较顺利。 在新业务线选型使用Dubbo的同时，我们也没有完全放弃Spring Cloud，我们抽出了一两名开发人员学习Spring Boot我也参与其中，为了验证Spring Boot是否可以到达实战的标准，我们在业余的时间使用Spring Boot开发了一款开源软件云收藏，经过这个项目的实战验证我们对Spring Boot就有了信心。最重要的是大家体会到使用Spring Boot的各种便利之后，就再也不想使用传统的方式来进行开发了。 但是还有一个问题，在选择了Spring Boot进行新业务开发的同时，并没有解决我们上面的那个问题，服务于服务直接调用仍然比较复杂和传统，这时候我们就开始研究Spring Cloud。因为大家在前期对Spring Boot有了足够的了解，因此学习Sprig Cloud就显得顺风顺水了。所以在使用Dubbo半年之后，我们又全面开始拥抱Spring Cloud。 为什么选择使用Spring Cloud而放弃了Dubbo可能大家会问，为什么选择了使用Dubbo之后，而又选择全面使用Spring Cloud呢？其中有几个原因： 1）从两个公司的背景来谈：Dubbo，是阿里巴巴服务化治理的核心框架，并被广泛应用于中国各互联网公司；Spring Cloud是大名鼎鼎的Spring家族的产品。阿里巴巴是一个商业公司，虽然也开源了很多的顶级的项目，但从整体战略上来讲，仍然是服务于自身的业务为主。Spring专注于企业级开源框架的研发，不论是在中国还是在世界上使用都非常广泛，开发出通用、开源、稳健的开源框架就是他们的主业。 2）从社区活跃度这个角度来对比，Dubbo虽然也是一个非常优秀的服务治理框架，并且在服务治理、灰度发布、流量分发这方面做的比Spring Cloud还好，除过当当网在基础上增加了rest支持外，已有两年多的时间几乎都没有任何更新了。在使用过程中出现问题，提交到github的Issue也少有回复。 相反Spring Cloud自从发展到现在，仍然在不断的高速发展，从github上提交代码的频度和发布版本的时间间隔就可以看出，现在Spring Cloud即将发布2.0版本，到了后期会更加完善和稳定。 3) 从整个大的平台架构来讲，dubbo框架只是专注于服务之间的治理，如果我们需要使用配置中心、分布式跟踪这些内容都需要自己去集成，这样无形中使用dubbo的难度就会增加。Spring Cloud几乎考虑了服务治理的方方面面，更有Spring Boot这个大将的支持，开发起来非常的便利和简单。 4）从技术发展的角度来讲，Dubbo刚出来的那会技术理念还是非常先进，解决了各大互联网公司服务治理的问题，中国的各中小公司也从中受益不少。经过了这么多年的发展，互联网行业也是涌现了更多先进的技术和理念，Dubbo一直停滞不前，自然有些掉队，有时候我个人也会感到有点可惜，如果Dubbo一直沿着当初的那个路线发展，并且延伸到周边，今天可能又是另一番景象了。 Spring 推出Spring Boot/Cloud也是因为自身的很多原因。Spring最初推崇的轻量级框架，随着不断的发展也越来越庞大，随着集成项目越来越多，配置文件也越来越混乱，慢慢的背离最初的理念。随着这么多年的发展，微服务、分布式链路跟踪等更多新的技术理念的出现，Spring急需一款框架来改善以前的开发模式，因此才会出现Spring Boot/Cloud项目，我们现在访问Spring官网，会发现Spring Boot和Spring Cloud已经放到首页最重点突出的三个项目中的前两个，可见Spring对这两个框架的重视程度。 总结一下，dubbo曾经确实很牛逼，但是Spring Cloud是站在近些年技术发展之上进行开发，因此更具技术代表性。 如何进行微服务架构演进当我们将所有的新业务都使用Spring Cloud这套架构之后，就会出现这样一个现象，公司的系统被分成了两部分，一部分是传统架构的项目，一部分是微服务架构的项目，如何让这两套配合起来使用就成为了关键，这时候Spring Cloud里面的一个关键组件解决了我们的问题，就是Zuul。在Spring Cloud架构体系内的所有微服务都通过Zuul来对外提供统一的访问入口，所有需要和微服务架构内部服务进行通讯的请求都走统一网关。如下图： 从上图可以看出我们对服务进行了分类，有四种：基础服务、业务服务、组合服务、前置服务。不同服务迁移的优先级不同 基础服务，是一些基础组件，与具体的业务无关。比如：短信服务、邮件服务。这里的服务最容易摘出来做微服务，也是我们第一优先级分离出来的服务。 业务服务，是一些垂直的业务系统，只处理单一的业务类型，比如：风控系统、积分系统、合同系统。这类服务职责比较单一，根据业务情况来选择是否迁移，比如：如果突然有需求对积分系统进行大优化，我们就趁机将积分系统进行改造，是我们的第二优先级分离出来的服务。 前置服务，前置服务一般为服务的接入或者输出服务，比如网站的前端服务、app的服务接口这类，这是我们第三优先级分离出来的服务。 组合服务，组合服务就是涉及到了具体的业务，比如买标过程，需要调用很多垂直的业务服务，这类的服务我们一般放到最后再进行微服务化架构来改造，因为这类服务最为复杂，除非涉及到大的业务逻辑变更，我们是不会轻易进行迁移。 在这四类服务之外，新上线的业务全部使用Sprng Boot/Cloud这套技术栈。就这样，我们从开源项目云收藏开始，上线几个Spring Boot项目，到现在公司绝大部分的项目都是在Spring Cloud这个架构体系中。 经验和教训架构演化的步骤 在确定使用Spring Boot/Cloud这套技术栈进行微服务改造之前，先梳理平台的服务，对不同的服务进行分类，以确认演化的节奏。 先让团队熟悉Spring Boot技术，并且优先在基础服务上进行技术改造，推动改动后的项目投产上线 当团队熟悉Spring Boot之后，再推进使用Spring Cloud对原有的项目进行改造。 在进行微服务改造过程中，优先应用于新业务系统，前期可以只是少量的项目进行了微服务化改造，随着大家对技术的熟悉度增加，可以加快加大微服务改造的范围 传统项目和微服务项目共存是一个很常见的情况，除非公司业务有大的变化，不建议直接迁移核心项目。 服务拆分原则服务拆分有以下几个原则和大家分享 横向拆分。按照不同的业务域进行拆分，例如订单、营销、风控、积分资源等。形成独立的业务领域微服务集群。 纵向拆分。把一个业务功能里的不同模块或者组件进行拆分。例如把公共组件拆分成独立的原子服务，下沉到底层，形成相对独立的原子服务层。这样一纵一横，就可以实现业务的服务化拆分。 要做好微服务的分层：梳理和抽取核心应用、公共应用，作为独立的服务下沉到核心和公共能力层，逐渐形成稳定的服务中心，使前端应用能更快速的响应多变的市场需求 服务拆分是越小越好吗？微服务的大与小是相对的。比如在初期，我们把交易拆分为一个微服务，但是随着业务量的增大，可能一个交易系统已经慢慢变得很大，并且并发流量也不小，为了支撑更多的交易量，我会把交易系统，拆分为订单服务、投标服务、转让服务等。因此微服务的拆分力度需与具体业务相结合，总的原则是服务内部高内聚，服务之间低耦合。 微服务vs传统开发使用微服务有一段时间了，这种开发模式和传统的开发模式对比，有很大的不同。 分工不同，以前我们可能是一个一个模块，现在可能是一人一个系统。 架构不同，服务的拆分是一个技术含量很高的问题，拆分是否合理对以后发展影响巨大。 部署方式不同，如果还像以前一样部署估计累死了，自动化运维不可不上。 容灾不同，好的微服务可以隔离故障避免服务整体down掉，坏的微服务设计仍然可以因为一个子服务出现问题导致连锁反应。 给数据库带来的挑战每个微服务都有自己独立的数据库，那么后台管理的联合查询怎么处理？这应该是大家会普遍遇到的一个问题，有三种处理方案。 1）严格按照微服务的划分来做，微服务相互独立，各微服务数据库也独立，后台需要展示数据时，调用各微服务的接口来获取对应的数据，再进行数据处理后展示出来，这是标准的用法，也是最麻烦的用法。 2) 将业务高度相关的表放到一个库中，将业务关系不是很紧密的表严格按照微服务模式来拆分，这样既可以使用微服务，也避免了数据库分散导致后台系统统计功能难以实现，是一个折中的方案。 3）数据库严格按照微服务的要求来切分，以满足业务高并发，实时或者准实时将各微服务数据库数据同步到NoSQL数据库中，在同步的过程中进行数据清洗，用来满足后台业务系统的使用，推荐使用MongoDB、HBase等。 三种方案在不同的公司我都使用过，第一种方案适合业务较为简单的小公司；第二种方案，适合在原有系统之上，慢慢演化为微服务架构的公司；第三种适合大型高并发的互联网公司。 微服务的经验和建议1、建议尽量不要使用Jsp，页面开发推荐使用Thymeleaf。Web项目建议独立部署Tomcat，不要使用内嵌的Tomcat，内嵌Tomcat部署Jsp项目会偶现龟速访问的情况。 2、服务编排是个好东西，主要的作用是减少项目中的相互依赖。比如现在有项目a调用项目b，项目b调用项目c…一直到h，是一个调用链，那么项目上线的时候需要先更新最底层的h再更新g…更新c更新b最后是更新项目a。这只是这一个调用链，在复杂的业务中有非常多的调用，如果要记住每一个调用链对开发运维人员来说就是灾难。 有这样一个好办法可以尽量的减少项目的相互依赖，就是服务编排，一个核心的业务处理项目，负责和各个微服务打交道。比如之前是a调用b，b掉用c，c调用d，现在统一在一个核心项目W中来处理，W服务使用a的时候去调用b，使用b的时候W去调用c，举个例子：在第三方支付业务中，有一个核心支付项目是服务编排，负责处理支付的业务逻辑，W项目使用商户信息的时候就去调用“商户系统”，需要校验设备的时候就去调用“终端系统”，需要风控的时候就调用“风控系统”，各个项目需要的依赖参数都由W来做主控。以后项目部署的时候，只需要最后启动服务编排项目即可。 3、不要为了追求技术而追求技术，确定进行微服务架构改造之前，需要考虑以下几方面的因素：1）团队的技术人员是否已经具备相关技术基础。2）公司业务是否适合进行微服务化改造，并不是所有的平台都适合进行微服务化改造，比如：传统行业有很多复杂垂直的业务系统。3）Spring Cloud生态的技术有很多，并不是每一种技术方案都需要用上，适合自己的才是最好的。 总结Spring Cloud对于中小型互联网公司来说是一种福音，因为这类公司往往没有实力或者没有足够的资金投入去开发自己的分布式系统基础设施，使用Spring Cloud一站式解决方案能在从容应对业务发展的同时大大减少开发成本。同时，随着近几年微服务架构和Docker容器概念的火爆，也会让Spring Cloud在未来越来越“云”化的软件开发风格中立有一席之地，尤其是在目前五花八门的分布式解决方案中提供了标准化的、全站式的技术方案，意义可能会堪比当前Servlet规范的诞生，有效推进服务端软件系统技术水平的进步。 作者：纯洁的微笑出处：http://www.ityouknow.com/版权所有，欢迎保留原文链接进行转载：)","link":"/sc/sc-zq/"},{"title":"爱油科技基于SpringCloud的微服务实践","text":"爱油科技基于SpringCloud的微服务实践个人简介刘思贤（微博@starlight36），爱油科技架构师、PMP。主要负责业务平台架构设计，DevOps实施和研发过程持续改进等，关注领域驱动设计与微服务、建设高效团队和工程师文化培养。 摘要本次分享主要介绍了爱油科技基于Docker和Spring Cloud将整体业务微服务化的一些实践经验，主要包括： 微服务架构的分层和框架选型 服务发现和配置管理 服务集成和服务质量保证 基于领域驱动设计 实施DevOps 从单体应用到微服务 单体应用优点 小而美，结构简单易于开发实现 部署门槛低，单个Jar包或者网站打包即可部署 可快速实现多实例部署 缺点 随着业务发展更多的需求被塞进系统，体系结构逐渐被侵蚀反应堆林立 被技术绑架，难以为特定业务选择平台或框架，尽管可能有更适宜的技术做这件事 协作困难，不同业务的团队在一个系统上进行开发相互冲突 难以扩展，为了热点业务而不得不同时扩容全部业务，或者难以继续扩容 架构拆分拆分：按行分层，按列分业务 在我们的微服务体系中，所有的服务被划分为了三个层次： 基础设施层：为所有业务提供基础设施，包括服务注册、数据库和NoSQL、对象存储、消息队列等基础设施服务，这一层通常是由成熟组件、第三方服务组成。 业务服务层：业务微服务，根据业务领域每个子域单独一个微服务，分而治之。 接入层：直接对外提供服务，例如网站、API接口等。接入层不包含复杂的业务逻辑，只做呈现和转换。 项目中我们主要关注业务服务层和接入层，对于没有足够运维力量的我们，基础设施使用云服务是省事省力的选择。 业务服务层我们给他起名叫作Epic，接入层我们起名Rune，建立之初便订立了如下原则： 业务逻辑层内所有服务完全对等，可相互调用 业务逻辑层所有服务必须是无状态的 接入层所有服务可调用业务逻辑层所有服务，但接入层内部同层服务之间不可调用 接入层不能包含业务逻辑代码 所有微服务必须运行在Docker容器里 业务逻辑层我们主要使用使用Java，接入层我们主要使用PHP或Node。后来随着团队的成长，逐步将接入层全部迁移至Node。 框架选型爱油科技作为一家成品油行业的初创型公司，需要面对非常复杂的业务场景，而且随着业务的发展，变化的可能性非常高。所以在微服务架构设计之初，我们就期望我们的微服务体系能： 不绑定到特定的框架、语言 服务最好是Restful风格 足够简单，容易落地，将来能扩展 和Docker相容性好 目前常见的微服务相关框架： Dubbo、DubboX Spring Cloud Motan Thrift、gRPC 这些常见的框架中，Dubbo几乎是唯一能被称作全栈微服务框架的“框架”，它包含了微服务所需的几乎所有内容，而DubboX作为它的增强，增加了REST支持。 它优点很多，例如： 全栈，服务治理的所有问题几乎都有现成答案 可靠，经过阿里实践检验的产品 实践多，社区有许多成功应用Dubbo的经验 不过遗憾的是： 已经停止维护 不利于裁剪使用 “过于Java”，与其他语言相容性一般 Motan是微博平台微服务框架，承载了微博平台千亿次调用业务。 优点是： 性能好，源自于微博对高并发和实时性的要求 模块化，结构简单，易于使用 与其他语言相容性好 不过： 为“短平快”业务而生，即业务简单，追求高性能高并发。 Apache Thrift、gRPC等虽然优秀，并不能算作微服务框架，自身并不包括服务发现等必要特性。 如果说微服务少不了Java，那么一定少不了Spring，如果说少不了Spring，那么微服务“官配”Spring Cloud当然是值得斟酌的选择。 优点： “不做生产者，只做搬运工” 简单方便，几乎零配置 模块化，松散耦合，按需取用 社区背靠Spring大树 不足： 轻量并非全栈 没解决RPC的问题 实践案例少 根据我们的目标，我们最终选择了Spring Cloud作为我们的微服务框架，原因有4点： 虽然Dubbo基础设施更加完善，但结构复杂，我们很难吃得下，容易出坑 基于Apache Thrift和gRPC自研，投入产出比很差 不想过早引入RPC以防滥用，Restful风格本身就是一种约束。 做选择时，Motan还没有发布 Spring CloudSpring Cloud是一个集成框架，将开源社区中的框架集成到Spring体系下，几个重要的家族项目： spring-boot，一改Java应用程序运行难、部署难，甚至无需Web容器，只依赖JRE即可 spring-cloud-netflix，集成Netflix优秀的组件Eureka、Hystrix、Ribbon、Zuul，提供服务发现、限流、客户端负载均衡和API网关等特性支持 spring-cloud-config，微服务配置管理 spring-cloud-consul，集成Consul支持 服务发现和配置管理Spring Cloud Netflix提供了Eureka服务注册的集成支持，不过没选它是因为： 更适合纯Java平台的服务注册和发现 仍然需要其他分布式KV服务做后端，没解决我们的核心问题 Docker作为支撑平台的重要技术之一，Consul几乎也是我们的必选服务。因此我们觉得一事不烦二主，理所应当的Consul成为我们的服务注册中心。 Consul的优势： 使用Raft一致性算法，能保证分布式集群内各节点状态一致 提供服务注册、服务发现、服务状态检查 支持HTTP、DNS等协议 提供分布式一致性KV存储 也就是说，Consul可以一次性解决我们对服务注册发现、配置管理的需求，而且长期来看也更适合跟不同平台的系统，包括和Docker调度系统进行整合。 最初打算自己开发一个Consul和Spring Cloud整合的组件，不过幸运的是，我们做出这个决定的时候，spring-cloud-consul刚刚发布了，我们可以拿来即用，这节约了很多的工作量。 因此借助Consul和spring-cloud-consul，我们实现了 服务注册，引用了srping-cloud-consul的项目可以自动注册服务，也可以通过HTTP接口手动注册，Docker容器也可以自动注册 服务健康状态检查，Consul可以自动维护健康的服务列表 异构系统可以直接通过Consul的HTTP接口拉取并监视服务列表，或者直接使用DNS解析服务 通过分布式一致性KV存储进行微服务的配置下发 为一些业务提供选主和分布式锁服务 当然也踩到了一些坑： spring-cloud-consul服务注册时不能正确选判本地ip地址。对于我们的环境来说，无论是在服务器上，还是Docker容器里，都有多个网络接口同时存在，而spring-cloud-consul在注册服务时，需要先选判本地服务的IP地址，判断逻辑是以第一个非本地地址为准，常常错判。因此在容器中我们利用entrypoint脚本获取再通过环境变量强制指定。 12345678910111213141516171819202122#!/usr/bin/env bashset -e# If service runs as Rancher service, auto set advertise ip address# from Rancher metadata service.if [ -n \"$RUN_IN_RANCHER\" ]; then echo \"Waiting for ip address...\" # Waiting for ip address sleep 5 RANCHER_MS_BASE=http://rancher-metadata/2015-12-19 PRIMARY_IP=`curl -sSL $RANCHER_MS_BASE/self/container/primary_ip` SERVICE_INDEX=`curl -sSL $RANCHER_MS_BASE/self/container/service_index` if [ -n \"$PRIMARY_IP\" ]; then export SPRING_CLOUD_CONSUL_DISCOVERY_HOSTNAME=$PRIMARY_IP fi echo \"Starting service #${SERVICE_INDEX-1} at $PRIMARY_IP.\"fiexec \"$@\" 我们的容器运行在Rancher中，所以可以利用Rancher的metadata服务来获取容器的IP地址，再通过SPRING_CLOUD_CONSUL_DISCOVERY_HOSTNAME环境变量来设置服务发现的注册地址。基于其他容器调度平台也会很相似。 另外一些服务中内置了定时调度任务等，多实例启动时需要单节点运行调度任务。通过Consul的分布式锁服务，我们可以让获取到锁的节点启用调度任务，没获取到的节点等待获取锁。 服务集成为了方便开发人员使用，微服务框架应当简单容易使用。对于很多微服务框架和RPC框架来说，都提供了很好的机制。在Spring Cloud中通过OpenFeign实现微服务之间的快速集成： 服务方声明一个Restful的服务接口，和普通的Spring MVC控制器几乎别无二致： 1234567891011121314@RestController@RequestMapping(\"/users\")public class UserResource { @RequestMapping(value = \"{id}\", method = RequestMethod.GET, produces = \"application/json\") public UserRepresentation findOne(@PathVariable(\"id\") String id) { User user = this.userRepository.findByUserId(new UserId(id)); if (user == null || user.getDeleted()) { throw new NotFoundException(\"指定ID的用户不存在或者已被删除。\"); } return new UserRepresentation(user); }} 客户方使用一个微服务接口，只需要定义一个接口： 1234567@FeignClient(\"epic-member-microservice\")public interface UserClient { @Override @RequestMapping(value = \"/users/{id}\", method = RequestMethod.GET, produces = \"application/json\") User findOne(@PathVariable(\"id\") String id);} 在需要使用UserClient的Bean中，直接注入UserClient类型即可。事实上，UserClient和相关VO类，可以直接作为公共接口封装在公共项目中，供任意需要使用的微服务引用，服务方Restful Controller直接实现这一接口即可。 OpenFeign提供了这种简单的方式来使用Restful服务，这大大降低了进行接口调用的复杂程度。 对于错误的处理，我们使用HTTP状态码作为错误标识，并做了如下规定： 4xx用来表示由于客户方参数错误、状态不正确、没有权限、操作冲突等种种原因导致的业务错误。 5xx用来表示由于服务方系统异常、无法服务等原因服务不可用的错误。 对于服务器端，只需要在一个异常类上添加注解，即可指定该异常的HTTP响应状态码，例如： 123456789101112131415@ResponseStatus(HttpStatus.NOT_FOUND)public class NotFoundException extends RuntimeException { public NotFoundException() { super(\"查找的资源不存在或者已被删除。\"); } public NotFoundException(String message) { super(message); } public NotFoundException(String message, Throwable cause) { super(message, cause); }} 对于客户端我们实现了自己的FeignClientExceptionErrorDecoder来将请求异常转换为对于的异常类，示例如下： 123456789101112131415161718192021222324252627@Componentpublic class FeignClientExceptionErrorDecoder implements ErrorDecoder { private final ErrorDecoder delegate = new ErrorDecoder.Default(); @Override public Exception decode(String methodKey, Response response) { // Only decode 4xx errors. if (response.status() &gt;= 500) { return delegate.decode(methodKey, response); } // Response content type must be json if (response.headers().getOrDefault(\"Content-Type\", Lists.newArrayList()).stream() .filter(s -&gt; s.toLowerCase().contains(\"json\")).count() &gt; 0) { try { String body = Util.toString(response.body().asReader()); // 转换并返回异常对象 ... } catch (IOException ex) { throw new RuntimeException(\"Failed to process response body.\", ex); } } return delegate.decode(methodKey, response); }} 需要注意的是，decode方法返回的4xx状态码异常应当是HystrixBadRequestException的子类对象，原因在于，我们把4xx异常视作业务异常，而不是由于故障导致的异常，所以不应当被Hystrix计算为失败请求，并引发断路器动作，这一点非常重要。 在UserClient.findOne方法的调用代码中，即可直接捕获相应的异常了： 12345try { User user = this.userClient.findOne(new UserId(id));} catch(NotFoundException ex) { ...} 通过OpenFeign，我们大大降低了Restful接口进行服务集成的难度，几乎做到了无额外工作量的服务集成。 服务质量保证微服务架构下，由于调用需要跨系统进行远程操作，各微服务独立运维，所以在设计架构时还必须考虑伸缩性和容错性，具体地说主要包括以下几点要求： 服务实例可以平滑地加入、移除 流量可以均匀地分布在不同的实例上 接口应当资源隔离，防止因为个别接口调用时间过长导致线程池被占满而导致整个服务不可用 能支持接口降级并隔离故障节点，防止集群雪崩 服务能进行平滑升级 Spring Cloud中内置的spring-cloud-netflix的其他组件为我们提供了很好的解决方案： Hystrix - 实现了断路器模式，帮助控流和降级，防止集群雪崩，就像汽车的避震器 Ribbon - 提供了客户端负载均衡器 Zuul - API网关模式，帮助实现接口的路由、认证等 下面主要介绍一下，各个组件在进行服务质量保证中是如何发挥作用的。 ConsulConsul中注册了一致性的可用的服务列表，并通过健康检查保证这些实例都是存活的，服务注册和检查的过程如下： 服务启动完成，服务端口开始监听时，spring-cloud-consul通过Consul接口发起服务注册，将服务的/health作为健康检查端点； Consul每隔5秒访问/health，检查当前微服务是否为UP状态； /health将会收集微服务内各个仪表收集上来的状态数据，主要包括数据库、消息队列是否连通等； 如果为UP状态，则微服务实例被标记为健康可用，否则被标记成失败； 当服务关闭时，先从Consul中取消服务注册，再优雅停机。 这样能够保证Consul中列出的所有微服务状态都是健康可用的，各个微服务会监视微服务实例列表，自动同步更新他们。 HystrixHystrix提供了断路器模式的实现，主要在三个方面可以说明： 图片来自Hystrix项目文档 首先Hystrix提供了降级方法，断路器开启时，操作请求会快速失败不再向后投递，直接调用fallback方法来返回操作；当操作失败、被拒或者超时后，也会直接调用fallback方法返回操作。这可以保证在系统过载时，能有后备方案来返回一个操作，或者优雅的提示错误信息。断路器的存在能让故障业务被隔离，防止过载的流量涌入打死后端数据库等。 然后是基于请求数据统计的断路开关，在Hystrix中维护一个请求统计了列表（默认最多10条），列表中的每一项是一个桶。每个桶记录了在这个桶的时间范围内（默认是1秒），请求的成功数、失败数、超时数、被拒数。其中当失败请求的比例高于某一值时，将会触发断路器工作。 最后是不同的请求命令（HystrixCommand）可以使用彼此隔离的资源池，不会发生相互的挤占。在Hystrix中提供了两种隔离机制，包括线程池和信号量。线程池模式下，通过线程池的大小来限制同时占用资源的请求命令数目；信号量模式下通过控制进入临界区的操作数目来达到限流的目的。 这里包括了Hystrix的一些重要参数的配置项： 参数 说明 circuitBreaker.requestVolumeThreshold 至少在一个统计窗口内有多少个请求后，才执行断路器的开关，默认20 circuitBreaker.sleepWindowInMilliseconds 断路器触发后多久后才进行下一次判定，默认5000毫秒 circuitBreaker.errorThresholdPercentage 一个统计窗口内百分之多少的请求失败才触发熔断，默认是50% execution.isolation.strategy 运行隔离策略，支持Thread，Semaphore，前者通过线程池来控制同时运行的命令，后者通过信号来控制，默认是Thread execution.isolation.thread.interruptOnTimeout 命令执行的超时时间，默认1000毫秒 coreSize 线程池大小，默认10 keepAliveTimeMinutes 线程存活时间，默认为1分钟 maxQueueSize 最大队列长度，-1使用SynchronousQueue，默认-1。 queueSizeRejectionThreshold 允许队列堆积的最大数量 RibbonRibbon使用Consul提供的服务实例列表，可以通过服务名选取一个后端服务实例连接，并保证后端流量均匀分布。spring-cloud-netflix整合了OpenFeign、Hystrix和Ribbon的负载均衡器，整个调用过程如下（返回值路径已经省略）： 在这个过程中，各个组件扮演的角色如下： Feign作为客户端工厂，负责生成客户端对象，请求和应答的编解码 Hystrix提供限流、断路器、降级、数据统计 Ribbon提供负载均衡器 Feign负责提供客户端接口收调用，把发起请求操作（包括编码、解码和请求数据）封装成一个Hystrix命令，这个命令包裹的请求对象，会被Ribbon的负载均衡器处理，按照负载均衡策略选择一个主机，然后交给请求对象绑定的HTTP客户端对象发请求，响应成功或者不成功的结果，返回给Hystrix。 spring-cloud-netflix中默认使用了Ribbon的ZoneAwareLoadBalancer负载均衡器，它的负载均衡策略的核心指标是平均活跃请求数（Average Active Requests）。ZoneAwareLoadBalancer会拉取所有当前可用的服务器列表，然后将目前由于种种原因（比如网络异常）响应过慢的实例暂时从可用服务实例列表中移除，这样的机制可以保证故障实例被隔离，以免继续向其发送流量导致集群状态进一步恶化。不过由于目前spring-cloud-consul还不支持通过consul来指定服务实例的所在区，我们正在努力将这一功能完善。除了选区策略外，Ribbon中还提供了其他的负载均衡器，也可以自定义合适的负载均衡器。 总的来看，spring-cloud-netflix和Ribbon中提供了基本的负载均衡策略，对于我们来说已经足够用了。但实践中，如果需要进行灰度发布或者需要进行流量压测，目前来看还很难直接实现。而这些特性在Dubbo则开箱即用。 ZuulZuul为使用Java语言的接入层服务提供API网关服务，既可以根据配置反向代理指定的接口，也可以根据服务发现自动配置。Zuul提供了类似于iptables的处理机制，来帮助我们实现验证权鉴、日志等，请求工作流如下所示： 图片来自Zuul官方文档。 使用Zuul进行反向代理时，同样会走与OpenFeign类似的请求过程，确保API的调用过程也能通过Hystrix、Ribbon提供的降级、控流机制。 Hystrix DashboardHystrix会统计每个请求操作的情况来帮助控制断路器，这些数据是可以暴露出来供监控系统热点。Hystrix Dashboard可以将当前接口调用的情况以图形形式展示出来： 图片来自Hystrix Dashboard官方示例 Hystrix Dashboard既可以集成在其他项目中，也可以独立运行。我们直接使用Docker启动一个Hystrix Dashboard服务即可： 1docker run --rm -ti -p 7979:7979 kennedyoliveira/hystrix-dashboard 为了实现能对整个微服务集群的接口调用情况汇总，可以使用spring-cloud-netflix-turbine来将整个集群的调用情况汇集起来，供Hystrix Dashboard展示。 日志监控微服务的日志直接输出到标准输出/标准错误中，再由Docker通过syslog日志驱动将日志写入至节点机器机的rsyslog中。rsyslog在本地暂存并转发至日志中心节点的Logstash中，既归档存储，又通过ElasticSearch进行索引，日志可以通过Kibana展示报表。 在rsyslog的日志收集时，需要将容器信息和镜像信息加入到tag中，通过Docker启动参数来进行配置： 1--log-driver syslog --log-opt tag=&quot;{{.ImageName}}/{{.Name}}/{{.ID}}&quot; 不过rsyslog默认只允许tag不超过32个字符，这显然是不够用的，所以我们自定义了日志模板： 1template (name=&quot;LongTagForwardFormat&quot; type=&quot;string&quot; string=&quot;&lt;%PRI%&gt;%TIMESTAMP:::date-rfc3339% %HOSTNAME% %syslogtag%%msg:::sp-if-no-1st-sp%%msg%&quot;) 在实际的使用过程中发现，当主机内存负载比较高时，rsyslog会发生日志无法收集的情况，报日志数据文件损坏。后来在Redhat官方找到了相关的问题，确认是rsyslog中的一个Bug导致的，当开启日志压缩时会出现这个问题，我们选择暂时把它禁用掉。 领域驱动设计我们使用领域驱动设计（DDD）的方法来构建微服务，因为微服务架构和DDD有一种天然的契合。把所有业务划分成若干个子领域，有强内在关联关系的领域（界限上下文）应当被放在一起作为一个微服务。最后形成了界限上下文-工作团队-微服务一一对应的关系： 身份与访问 - 团队A - 成员微服务 商品与促销 - 团队B - 商品微服务 订单交易 - 团队C - 交易微服务 … 微服务设计在设计单个微服务（Epic层的微服务）时，我们这样做： 使用OOD方法对业务进行领域建模，领域模型应当是充血模型 领域服务帮助完成多个领域对象协作 事件驱动，提供领域事件，供内部或者其他微服务使用 依赖倒置，在适配器接口中实现和框架、组件、SDK的整合 这给我们带来了显著的好处： 服务开发时关注于业务，边界合理清晰 容易直接对领域模型进行单元测试 不依赖特定组件或者平台 事务问题从单体应用迁移到微服务架构时，不得不面临的问题之一就是事务。在单体应用时代，所有业务共享同一个数据库，一次请求操作可放置在同一个数据库事务中；在微服务架构下，这件事变得非常困难。然而事务问题不可避免，非常关键。 解决事务问题时，最先想到的解决方法通常是分布式事务。分布式事务在传统系统中应用的比较广泛，主要基于两阶段提交的方式实现。然而分布式事务在微服务架构中可行性并不高，主要基于这些考虑： 分布式事务需要事务管理器，对于不同语言平台来说，几乎没有有一致的实现来进行事务管理； 并非所有的持久化基施都提供完整ACID的事务，比如现在广泛使用的NoSQL； 分布式事务存在性能问题。 根据CAP理论，分布式系统不可兼得一致性、可用性、分区容错性（可靠性）三者，对于微服务架构来讲，我们通常会保证可用性、容错性，牺牲一部分一致性，追求最终一致性。所以对于微服务架构来说，使用分布式事务来解决事务问题无论是从成本还是收益上来看，都不划算。 对微服务系统来说解决事务问题，CQRS+Event Sourcing是更好的选择。 CQRS是命令和查询职责分离的缩写。CQRS的核心观点是，把操作分为修改状态的命令（Command），和返回数据的查询（Query），前者对应于“写”的操作，不能返回数据，后者对应于“读”的操作，不造成任何影响，由此领域模型被一分为二，分而治之。 Event Sourcing通常被翻译成事件溯源，简单的来说就是某一对象的当前状态，是由一系列的事件叠加后产生的，存储这些事件即可通过重放获得对象在任一时间节点上的状态。 通过CQRS+Event Sourcing，我们很容易获得最终一致性，例如对于一个跨系统的交易过程而言： 用户在交易微服务提交下单命令，产生领域事件PlaceOrderEvent，订单状态PENDING； 支付微服务收到领域事件进行扣款，扣款成功产生领域事件PaidEvent； 交易微服务收到领域事件PaidEvent，将订单标记为CREATED； 若支付微服务发现额度不足扣款失败，产生领域事件InsufficientEvent，交易微服务消费将订单标记为CANCELED。 我们只要保证领域事件能被持久化，那么即使出现网络延迟或部分系统失效，我们也能保证最终一致性。 实践上，我们利用Spring从4.2版本开始支持的自定义应用事件机制将本地事务和事件投递结合起来进行： 领域内业务过程会产生领域事件，通过Spring的应用事件机制进行应用内投递； 监听相应的领域事件，在事务提交前投递至消息队列； 以上全都没有异常发生，则本地事务提交，如果出现异常，本地事务回滚。 一些小经验 使用Spring Configured实现非Spring Bean的依赖注入（自己new的对象也可以注入了，对充血模型非常有用） 使用Swagger UI实现自文档的微服务，写好接口即有文档，即可调试 DevOps到目前为止我们已经有数十个微服务运行于线上了，微服务数目甚至多过了团队人数。如果没有DevOps支持，运维这些微服务将是一场灾难。我们使用Docker镜像作为微服务交付的标准件： Gitlab管理团队项目代码 Gitlab-CI提供构建打包，大家提交的项目都要构建并跑通测试 使用Rancher作为Docker调度平台，Merge后RC分支自动部署 测试通过后统一上线发布 由于时间所限，这里就不展开赘述了。 永不完美基于spring-cloud-consul的配置管理仍然需要完善，对于大规模应用的环境中，配置的版本控制、灰度、回滚等非常重要。SpringCloud提供了一个核，但是具体的使用还要结合场景、需求和环境等，再做一些工作。 对于非JVM语言的微服务和基于SpringCloud的微服务如何协同治理，这一问题仍然值得探索。包括像与Docker编排平台，特别是与Mesos协同进行伸缩的服务治理，还需要更多的实践来支持。 总结 是否选用微服务架构，应当根据业务实际情况进行判断，切勿跟风为了微服务而微服务； 目前来看还没有微服务全栈框架，Spring Cloud也未必是最优方案，技术选型还是应当务实； 微服务架构下，对于业务的理解拆分、领域建模等提出了更高的要求，相比框架，它们才是微服务架构的基石； DevOps是微服务实践中的重要一环，不容小视。","link":"/sc/sc-fx1/"},{"title":"快速使用Spring Cloud Feign作为客户端调用服务提供者","text":"前言 在使用Spring Cloud开发微服务应用时中，各个微服务服务提供者都是以HTTP接口的形式对外提供服务，因此服务消费者在调用服务提供者时，通过HTTP Client的方式访问。当然我们可以使用JDK原生的URLConnection、Apache的Http Client、Netty的异步HTTP Client, Spring的RestTemplate去实现服务间的调用。Spring Cloud对Fegin进行了增强，使Fegin支持了Spring MVC的注解，并整合了Ribbon和Eureka，从而让Fegin的使用更加方便。 Feign简介Feign是一种声明式、模板化的HTTP客户端。在Spring Cloud中使用Feign, 可以做到使用HTTP请求远程服务时能就像调用本地方法一样的体验，开发者完全感知不到这是远程方法，更感知不到这是个HTTP请求。Feign的Github网址,比如：Feign具有如下特性： 可插拔的注解支持，包括Feign注解和JAX-RS注解 支持可插拔的HTTP编码器和解码器 支持Hystrix和它的Fallback 支持Ribbon的负载均衡 支持HTTP请求和响应的压缩 Feign是一个声明式的Web Service客户端，它的目的就是让Web Service调用更加简单。它整合了Ribbon和Hystrix，从而不再需要显式地使用这两个组件。Feign还提供了HTTP请求的模板，通过编写简单的接口和注解，就可以定义好HTTP请求的参数、格式、地址等信息。接下来，Feign会完全代理HTTP的请求，我们只需要像调用方法一样调用它就可以完成服务请求。Feign 示例工程 链接：https://github.com/SoftwareKing/spring-cloud-study/tree/master/sc-feign-first 本文最终修改时间：2017-05-20 18:47:23，为了解决问题1和2最终使用版本:Spring Boot的版本为1.5.3.RELEASE，Spring Cloud版本为Dalston.RELEASE 服务消费者中sc-feign-first-consumer的Feign的定义为了让Feign知道在调用方法时应该向哪个地址发请求以及请求需要带哪些参数，我们需要定义一个接口： 123456789101112131415package org.xujin.sc.feign.user.service;import org.springframework.cloud.netflix.feign.FeignClient;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestMethod;import org.xujin.sc.feign.user.model.OrderModel;@FeignClient(name = \"sc-feign-first-provider\")//【A】public interface UserFeignService {@RequestMapping(value = \"/sc/order/{id}\", method = RequestMethod.GET)//【B】public OrderModel findOrderById(@PathVariable(\"id\") Long id); //【C】} A: @FeignClient用于通知Feign组件对该接口进行代理(不需要编写接口实现)，使用者可直接通过@Autowired注入，如下代码所示。 123 // 注入服务提供者,远程的Http服务@Autowiredprivate UserFeignService userFeignService; B: @RequestMapping表示在调用该方法时需要向/sc/order/{id}发送GET请求。 C: @PathVariable与SpringMVC中对应注解含义相同 服务消费者中Feign的使用123456789101112131415161718192021222324252627282930package org.xujin.sc.feign.user.controller;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RestController;import org.xujin.sc.feign.user.model.OrderModel;import org.xujin.sc.feign.user.service.UserFeignService;/** * UserController * @author xujin */@RestControllerpublic class UserController { private static final Logger logger = LoggerFactory.getLogger(UserController.class); // 注入服务提供者,远程的Http服务 @Autowired private UserFeignService userFeignService; // 服务消费者对位提供的服务 @GetMapping(\"/sc/user/{id}\") public OrderModel findByIdByEurekaServer(@PathVariable Long id) { return userFeignService.findOrderById(id); }} 如上代码所示，通过@Autowired将声明的Feign依赖注入即可，调用userFeignService.findOrderById(id)使用。开发者通过userFeignService.findOrderById()就能完成发送HTTP请求和解码HTTP返回结果并封装成对象的过程。 启动测试依次按顺序启动如下工程注册中心: sc-fegin-first-server服务提供者1:sc-fegin-first-provider01服务提供者2:sc-fegin-first-provider02以上工程能正常启动work，但是当启动服务消费者: sc-fegin-first-consumer报错如下。 使用的示例工程的Spring Boot的版本为1.5.2.RELEASE，Spring Cloud版本为Dalston.RELEASE会出现以下错误。 12345678910111213141516171819&lt;!-- 引入spring boot的依赖 --&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.2.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;!-- 引入spring cloud的依赖 --&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Dalston.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 访问http://localhost:8010/sc/user/1 ,出现以下错误即：【问题一】feign/Feign$BuilderCaused by: java.lang.NoClassDefFoundError: feign/Feign$Builder12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273java.lang.IllegalStateException: ApplicationEventMulticaster not initialized - call &apos;refresh&apos; before multicasting events via the context: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@2d140a7: startup date [Sun May 14 22:44:43 CST 2017]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@4bf48f6 at org.springframework.context.support.AbstractApplicationContext.getApplicationEventMulticaster(AbstractApplicationContext.java:404) [spring-context-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.context.support.ApplicationListenerDetector.postProcessBeforeDestruction(ApplicationListenerDetector.java:97) ~[spring-context-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.beans.factory.support.DisposableBeanAdapter.destroy(DisposableBeanAdapter.java:253) ~[spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroyBean(DefaultSingletonBeanRegistry.java:578) [spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroySingleton(DefaultSingletonBeanRegistry.java:554) [spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.beans.factory.support.DefaultListableBeanFactory.destroySingleton(DefaultListableBeanFactory.java:961) [spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroySingletons(DefaultSingletonBeanRegistry.java:523) [spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.beans.factory.support.DefaultListableBeanFactory.destroySingletons(DefaultListableBeanFactory.java:968) [spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.context.support.AbstractApplicationContext.destroyBeans(AbstractApplicationContext.java:1033) [spring-context-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:555) [spring-context-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122) [spring-boot-1.5.2.RELEASE.jar:1.5.2.RELEASE] at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:737) [spring-boot-1.5.2.RELEASE.jar:1.5.2.RELEASE] at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:370) [spring-boot-1.5.2.RELEASE.jar:1.5.2.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:314) [spring-boot-1.5.2.RELEASE.jar:1.5.2.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1162) [spring-boot-1.5.2.RELEASE.jar:1.5.2.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1151) [spring-boot-1.5.2.RELEASE.jar:1.5.2.RELEASE] at org.xujin.sc.feign.user.UserConsumerApplication.main(UserConsumerApplication.java:15) [classes/:na]2017-05-14 22:44:44.079 ERROR 2372 --- [ main] o.s.boot.SpringApplication : Application startup failedorg.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name &apos;methodValidationPostProcessor&apos; defined in class path resource [org/springframework/boot/autoconfigure/validation/ValidationAutoConfiguration.class]: Unsatisfied dependency expressed through method &apos;methodValidationPostProcessor&apos; parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name &apos;org.xujin.sc.feign.user.service.UserFeignService&apos;: Failed to introspect bean class [org.springframework.cloud.netflix.feign.FeignClientFactoryBean] for lookup method metadata: could not find class that it depends on; nested exception is java.lang.NoClassDefFoundError: feign/Feign$Builder at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:749) ~[spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:467) ~[spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1173) ~[spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1067) ~[spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:513) ~[spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483) ~[spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306) ~[spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230) ~[spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302) ~[spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) ~[spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.context.support.PostProcessorRegistrationDelegate.registerBeanPostProcessors(PostProcessorRegistrationDelegate.java:223) ~[spring-context-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.context.support.AbstractApplicationContext.registerBeanPostProcessors(AbstractApplicationContext.java:702) ~[spring-context-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:527) ~[spring-context-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122) ~[spring-boot-1.5.2.RELEASE.jar:1.5.2.RELEASE] at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:737) [spring-boot-1.5.2.RELEASE.jar:1.5.2.RELEASE] at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:370) [spring-boot-1.5.2.RELEASE.jar:1.5.2.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:314) [spring-boot-1.5.2.RELEASE.jar:1.5.2.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1162) [spring-boot-1.5.2.RELEASE.jar:1.5.2.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1151) [spring-boot-1.5.2.RELEASE.jar:1.5.2.RELEASE] at org.xujin.sc.feign.user.UserConsumerApplication.main(UserConsumerApplication.java:15) [classes/:na]Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name &apos;org.xujin.sc.feign.user.service.UserFeignService&apos;: Failed to introspect bean class [org.springframework.cloud.netflix.feign.FeignClientFactoryBean] for lookup method metadata: could not find class that it depends on; nested exception is java.lang.NoClassDefFoundError: feign/Feign$Builder at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.determineCandidateConstructors(AutowiredAnnotationBeanPostProcessor.java:269) ~[spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.determineConstructorsFromBeanPostProcessors(AbstractAutowireCapableBeanFactory.java:1118) ~[spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1091) ~[spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.getSingletonFactoryBeanForTypeCheck(AbstractAutowireCapableBeanFactory.java:923) ~[spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.getTypeForFactoryBean(AbstractAutowireCapableBeanFactory.java:804) ~[spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.isTypeMatch(AbstractBeanFactory.java:558) ~[spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.beans.factory.support.DefaultListableBeanFactory.doGetBeanNamesForType(DefaultListableBeanFactory.java:432) ~[spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBeanNamesForType(DefaultListableBeanFactory.java:395) ~[spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.beans.factory.BeanFactoryUtils.beanNamesForTypeIncludingAncestors(BeanFactoryUtils.java:220) ~[spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.beans.factory.support.DefaultListableBeanFactory.findAutowireCandidates(DefaultListableBeanFactory.java:1260) ~[spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1101) ~[spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1066) ~[spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:835) ~[spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:741) ~[spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] ... 19 common frames omittedCaused by: java.lang.NoClassDefFoundError: feign/Feign$Builder at java.lang.Class.getDeclaredMethods0(Native Method) ~[na:1.8.0_112] at java.lang.Class.privateGetDeclaredMethods(Class.java:2701) ~[na:1.8.0_112] at java.lang.Class.getDeclaredMethods(Class.java:1975) ~[na:1.8.0_112] at org.springframework.util.ReflectionUtils.getDeclaredMethods(ReflectionUtils.java:613) ~[spring-core-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.util.ReflectionUtils.doWithMethods(ReflectionUtils.java:524) ~[spring-core-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.util.ReflectionUtils.doWithMethods(ReflectionUtils.java:510) ~[spring-core-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.determineCandidateConstructors(AutowiredAnnotationBeanPostProcessor.java:247) ~[spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] ... 32 common frames omittedCaused by: java.lang.ClassNotFoundException: feign.Feign$Builder at java.net.URLClassLoader.findClass(URLClassLoader.java:381) ~[na:1.8.0_112] at java.lang.ClassLoader.loadClass(ClassLoader.java:424) ~[na:1.8.0_112] at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331) ~[na:1.8.0_112] at java.lang.ClassLoader.loadClass(ClassLoader.java:357) ~[na:1.8.0_112] ... 39 common frames omitted 经查找解决问题2天查看无果(捂脸，后面写源码分析定位)，因此决定将Spring Boot的版本改变为1.4.3.RELEASE，Spring Cloud版本为Camden.SR5之后,按上面的顺序启动，之后测试http://localhost:8010/sc/user/1 ,可以正常work。 Fegin的work原理Spring Cloud应用在启动时，Feign会扫描标有@FeignClient注解的接口，生成代理，并注册到Spring容器中。生成代理时Feign会为每个接口方法创建一个RequetTemplate对象，该对象封装了HTTP请求需要的全部信息，请求参数名、请求方法等信息都是在这个过程中确定的，Feign的模板化就体现在这里。在本例中，我们将Feign与Eureka和Ribbon组合使用，@FeignClient(name = “sc-feign-first-provider”)意为通知Feign在调用该接口方法时要向Eureka中查询名为ea的服务，从而得到服务URL。 Fegin的常见应用Feign的Encoder、Decoder和ErrorDecoderFeign将方法签名中方法参数对象序列化为请求参数放到HTTP请求中的过程，是由编码器(Encoder)完成的。同理，将HTTP响应数据反序列化为java对象是由解码器(Decoder)完成的。 默认情况下，Feign会将标有@RequestParam注解的参数转换成字符串添加到URL中，将没有注解的参数通过Jackson转换成json放到请求体中。 注意，如果在@RequetMapping中的method将请求方式指定为GET，那么所有未标注解的参数将会被忽略，例如： 12@RequestMapping(value = \"/group/{groupId}\", method = RequestMethod.GET)void update(@PathVariable(\"groupId\") Integer groupId, @RequestParam(\"groupName\") String groupName, DataObject obj); 此时因为声明的是GET请求没有请求体，所以obj参数就会被忽略。 在Spring Cloud环境下，Feign的Encoder只会用来编码没有添加注解的参数。如果你自定义了Encoder, 那么只有在编码obj参数时才会调用你的Encoder。 对于Decoder, 默认会委托给SpringMVC中的MappingJackson2HttpMessageConverter类进行解码。只有当状态码不在200 ~ 300之间时ErrorDecoder才会被调用。 ErrorDecoder的作用是可以根据HTTP响应信息返回一个异常，该异常可以在调用Feign接口的地方被捕获到。我们目前就通过ErrorDecoder来使Feign接口抛出业务异常以供调用者处理。 更换Feign默认使用的HTTP ClientFeign在默认情况下使用的是JDK原生的URLConnection发送HTTP请求，没有连接池，但是对每个地址会保持一个长连接，即利用HTTP的persistence connection 。我们可以用Apache的HTTP Client替换Feign原始的http client, 从而获取连接池、超时时间等与性能息息相关的控制能力。Spring Cloud从Brixtion.SR5版本开始支持这种替换，首先在项目中声明Apache HTTP Client和feign-httpclient依赖： 12345678910&lt;!-- 使用Apache HttpClient替换Feign原生httpclient --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpclient&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.netflix.feign&lt;/groupId&gt; &lt;artifactId&gt;feign-httpclient&lt;/artifactId&gt; &lt;version&gt;8.17.0&lt;/version&gt; &lt;/dependency&gt; 然后在application.yml中添加如下：123feign: httpclient: enabled: true spring cloud feign使用okhttp3参考 spring cloud feign常见问题参数不会自动传递服务消费者端调用1234@RequestMapping(value = \"/test\", method = RequestMethod.GET) public String hello(@RequestParam(\"name\") String name, @RequestParam(\"age\") int age) { return userFeignService.hello(name, age); } 服务提供者Controller对外服务1234@RequestMapping(value = \"/hello\", method = RequestMethod.GET) public String hello(@RequestParam(\"name\") String name, @RequestParam(\"age\") int age) { return name + age; } Fegin客户端定义调用12@RequestMapping(value = \"/hello\", method = RequestMethod.GET) public String hello(String name, @RequestParam(\"age\") int age); 启动的时候sc-fegin-first-consumer工程不报错。但是当访问http://localhost:8010/test?name=xujin&amp;age=25 ,报错如下123feign.FeignException: status 405 reading UserFeignService#hello(String,int); content:{&quot;timestamp&quot;:1494856464666,&quot;status&quot;:405,&quot;error&quot;:&quot;Method Not Allowed&quot;,&quot;exception&quot;:&quot;org.springframework.web.HttpRequestMethodNotSupportedException&quot;,&quot;message&quot;:&quot;Request method &apos;POST&apos; not supported&quot;,&quot;path&quot;:&quot;/hello&quot;} at feign.FeignException.errorStatus(FeignException.java:62) ~[feign-core-9.3.1.jar:na] Fegin客户端定义修改如下OK，原因是name被自动放到request body。只要有body，就会被feign认为是post请求，所以整个hello是被当作带有request parameter和body的post请求发送出去了，因此出现上面的错误提示。 12@RequestMapping(value = \"/hello\", method = RequestMethod.GET) public String hello(@RequestParam(\"name\") String name, @RequestParam(\"age\") int age); POST多参数调用 POST多参数 Feign端定义： 12@RequestMapping(value = \"/test/post\", method = RequestMethod.POST)public OrderModel post(OrderModel orderModel); 12@RequestMapping(value = \"/test/post\", method = RequestMethod.POST)public OrderModel post(@RequestBody OrderModel orderModel); 以上两种定义方式等价 服务提供者的定义 12345@PostMapping(\"/test/post\")public OrderModel testPost(@RequestBody OrderModel orderModel) { orderModel.setOrderNo(2222222L); return orderModel;} 修改订单号返回证明，服务提供者接到从Feign POST请求过来的数据。 服务消费者端的使用 1234@PostMapping(\"/test/post\")public OrderModel testPost(@RequestBody OrderModel orderModel) { return userFeignService.post(orderModel);} 测试当修改了Feign默认的http Client之后，出现如下错误，具体出错原因还在排查之中，本文会随时更改。【问题二】更换了Feign默认的Client出现HystrixRuntimeException12345678{ \"timestamp\": 1494947172990, \"status\": 500, \"error\": \"Internal Server Error\", \"exception\": \"com.netflix.hystrix.exception.HystrixRuntimeException\", \"message\": \"UserFeignService#post(OrderModel) failed and no fallback available.\", \"path\": \"/test/post\"} 1234567java.lang.IllegalArgumentException: MIME type may not contain reserved characters at org.apache.http.util.Args.check(Args.java:36) ~[httpcore-4.4.5.jar:4.4.5] at org.apache.http.entity.ContentType.create(ContentType.java:182) ~[httpcore-4.4.5.jar:4.4.5] at feign.httpclient.ApacheHttpClient.getContentType(ApacheHttpClient.java:159) ~[feign-httpclient-8.17.0.jar:8.17.0] at feign.httpclient.ApacheHttpClient.toHttpUriRequest(ApacheHttpClient.java:140) ~[feign-httpclient-8.17.0.jar:8.17.0] at feign.httpclient.ApacheHttpClient.execute(ApacheHttpClient.java:83) ~[feign-httpclient-8.17.0.jar:8.17.0] 当关闭之后，访问正常如下所示，醉了同样的代码(PS:捂脸) 123feign: httpclient: enabled: false 1{\"createTime\":1494944311023,\"orderNo\":33333,\"payTime\":1494944311023} GET多参数调用当服务之间GET调用为多参数时，可以使用Map来构建参数传递Feign接口中的示例定义12@RequestMapping(value = \"/test/get\", method = RequestMethod.GET)public String testGet(@RequestParam Map&lt;String, Object&gt; map); 服务消费者的调用 12345678@GetMapping(\"/test/get\")public String testGet() { HashMap&lt;String, Object&gt; map = Maps.newHashMap(); map.put(\"orderNo\", \"1\"); map.put(\"createTime\", new Date()); map.put(\"payTime\", new Date()); return userFeignService.testGet(map);} 个人看来，如果是GET的多参数通过Map进行传递，当参数比较多时，个人建议使用面向对象的思维，通过POST的方式传递对象相对较好。 服务提供者的使用 1234@RequestMapping(value = \"/test/get\", method = RequestMethod.GET)public String testGet(@RequestParam Map&lt;String, Object&gt; map) { return String.valueOf(map);} 访问URL:http://localhost:8010/test/get ,测试OK. 1{orderNo=1, createTime=Sat May 20 19:47:38 CST 2017, payTime=Sat May 20 19:47:38 CST 2017} 总结 本文主要介绍了Feign的基本的定义，以及Feign的work原理和使用Feign的注意事项和常见问题。最后介绍了一下更换Feign默认使用的HTTP Client。主要是遇到一个奇葩的问题，最终没解决更换版本。在下一篇文章中将介绍Feign的其它的使用，例如Feign的继承，日志级别，以及Feign源码分析等 参考文献希望Feign能够支持参数请求使用POJO的Issue建议使用Feign原生的注解的Issue建议增强Feign的功能建议支持可选的Request Body（目前Feign当POST一个null时，会报异常）","link":"/sc/sc-fegin01/"},{"title":"Spring Cloud Sleuth-全链路监控调研","text":"前言:做过软件开发的都知道，对系统进行全链路的监控是非常有必要的。在单体应用中，传统的方式是软件开发者，通过自定义日志的level，日志文件的方式记录单体应用的运行日志。从而排查线上系统出现运行过慢，出现故障，异常等问题，但是在微服务架构或分布式系统中，一个系统被拆分成了A、B、C、D、E等多个服务，而每个服务可能又有多个实例组成集群，采用上诉定位问题的方式就行不通了，你充其量就知道某个服务是应用的瓶颈，但中间发生了什么你完全不知道。而且问题的查询，因为有海量各种各样的日志等文件，导致追溯定位问题等极其不方便。因此需要全链路监控系统的收集，上报，对海量日志实时计算生成，监控告警，视图报表，帮助开发人员快速定位问题。 服务追踪分析一个由微服务构成的应用系统由N个服务实例组成，通过REST请求或者RPC协议等来通讯完成一个业务流程的调用。对于入口的一个调用可能需要有多个后台服务协同完成，链路上任何一个调用超时或出错都可能造成前端请求的失败。服务的调用链也会越来越长，并形成一个树形的调用链。如下图所示:但是随着服务的增多，对调用链的分析也会越来越负责。设想你在负责下面这个系统，其中每个小点都是一个微服务，他们之间的调用关系形成了复杂的网络。如下图所示: 通过该图，可以看出错综复杂的调用网路图。针对服务化应用全链路追踪的问题，Google发表了Dapper论文，介绍了他们如何进行服务追踪分析。其基本思路是在服务调用的请求和响应中加入ID，标明上下游请求的关系。利用这些信息，可以可视化地分析服务调用链路和服务间的依赖关系。 什么是 Spring Cloud Sleuth ?Spring Cloud Sleuth为Spring Cloud提供了分布式追踪方案，为了更好的理解这个领域中的一些概念，建议先自行搜索学习一下Google Dapper相关的论文，http://research.google.com/pubs/pub36356.html，github Code连接:Spring Cloud Sleuth Code。官方文档地址:http://cloud.spring.io/spring-cloud-sleuth/spring-cloud-sleuth.html. 其官方文档中对自己的定义是如下： Spring Cloud Sleuth implements a distributed tracing solution for Spring Cloud, borrowing heavily from Dapper, Zipkin and HTrace. For most users Sleuth should be invisible, and all your interactions with external systems should be instrumented automatically. You can capture data simply in logs, or by sending it to a remote collector service. 简单来说，Spring Cloud Sleuth就是APM(Application Performance Monitor),全链路监控的APM的一部分，如果要完整的使用该组件需要自己定制化或者和开源的系统集成，例如:ZipKin。 APM（Application Performance Monitor）这个领域最近异常火热。国外该领域知名公司包括New Relic，Appdynamics，Splunk。其中New Relic已经成功IPO，估值超过20亿美元。国内外的个大互联网公司也都有类似大名鼎鼎的APM产品，例如淘宝鹰眼Eagle Eyes，点评的CAT，微博的Watchman，twitter的Zipkin。他们的产品虽未像专业APM公司的产品这样功能强大，但结合各自公司的业务特点，这些产品在支撑业务系统的高性能和稳定性方面，发挥了显著的作用。 Spring Cloud Sleuth和Zipkin对应Dpper的开源实现是Zipkin，支持多种语言包括JavaScript，Python，Java, Scala, Ruby, C#, Go等。其中Java由多种不同的库来支持。 SpringCloudSleuth 借用了 Dapper 的术语 Span 基本工作单元，例如，在一个新建的span中发送一个RPC等同于发送一个回应请求给RPC，span通过一个64位ID唯一标识，trace以另一个64位ID表示，span还有其他数据信息，比如摘要、时间戳事件、关键值注释(tags)、span的ID、以及进度ID(通常是IP地址) span在不断的启动和停止，同时记录了时间信息，当你创建了一个span，你必须在未来的某个时刻停止它。 Trace 一系列spans组成的一个树状结构，例如，如果你要在分布式中大数据存储中使用，Trace将会由一个请求执行调用链形成。 Annotation 用来及时记录一个事件的存在，一些核心annotations用来定义一个请求的开始和结束。cs：Client Sent - 客户端发起一个请求，这个annotion描述了这个span的开始 sr：Server Received - 服务端获得请求并准备开始处理它，如果将其sr减去cs时间戳便可得到网络延迟ss：Server Sent - 注解表明请求处理的完成(当请求返回客户端)，如果ss减去sr时间戳便可得到服务端需要的处理请求时间 cr：Client Received - 表明span的结束，客户端成功接收到服务端的回复，如果cr减去cs时间戳便可得到客户端从服务端获取回复的所有所需时间将Span和Trace在一个系统中使用Zipkin注解的过程图形化，如下图所示:","link":"/sc/sc-sleuth/"},{"title":"关于SpringCloud中国社区以及国内使用情况","text":"Spring Cloud中国社区起源 其实当Spring Cloud项目刚在github上出现的时候，我就一直在关注其项目发展，到了2015年8月，由于个人兴趣研究Spring Cloud项目，由于国内相关文档较少，当时就想建立一个中国社区，于是就先把域名注册了，选中域名为springcloud.cn。 为什么要发起Spring Cloud中国社区 Spring Cloud发展到2016年，国内关注的人越来越多，但是相应学习交流的平台和材料比较分散，不利于学习交流，因此Spring Cloud中国社区应运而生。 Spring Cloud中国社区是国内首个Spring Cloud构建微服务架构的交流社区。我们致力于为Spring Boot或Spring Cloud技术人员提供分享和交流的平台，推动Spring Cloud在中国的普及和应用。 欢迎CTO、架构师、开发者等，在这里学习与交流使用Spring Cloud的实战经验。 目前QQ群人数:7000+,微信群:2000+. 扫描下面二维码或者微信搜索SpringCloud，关注社区公众号 Spring Cloud中国社区QQ群①:415028731 Spring cloud中国社区QQ群②:530321604 Spring Cloud中国社区官网:http://springcloud.cn Spring Cloud中国社区论坛:http://springcloud.cn Spring Cloud中国社区文档:http://docs.springcloud.cn spring cloud目前国内使用情况 中国联通子公司http://flp.baidu.com/feedland/video/?entry=box_searchbox_feed&amp;id=144115189637730162&amp;from=timeline&amp;isappinstalled=0 上海米么金服 指点无限（北京）科技有限公司 易保软件 目前在定制开发中 http://www.ebaotech.com/cn/ 广州简法网络 深圳睿云智合科技有限公司 持续交付产品基于Spring Cloud研发 http://www.wise2c.com 猪八戒网 上海云首科技有限公司 华为 整合netty进来用rpc 包括nerflix那套东西 需要注意的是sleuth traceid的传递需要自己写。tps在物理机上能突破20w 东软 南京云帐房网络科技有限公司 四众互联(北京)网络科技有限公司 深圳摩令技术科技有限公司 广州万表网 视觉中国 上海秦苍信息科技有限公司-买单侠 爱油科技(大连)有限公司爱油科技基于SpringCloud的微服务实践 广发银行 卖货郎(http://www.51mhl.com/） 拍拍贷 甘肃电信 新浪商品部 春秋航空 冰鉴科技 万达网络科技集团-共享商业平台-共享供应链中心 网易乐得技术团队 饿了么某技术团队 高阳捷迅信息科技–话费中心业务平台–凭证查询及收单系统数据在统计之中，会一直持续更新，敬请期待！ 捐赠社区发展捐赠社区 如果你觉得，Spring Cloud中国社区还可以，为了更好的发展，你可以捐赠社区，点击下面的打赏捐赠，捐赠的钱将用于社区发展和线下meeting up。","link":"/sc/springcloud/"},{"title":"什么是Spring Cloud Config？","text":"前言:在单体应用中，我们一般的做法是把Property和Code放在一起，没有什么问题。但是在分布式系统中，由于存在多个服务实例，需要分别管理到每个具体的服务工程中的配置，上线需要准备check list 并逐个检查每个上线的服务是否正确。在系统上线之后修改某个配置，需要重启服务。这样开发就相当麻烦。因此我们急需需要把分布式系统中的配置信息抽取出来统一管理，服务获取系统信息时有一个覆盖顺序:property–&gt; Evn—-&gt;配置中心。这样修改环境变量或者修改配置中心的配置就能取到最新的配置信息。在唯品会 Venus Framework中我们专门设计了这个功能。Spring cloud出现之后，避免了大家重复造轮子。 什么是 Spring Cloud Config ?其官方文档中对自己的定义是如下，官网连接:Spring Cloud Config。 Spring Cloud Config provides server and client-side support for externalized configuration in a distributed system.With the Config Server you have a central place to manage external properties for applications across all environments. 简单来说，Spring Cloud Config就是我们通常意义上的配置中心 - 把应用原本放在本地文件的配置抽取出来放在中心服务器，从而能够提供更好的管理、发布能力。 另外，Spring Cloud Config提供基于以下3个维度的配置管理： 应用 这个比较好理解，每个配置都是属于某一个应用的 环境 每个配置都是区分环境的，如dev, test, prod等 版本 这个可能是一般的配置中心所缺乏的，就是对同一份配置的不同版本管理，比如:可以通过Git进行版本控制。 Spring Cloud Config提供版本的支持，也就是说对于一个应用的不同部署实例，可以从服务端获取到不同版本的配置，这对于一些特殊场景如：灰度发布，A/B测试等提供了很好的支持。 为什么会诞生Spring Cloud Config? 配置中心目前现状:不管是开源的(百度的disconf)，还是一些公司自己闭源投入使用的产品已经不少了，那为什么还会诞生Spring Cloud Config呢？ 在我看来，Spring Cloud Config在以下几方面还是有比较独特的优势，如下： 基于应用、环境、版本三个维度管理 这个在前面提过了，主要是有版本的支持 配置存储支持Git 这个就比较有特色了，后端基于Git存储，一方面程序员非常熟悉，另一方面在部署上会非常简单，而且借助于Git，天生就能非常好的支持版本 当然，它还支持其它的存储如本地文件、SVN等 和Spring无缝集成 它无缝支持Spring里面Environment和PropertySource的接口 所以对于已有的Spring应用程序的迁移成本非常低，在配置获取的接口上是完全一致的 Spring Cloud Config 入门例子上述节点主要介绍了Spring cloud的相关理论，大家对Spring Cloud Config有了一个初步的认识，接下来例子让大家感受一下Spring cloud config的魅力。 Overview 上图简要描述了一个普通Spring Cloud Config应用的场景。其中主要有以下几个组件： Config Client Client很好理解，就是使用了Spring Cloud Config的应用 Spring Cloud Config提供了基于Spring的客户端，应用只要在代码中引入Spring Cloud Config Client的jar包即可工作 Config Server Config Server是需要独立部署的一个web应用，它负责把git上的配置返回给客户端 Remote Git Repository 远程Git仓库，一般而言，我们会把配置放在一个远程仓库，通过现成的git客户端来管理配置 Local Git Repostiory Config Server的本地Git仓库 Config Server接到来自客户端的配置获取请求后，会先把远程仓库的配置clone到本地的临时目录，然后从临时目录读取配置并返回","link":"/sc/sc-config/"},{"title":"IDEA For Mac使用技巧","text":"摘要: 本文主要记录在项目开发过程中，使用IDEA For Mac的使用技巧。包括快捷键，注释模板和版权注释模板等。 一.IDEA for MAC OS X 快捷键 键位 功能介绍 使用说明 tab+空格 基本代码补全功能，包括类名、方法名、或者变量名 代码补全 二.IDEA设置默认生成版权注释功能2.1 设置版权信息模板在使用idea开发时，有时为了规范，我们需要在一个类头部增加版权信息，这个是可以让IDEA自动生成，只要配置下，就能像eclipse里一样，创建类文件时就生成民copyright信息，具体的步骤如图： 2.2 设置生效作用域和使用的模板： 2.3 设置版权信息模板123Copyright (c) $today.year xujin.org All right reserved. This software is the confidential and proprietary information of xujin.org (&quot;Confidential Information&quot;). You shall not disclose such Confidential Information and shall use it only in accordance with the terms of the license agreement you entered into with xujin.org","link":"/tools/idea-zs/"},{"title":"DinCos中间件生态圈","text":"1. 什么是DinCos？ DinCos 是Distributed Naming Configuration Service 首字母简称，主要关注的领域是 命名服务（Naming Service）命名服务:提供分布式系统中所有对象，实体的名字到关联元数据之间的映射管理服务，最典型的场景就是服务治理中间件中的服务注册与发现。 配置服务 (Configuration Service)配置服务 关注现在应用架构中所有服务的配置中心化，外部化以及动态化的统一配置管理方式，比如配置中心中间件。 2. DinCos中间件主站: http://dincos.com/Github: https://github.com/dincos","link":"/dincos/gs/"},{"title":"Bean Mapping之Orika的项目运用","text":"前言 在JavaEE开发过程中，我们经常会把持久层的实体对象copy给VO，BO等，用于快速将持久层中的对象释放如下图所示。但很多时候BO，VO和Entity的结构都是类似的。刚开始通过写很多冗长的b.setF1(a.getF1())这样的代码来实现对象的Copy，后来逐渐延伸出Spring BeanUtils， CgLib BeanCopier, Apache BeanUtils, Dozer等快速实体映射工具jar。性能对比可以参考这篇文章:http://www.cnblogs.com/kaka/archive/2013/03/06/2945514.html orika-mapper快速高效映射框架为什么需要模型映射？ 多次模型, 可以保证内部实体不被直接暴露, 也可使得接口层模型更为独立, 解耦实体层模型。Bean Mapping用于快速，高性能的对两个POJO对象做数据双向映射。 Orkia的设计思路github:https://github.com/orika-mapper/orikadoc:http://orika-mapper.github.io/orika-docs/ Orika使用javaassist提前生成拷贝代码 优势：避免使用反射和多次读取映射规则，性能高内存消耗低 Orika 的设计思路就是预先通过javaassist 把Java Bean 之间的映射关系一次性生成目标拷贝方法代码。 这样就可以避免在Bean 映射环节一次次的读取映射规则。 这就是Orika 性能提升的原因。理论上以生成的目标Java 代码来运行映射是拷贝模式所能取到性能最大值的方法。 通过自定义注解的方式，Orika与Spring框架整合(在这里不描述是如何自定义整合使用)，达到高性能的模型映射，支持无配置映射，支持复杂映射，支持自定义类型转换。 在实际项目中使用如下: 在applicationContext.xml文件中，配置Model的通配符扫描包路径 123 &lt;bean id=\"orikaBeanMapper\" class=\"com.xxxxx.xxxxx.core.beans.mapping.orika.OrikaBeanMapper\"&gt; &lt;property name=\"basePackage\" value=\"com.xxxxx.financing.model.**\"&gt;&lt;/property&gt;&lt;/bean&gt; 在需要copy的地方依赖注入 1234 @Autowiredprivate BeanMapper beanMapper; beanMapper.map(financingAccountModel, FinancingAccount.class) entity上注解配置如下，此处省略get set方法。 123456789 @MapClass(value=\"com.xxx.financing.database.model.FinancingAccountModel\")public class FinancingAccount { private Long id; private String userId; private String userName; }","link":"/venus/venus-orika/"},{"title":"CloudStack中云主机的UTC时间转为本地时间","text":"CloudStack UTC时间处理 CloudStack项目中使用的时间是UTC时间，具体什么是UTC时间大家可以百度，但是我们需要的时间是正常的时间，所以在国泰君安开发测试云中，同步资源管理中虚拟机的同步管理，需要对虚拟机的时间格式化进行转换。工具类如下，关键是时间格式的问题，时间格式为yyyy-MM-dd’T’HH:mm:ss+SSSS。 工具类①12345678910111213public static Date utc2LocalDate(String utcTime) { String utcTimePatten = \"yyyy-MM-dd'T'HH:mm:ss+SSSS\"; SimpleDateFormat sdf = new SimpleDateFormat(utcTimePatten); Date dt = null; try { dt = sdf.parse(utcTime); } catch (ParseException e) { e.printStackTrace(); } return dt; } 工具类②12345678910111213141516171819202122232425262728293031323334353637383940 public class TestUtc { public static void main(String args[]) { try { String ts = \"2015-04-22T15:58:54+0800\"; System.out.println(\"ts = \" + ts); ts = ts.replace(\"Z\", \" UTC\"); System.out.println(\"ts = \" + ts); SimpleDateFormat sdf = new SimpleDateFormat( \"yyyy-MM-dd'T'HH:mm:ss+SSSS\"); Date dt = sdf.parse(ts); TimeZone tz = sdf.getTimeZone(); Calendar c = sdf.getCalendar(); System.out.println(\"Display name: \" + tz.getDisplayName()); System.out.println(getString(c)); } catch (ParseException pe) { System.out.println(\"Error offset: \" + pe.getErrorOffset()); pe.printStackTrace(); } } private static String getString(Calendar c) { StringBuffer result = new StringBuffer(); result.append(c.get(Calendar.YEAR)); result.append(\"-\"); result.append((c.get(Calendar.MONTH) + 1)); result.append(\"-\"); result.append(c.get(Calendar.DAY_OF_MONTH)); result.append(\" \"); result.append(c.get(Calendar.HOUR_OF_DAY)); result.append(\":\"); result.append(c.get(Calendar.MINUTE)); result.append(\":\"); result.append(c.get(Calendar.SECOND)); return result.toString(); } } 测试类1234567891011121314151617 public class TestUtcTime { /** * * @param args * @return void */ public static void main(String[] args) { String ts = \"2015-04-22T15:58:54+0800\"; Date date = new Date(); System.out.println(date); System.out.println(DateUtil.utc2LocalDate(ts)); } }","link":"/ex/cs-utc/"},{"title":"Spring initializr源码工程解析","text":"什么是Spring initializr什么是Spring initializrinitializr是Spring提供的一个快速根据按需生成带有Spring风格的工程的代码生成器。代码地址:https://github.com/spring-io/initializr/在线地址:https://start.spring.io 工程目录解读 模块名 说明 initializr-actuator 可选模块，提供统计数据和指标 initializr-docs 文档 initializr-generator 单独的生成类库，核心模块，可以引入自己的代码生成器工程中 initializr-service Spring Boot的主入口应用工程 initializr-web REST端点和web接口，主要是Controller类 未完待续","link":"/ex/spring-initializr/"},{"title":"在STS或eclipse中安装Lombok并使用","text":"lombok 提供了简单的注解的形式来帮助我们简化消除一些必须有但显得很臃肿的 java 代码。特别是相对于 POJO，使用相应的注解可以简化整个代码。lombok 的官方网址：http://projectlombok.org/ ,从官网下载 一.安装lombok 1.在STS中安装lombok ①找到lombok.jar，执行命令: D:\\devtools&gt;java -jar lombok.jar或者直接双击lombok.jar ②确认完STS的安装路径后，点击install/update按钮，即可安装完成，如下图所示 ③安装完成之后，请确认eclipse安装路径下是否多了一个lombok.jar包，并且其 配置文件STS.ini(eclipse打开eclipse.ini）中是否 添加了如下内容: -javaagent:lombok.jar -Xbootclasspath/a:lombok.jar 如果上面的答案均为true，那么恭喜你已经安装成功，否则将缺少的部分添加到相应的位置即可 二.测试安装lombok是否成功创建一个Java类，如下，尝试使用下面 1234567@Datapublic class User { private String id; private String name; private String userId; private String password; }","link":"/ex/lombok/"},{"title":"Eclipse for Mac 快捷键","text":"摘要:本文主要介绍了Mac下Eclipse的常用快捷键，开发环境切换到Mac下后原来Window下的快捷键很大一部分是不相容的，一方面不熟悉快捷键会导致开发效率明显降低，另一方面频繁录入错误的快捷键IDE也一脸懵逼，方便速查记录如下，尤其像我习惯了Eclipse IDE。 最常用 快捷键 说明 Option+↓ 向下移动代码 Option+↑ 向上移动代码 Option+/ 代码智能提示 Option+Command+C 修改函数结构，适用重构 Command+Option+R 批量重命名 Option+Command+L 抽取本地变量 Command+Option+S 快速生成代码，Getter&amp;Setter，Constructor等 Option+回车 显示当前选择资源的属性 Command+Shift+O 整理包去掉多余的import语句 文本位置跳转快捷键 快捷键 说明 Command+左箭头 跳转到一行的开头 Command+右箭头 跳转到一行的末尾 Command+上箭头 跳转到文本的开头 Command+下箭头 跳转到文本的末尾 Option+左箭头 跳转到当前单词的开头 Option+右箭头 跳转到当前单词的末尾 文本选中快捷键 快捷键 说明 Shift+Command+左箭头 选中光标到本行开头的文本 Shift+Command+右箭头 选中光标到本行末尾的文本 Shift+Command+上箭头 选中光标到全部文本的开头 Shift+Command+下箭头 选中光标到全部文本的末尾 Shift+Option+左箭头 选中光标到当前单词的开头 Shift+Option+右箭头 选中光标到当前单词的末尾 Command类","link":"/ex/eclipse-for-mac/"},{"title":"个人博客-有争议文章版权问题复盘声明","text":"摘要:大家好，我是许进沉思录的博主许进，感谢大家对我的博客进行阅读，之所以网站取名为沉思录主要想用博客的方式记录我人生每个阶段的技术思考和技术学习快照，和感悟。由于最近有网友对我博客上的内容的版权问题产生争议，因此本文主要对我个人博客内容的版权问题争议进行复盘声明。 前言这篇文章为什么会出现呢？ 第一,因为最近发生了让我匪夷所思的事情，至于什么事情我不想做过多解释。我只想做好我自己，尊师重道，有则改之，无责加勉。 第二,最近有幸和另外6位作者写完一本名为《重新定义Spring Cloud实战》技术书，起初规划了32章，最后实在写不动了，保留了精华的25章，由于工作特别忙，7位作者经过无数个夜晚熬夜，最终初稿汇总之后 1400页，我第一感觉我的天呀，纸张这么贵。而且我们在写的过程中，站在读者的角度+降低成本的角度，做了很多思考。最后我们7人进行缩减，能用一句话说明白的就不要用两句话，经过对整本书进行调整，在保持内容不变的情况下最后初稿为1187页。好像跑题了，言归正传，最近电子鲜读版本已公开。好多技术朋友看完之后，有人问我:我可以在我博客上写一下关于这本书的读书笔记吗？我说可以呀，然后他问了我版权署名的问题。我回答是:我不太介意这个问题，我们做好自己就可以。但是为了避免引起不必要的麻烦，我建议他可以写为《某某某书的读书笔记》 针对上述两个问题，和最近发生的事情，真的有必要进行复盘进行声明。 1.博客概述 我开始接触写博客的时候是从新浪博客开始，后来经过多次折腾进行迁移。在写这篇文章之前，我想介绍一下什么是博客。百度百科对博客的描述如下图片所示: 简单的来说博客就是对学习，生活，感悟，思考的一种记录方式。仅代表个人观点。 2. 博客版权声明 近几年随着知识产权和版权意识的增强，很多人开始对自己在网上发表的博客信息或网络日志，或者想法和感悟增加版权信息。 2.1 Hexo博客版权增加用过Hexo或者Hugo的可以知道，有时为了反复添加重复内容，会统一添加版权信息。代码如下所示: 1234567&lt;! -- 添加版权信息 --&gt;&lt;div class=&quot;article-footer-copyright&quot;&gt;&lt;i class=&quot;fa fa-lightbulb-o&quot;&gt;&lt;/i&gt;本文由&lt;b&gt;&lt;a href=&quot;&lt;%= config.root %&gt;index.html&quot; target=&quot;_blank&quot; title=&quot;&lt;%= config.author %&gt;&quot;&gt;&lt;%= config.author %&gt;&lt;/a&gt;&lt;/b&gt;创作和发表,采用&lt;a href=&quot;http://creativecommons.org/licenses/by/3.0/cn&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;CC BY 3.0 CN协议&lt;/a&gt; 进行许可。转载请注明作者及出处,本文作者为&lt;b&gt;&lt;a href=&quot;&lt;%= config.root %&gt;index.html&quot; target=&quot;_blank&quot; title=&quot;&lt;%= config.author %&gt;&quot;&gt;&lt;%= config.author %&gt;&lt;/a&gt;&lt;/b&gt;,本文标题为&lt;b&gt;&lt;a href=&quot;&lt;%- config.root %&gt;&lt;%- post.path %&gt;&quot; target=&quot;_blank&quot; title=&quot;&lt;%= post.title %&gt;&quot;&gt;&lt;%= post.title %&gt;&lt;/a&gt;&lt;/b&gt;本文链接为&lt;b&gt;&lt;a href=&quot;&lt;%- config.root %&gt;&lt;%- post.path %&gt;&quot; target=&quot;_blank&quot; title=&quot;&lt;%= post.title %&gt;&quot;&gt;&lt;%- config.url %&gt;/&lt;%- post.path %&gt;&lt;/a&gt;&lt;/b&gt;&lt;/div&gt;&lt;! -- 添加版权信息 --&gt; 优点:统一添加版权信息缺点:如果遗漏容易产生误解 统一添加的方式，虽然方便，即便你指明了作者是谁，但是也容易引起误会，可能会给自己造成困扰。比如下面争议的几篇文章。 3.博客版权-争议问题复盘说明3.1 博客主题版权声明 我博客基于Hexo构建，主题基于https://github.com/ppoffice/hexo-theme-icarus优化美化进行定制DIY。感谢原作者贡献了分享了该主题。 3.2 Spring Cloud Zuul异常处理文章-版权说明如下图所示Spring Cloud Zuul异常处理文章来自于Spring Cloud中国社区博客投稿，文稿署名张劲，为了让更多的人学习了解。放了一份到我博客已注明作者。 跟作者沟通了解之后，作者没有参加过上海技术沙龙也没看过对应的PPT， 3.3 数据库连性池性能测试-文章版权声明 本篇文章链接在我博客上地址是:http://xujin.org/mw/dcp-test/， 是我在唯品会中间件团队时学习中间件的记录，收集整理成MD文稿而来。 通过百度搜索结果如下，最下面的两个截图类似的文章。 跟原作者沟通声明版权为唯品会中间件团队沟通结果如下: 处理结果如下: 4.总结处理方式博客后期优化方式:1.修改统一加版权方式为手动添加，减少不必要的误会。2.增加反馈机制，第一时间反馈处理","link":"/ex/bqsm/"},{"title":"Java8编译器的新特性-参数名字保留在字节码中","text":"摘要:很长一段时间里，Java程序员一直在发明不同的方式使得方法参数的名字能保留在Java字节码中，并且能够在运行时获取它们（比如，Paranamer类库）。最终，在Java 8中把这个强烈要求的功能添加到语言层面（通过反射API与Parameter.getName()方法）与字节码文件（通过新版的javac的–parameters选项）中。由于中间件框架使用jdk8的新特性check参数顺序和签名，因此在使用RPC框架中，RPC服务端接口定义编译后的Class文件中加入了参数,但是在webApp中使用RPC Client在Eclipse等IDE中开发调试，由于生成class的时候Ide不会自动参数带进去。因此需要对IDE进行设置。 Java编译器的新特性参数名字很长一段时间里，Java程序员一直在发明不同的方式使得方法参数的名字能保留在Java字节码中，并且能够在运行时获取它们（比如，Paranamer类库）。最终，在Java 8中把这个强烈要求的功能添加到语言层面（通过反射API与Parameter.getName()方法）与字节码文件（通过新版的javac的–parameters选项）中。123456789101112131415161718package org.xujin.jdk.parameter;import java.lang.reflect.Method;import java.lang.reflect.Parameter;/** * @author xujin */public class ParameterNames { public static void main(String[] args) throws Exception { Method method = ParameterNames.class.getMethod(\"main\", String[].class); for (final Parameter parameter : method.getParameters()) { System.out.println(\"Parameter: \" + parameter.getName()); } }} 如果不使用–parameters参数来编译这个类，然后运行这个类，会得到下面的输出：1Parameter: arg0 如果使用–parameters参数来编译这个类，程序的结构会有所不同（参数的真实名字将会显示出来）：1Parameter: args Maven和Gradle使用方式Maven使用介绍对于有经验的Maven用户，通过maven-compiler-plugin的配置可以将-parameters参数添加到编译器中去。12345678910&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.1&lt;/version&gt; &lt;configuration&gt; &lt;compilerArgument&gt;-parameters&lt;/compilerArgument&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;/configuration&gt;&lt;/plugin&gt; 针对Java 8最新发布的Eclipse Kepler SR2（请检查这里的下载说明）提供了非常实用的配置选项，可以通过下图的配置方式来控制编译器行为 Gradle使用介绍在build.gradle中配置如下即可1234567compileJava { sourceCompatibility = 1.8 targetCompatibility = 1.8 options.compilerArgs &lt;&lt; &apos;-parameters&apos; options.fork = true options.forkOptions.executable = &apos;javac&apos;} 在IDE中的配置 有一种情况需要IDE编辑器在编译的时候，需要靠IDE自动的把参数等信息加到class文件中。 Eclipse中的配置 使用Eclipse进行本地调试时，需进行如下配置： Preferences -&gt; Java -&gt; Compiler JDK Compiliance -&gt; “Compiler compliance level”设置为1.8 Classfile Generation -&gt; “Store information about method parameters (usable via reflection)”设置为勾选 在IdeA中的配置 使用IDEA进行本地调试时，需进行如下配置： Preferences -&gt; “Build, Execution, Deployment” -&gt; Compiler -&gt; “Java Compiler” “Project bytecode version”设置为1.8 “Additional command line parameters”添加”-parameters”","link":"/ex/jdk8-parameters/"},{"title":"Corn表达式与时间整点半点代码片","text":"摘要:本文主要介绍了Corn表达式和判断时间是否半点或者整点执行的代码片。 Corn表达式1234567891011String exp=\"0/3 * * * * ? \";//判断表达式是否有效boolean valid = CronExpression.isValidExpression(exp); //使用CronExpression生成时间序列 CronExpression cronExpression = new CronExpression(exp);System.out.println(cronExpression.getNextValidTimeAfter(new Date()));//使用CronSequenceGenerator生成时间序列 CronSequenceGenerator cronSequenceGenerator = new CronSequenceGenerator(exp); Date nextTimePoint = cronSequenceGenerator.next(new Date()); 判断时间是否整点或者半点执行1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495package com.xxx.xxx.utils;import java.util.Calendar;import java.util.Date;import java.util.GregorianCalendar;/** * @Author xujin */public class DateUtil { /** * 判断当前时间是半点 * @return */ public static Boolean judgeTimeIsHalf() { Boolean judgeTimeIsHalf=false; Date date = new Date(); GregorianCalendar gc = new GregorianCalendar(); gc.setTime(date); if (gc.get(gc.MINUTE)==30) { judgeTimeIsHalf= true; } return judgeTimeIsHalf; } /** * 判断当前时间是半点 * @return */ public static boolean judgeTimeIsWhole() { Boolean judgeTimeIsWhole=false; Date date = new Date(); GregorianCalendar gc = new GregorianCalendar(); gc.setTime(date); if ( gc.get(gc.MINUTE)==0 ) { judgeTimeIsWhole= true; } return judgeTimeIsWhole; } public static int getMinute() { Date date = new Date(); GregorianCalendar gc = new GregorianCalendar(); gc.setTime(date); return gc.get(gc.MINUTE); } public static boolean quarztTime(int h,int m) { Boolean isQuarztTime=false; Date date = new Date(); GregorianCalendar gc = new GregorianCalendar(); gc.setTime(date); if((gc.get(gc.HOUR_OF_DAY)==h&amp;&amp;gc.get(gc.MINUTE)==m)) { isQuarztTime= true; } return isQuarztTime; } public static String getHourAndMinute() { Date date = new Date(); GregorianCalendar gc = new GregorianCalendar(); gc.setTime(date); String hour=String.valueOf(gc.get(gc.HOUR_OF_DAY)); String minute=String.valueOf(gc.get(gc.MINUTE)); return hour+minute; } public static void main(String[] args) { System.out.println(getHourAndMinute()); Calendar calendar=Calendar.getInstance(); System.out.println( \"现在是：\"+ calendar.get(GregorianCalendar.YEAR)+\"年\"+ (calendar.get(GregorianCalendar.MONTH)+1)+\"月\"+ calendar.get(GregorianCalendar.DAY_OF_MONTH)+\"日\"+ calendar.get(GregorianCalendar.HOUR)+\"时\"+ calendar.get(GregorianCalendar.MINUTE)+\"分\"+ calendar.get(GregorianCalendar.SECOND)+\"秒\" ); }}","link":"/ex/get-hfs/"},{"title":"使用Java Signal将应用程序从LVS中摘除","text":"摘要:本文主要介绍了，如何使用Java Signal和SignalHandler实现，通过Linux 命令实现kill -s BUS pid和kill -s USR2 pid实现不kill应用进程，把应用程序从LVS中摘除。而不是通过Reset 请求调用。由于只允许本机操作，所以可选方案三种:1.reset 调用更改Status，2.Linux 信号量传递给Java程序 3.配置中心或者XX管理系统后台权限管理，调用reset服务。从安全性和快速解决需求的角度考虑使用Linux 信号量传递给Java程序方案。 Java Signal 概述信号简介信号是在软件层次上对中断机制的一种模拟，在原理上，一个进程收到一个信号与处理器收到一个中断请求可以说是一样的。通俗来讲，信号就是进程间的一种异步通信机制。典型的例子:kill -s SIGKILL pid (即kill -9 pid) 立即杀死指定pid的进程。在上面这个例子中，SIGKILL就是往pid进程发送的信号。 平台相关性 信号具有平台相关性，不同平台下能使用的信号种类是有差异的。在Linux下支持的信号(对比信号列表查看描述) SEGV, ILL, FPE, BUS, SYS, CPU, FSZ, ABRT, INT, TERM, HUP, USR1, USR2, QUIT, BREAK, TRAP, PIPE在Windows下支持的信号 SEGV, ILL, FPE, ABRT, INT, TERM, BREAK 信号选择 为了不干扰正常信号的运作，又能模拟Java异步通知，我们需要先选定一种特殊的信号。通过查看信号列表上的描述，发现 SIGUSR1 和 SIGUSR2 是允许用户自定义的信号。那么选择它们，理论上就不会影响正常功能了。这里我选用了BUS和USR2作为传递信号。原因是USR1在Linux系统下面，很大可能性会被其它应用占用。在本次实践中，就是被占用导致handle出现异常。 实现代码JDK API实现调研 Sun为我们提供了2个方便安装和替换信号处理器的工具类。通过下面的api可以快速实现。 sun.misc.Signal sun.misc.SignalHandler JanusSignalHandler的code1234567891011121314151617181920public class JanusSignalHandler implements SignalHandler { private static Logger logger = LoggerFactory.getLogger(JanusSignalHandler.class); @Override public void handle(Signal signal) { if (null != signal) { signalHandle(signal); } } private void signalHandle(Signal sn) { if (sn.getName().equals(\"BUS\")) { JanusNettyServer.online = false; logger.info(\"Signal name is:SIGBUS,online is:false\"); } else if (sn.getName().equals(\"USR2\")) { JanusNettyServer.online = true; logger.info(\"Signal name is:SIGUSR2,online is:true\"); } else { return; } }} addSingalHook的Code 应用程序启动的时候，调用此方法install signals12345678910private void addSingalHook() { try { JanusSignalHandler janusSignalHandler = new JanusSignalHandler(); // install signals Signal.handle(new Signal(\"BUS\"), janusSignalHandler); Signal.handle(new Signal(\"USR2\"), janusSignalHandler); } catch (IllegalArgumentException e) { logger.error(\"exception:[{}]\", e.getMessage()); } } 部署到Linux程序中Test执行 kill -s BUS pid 从LVS中摘除执行 kill -s USR2 pid 加入LVS中 健康检查result: 总结 本文主要介绍了，如何使用Java Signa和SignalHandler实现，通过Linux 命令实现kill -s BUS pid和kill -s USR2 pid实现不kill应用进程，把应用程序从LVS中摘除。但是在实践过程中，需要选对用户可以自定义的信号量。不然，会误杀应用程序本身。","link":"/ex/java-singal-linux/"},{"title":"Mysql批量执行更新shell脚本","text":"摘要:在生产上执行更新sql，当更新的数据超过上100万的时候，执行更新操作会造成卡表或者锁表。本文主要记录一个了批量更新Mysql某张表的数据的脚本代码片。 mysql的批量执行更新1234567891011121314151617181920212223242526#!/bin/bash. ~/.bash_profilelog=/home/apps/update/update_log_1_$(date +%F).logvstart=1step=10000vstop=$((${vstart}+${step}))max=14800000echo \"stop value is $vstop\"while [ ${vstart} -lt $((${max}+1)) ] do echo \"`date +%F-%T`; mysql -uusername -ppwd --default-character-set=utf8 -S /tmp/mysql3306.sock vip_dbname -e\\\"UPDATE tbname set limit_days=3, update_time=now() where pid between ${vstart} and ${vstop}\\\"\" &gt;&gt; ${log} /apps/svr/mysql5/bin/mysql -uusername -ppwd --default-character-set=utf8 -S /tmp/mysql3306.sock vip_dbname -e\"UPDATE tbname set limit_days=3, update_time=now() where pid between ${vstart} and ${vstop} \" vstart=$((${vstop}+1)) vstop=$((${vstop}+${step})) if [ ${vstop} -gt ${max} ]; then vstop=${max} fi sleep 1 #echo \"start at ${vstart}, stop at ${vstop}\"done","link":"/ex/mysql-batch-update/"},{"title":"Jdk的万能配置","text":"java是通过java虚拟机来解释运行的,也就是通过java命令; javac编译生成的.class文件就是虚拟机要执行的代码, 称之为字节码(bytecode),虚拟机通过classloader来装载这些字节码,也就是通常意义上的类.这里就有一个问题,classloader从哪里知道java本身的类库及用户自己的类在什么地方呢?或者有着缺省值(当前路径).或者要有一个用户指定的变量来表明, 这个变量就是类路径(classpath),或者在运行的时候传参数给虚拟机.通过这段文字，你就知道，为什么javac编译通过了，但是java命令却出错(类定义没找到)的原因了。就是环境变量classpath(类路径)没有设置正确，使得JAVA虚拟机的classloader无法找到类来执行目标程序 快速配置1.新建系统变量JAVA_HOME变量(JAVA_HOME指明JDK安装路径。) E:\\development\\Java\\Java8\\jdk1.8.0_73 2.在系统变量中的path中添加(Path使得系统可以在任何路径下识别java命令。) ;%JAVA_HOME%\\bin;%JAVA_HOME%\\jre\\bin; 3、新建系统变量CLASSPATH(CLASSPATH为java加载类(class or lib)路径，只有类在classpath中，java命令才能识别.) 设定值为：.;%JAVA_HOME%\\lib;%JAVA_HOME%\\lib\\tools.jar 注意 一定要加“.”，“.”代表当前目录，即可到处建立.java文件，java class都能找到并编译运行用户的.java文件。 4.进入dos窗口运行“java –version” 如果显示下面内容则成功。","link":"/java/jdk-install/"},{"title":"HashMap多线程死循环问题","text":"摘要：一直都知道Java HashMap使用不当会导致CPU 达到100%的线上故障，以及怎么造成的，怎么在使用过程中进行规避，由于时间的关系。最近整理如本文所示。 一.HashMap出现死循环原因1.1 什么是线程安全当多个线程访问某一个类(对象和方法)时，这个类的对象或方法都能始终表现出正确的行为或者我们想要的结果，我们就认为其是线程安全的，否则非线程安全。我们都知道HashMap是非线程安全的，那怎么使用HashMap会导致CPU占用率达到100%。 之所以会导致HashMap出现死循环是因为多线程会导致HashMap的Entry节点形成环链，这样当遍历集合时Entry的next节点由于不为空，从而形成死循环，从而导致CPU达到100% 1.2 为何出现死循环简要说明HashMap是非线程安全的，在高并发场景下，如果不能保持足够的同步，就有可能在执行HashMap.get时进入死循环，将CPU的消耗到100%。 HashMap采用链表解决Hash冲突。因为是链表结构，那么就很容易形成闭合的链路，这样在循环的时候只要有线程对这个HashMap进行get操作就会产生死循环， 单线程情况下，只有一个线程对HashMap的数据结构进行操作，是不可能产生闭合的回路的。 只有在多线程并发的情况下才会出现这种情况，那就是在put操作的时候，如果size&gt;initialCapacity*loadFactor，hash表进行扩容，那么这时候HashMap就会进行rehash操作，随之HashMap的结构就会很大的变化。很有可能就是在两个线程在这个时候同时触发了rehash操作，产生了闭合的回路。 二.HashMap死循环原因分析2.1 问题的症状在多线程下使用HashMap，到了线上之后，我们发现程序经常占了100%的CPU，查看堆栈，你会发现程序都Hang在了HashMap.get()这个方法上了，重启程序后问题消失。但是过段时间又会来。而且，这个问题在测试环境里可能很难重现。 2.2 为什么会造成死循环HashMap采用链表解决Hash冲突，因为是链表结构，那么就很容易形成闭合的链路，这样在循环的时候只要有线程对这个HashMap进行get操作就会产生死循环。但是，我好奇的是，这种闭合的链路是如何形成的呢。在单线程情况下，只有一个线程对HashMap的数据结构进行操作，是不可能产生闭合的回路的。那就只有在多线程并发的情况下才会出现这种情况，那就是在put操作的时候，如果size&gt;initialCapacity*loadFactor，那么这时候HashMap就会进行rehash操作，随之HashMap的结构就会发生翻天覆地的变化。很有可能就是在两个线程在这个时候同时触发了rehash操作，产生了闭合的回路。 三.参考文章http://blog.csdn.net/xuefeng0707/article/details/40797085 http://coolshell.cn/articles/9606.html http://firezhfox.iteye.com/blog/2241043 http://www.cnblogs.com/kxdblog/p/4323892.html http://www.cnblogs.com/ITtangtang/p/3966467.html http://blog.csdn.net/xuefeng0707/article/details/40797085http://blog.csdn.net/zhuqiuhui/article/details/51849692","link":"/java/hm02/"},{"title":"Dive into Venus Boot","text":"摘要: Venus Boot是Spring Boot的瘦身版，基于Spring Boot结合项目实战抽离，以中间件思想即插即用的开源项目集合。 一.Venus Boot概述1.1 venus Boot概述 Venus Boot是Spring Boot的瘦身版，基于Spring Boot结合项目实战抽离，以中间件思想即插即用的开源项目集合。Venus Boot基于 Spring Boot 的中间件轻量集成方案，与标准的 Spring Boot 工程无缝集成。其在完美集成市面上最优中间件的前提下对用户提供了易用、统一的编程界面。 1.2 Venus Boot特性Venus boot底层是基于 Spring Boot 的，天生便可与 Spring Boot，Spring 工程无缝集成，大大减少了用户的迁移成本。 二.Venus Boot2.1 项目列表 名称 版本 状态 备注 venus-boot 1.0.0 todo venus-boot-mybatis 1.0.0 todo venus-boot-orika 1.0.0 venus-boot-maven 1.0.0 venus-boot-swagger 1.0.0 todo Venus-boot-swagger-ui 1.0.0 todo Venus-boot-httpclient 1.0.0 todo 2.2 venus-boot地址:https://github.com/venus-boot/venus-boot 2.3 venus-boot-orikahttps://github.com/venus-boot/venus-boot-orika 2.4 venus-boot-swaggerhttps://github.com/venus-boot/venus-boot-swagger 2.5 venus-boot-mybatishttps://github.com/venus-boot/venus-boot-mybatis 2.6 venus-boot-mavenhttps://github.com/venus-boot/venus-boot-maven","link":"/vb/01/"},{"title":"并发编程总结之volatile","text":"摘要:本节主要介绍了 volatile关键字的作用是使变量在多个线程间可见,但是不具有原子性，以及volatile的运行内存介绍。 在java中，每个线程都会有一块工作内存区，其中存放着所有线程共享的主内存中的变量值的拷贝。当线程执行时，它在自己的工作区内存中操作这些变量。为了存取一个共享的变量，一个线程通常会先获取锁定并清除它的内存工作区，把这些共享变量从所有线程的共享内存中正确的装入到它自己所在的工作内存中，当线程解锁时，保证该工作内存中变量的值写回到共享内存中。 volatile的作用就是强制线程到主内存(共享内存)里去读取变量，而不去线程工作区内存里去读取，从而实现了多个线程间的变量可见，也就是满足线程安全的可见性。 volatile概念volatile概念-具有可见性 volatile关键字的作用是使变量在多个线程间可见。 代码示例如下代码所示，当isRunning没有被volatile关键字修饰的时候，程序一直循环，线程不会结束。123456789101112131415161718192021222324252627public class RunThread extends Thread { // isRunning没有被volatile关键字修饰 private boolean isRunning = true;//① private void setRunning(boolean isRunning) { this.isRunning = isRunning; } public void run() { System.out.println(\"开始进入run方法..\"); while (isRunning == true) { // 一直循环........ } System.out.println(\"while循环结束,线程停止\"); } public static void main(String[] args) throws InterruptedException { RunThread rt = new RunThread(); rt.start(); Thread.sleep(3000); rt.setRunning(false); System.out.println(\"isRunning的值已经被设置了false\"); Thread.sleep(1000); System.out.println(rt.isRunning); }} 当把上述代码的①处，修改为如下时:1private volatile boolean isRunning = true; 运行结果是isRunning修改为false之后，线程读取到isRunning = false，从而线程结束while循环，线程退出1234开始进入run方法..isRunning的值已经被设置了falsewhile循环结束,线程停止false 示例代码线程操作内存简图 小结 在java中，每个线程都会有一块工作内存区，其中存放着所有线程共享的主内存中的变量值得拷贝。当线程执行时，它在自己的工作区内存中操作这些变量。为了存取一个共享的变量，一个线程通常会先获取锁定并清除它的内存工作区，把这些共享变量从所有线程的共享内存中正确的装入到它自己所在的工作内存中，当线程解锁时，保证该工作内存中变量的值写回到共享内存中。 一个线程可以执行的操作有使用(use)，赋值(assign),装载(load),存储(store),锁定(lock),解锁(unlock)。而主内存可以执行的操作有读(read),写(write),锁定(lock),解锁（unlock)，每个操作都是原子的。 volatile的作用就是强制线程到主内存(共享内存)里去读取变量，而不去线程工作区内存里去读取，从而实现了多个线程间的变量可见，也就是满足线程安全的可见性。 volatile-不具有原子性 volatile关键字虽然拥有多个线程之间的可见性，但是不具备同步性，也就是原子性，可以算得上一个轻量级别的synchronized,性能要比synchronized强很多，不会造成阻塞(在很多开源框架，比如Netty的底层代码就大量的使用volatile，由此可见Netty的性能非常不错),但是需要注意的是，volatile用于只针对于多个线程可见的变量操作，并不能替代synchronized的同步功能。 示例代码112345678910111213141516171819202122232425public class VolatileNoAtomic extends Thread { private static volatile int count; private static void addCount() { for (int i = 0; i &lt; 1000; i++) { count++; } System.out.println(count); } public void run() { addCount(); } public static void main(String[] args) { VolatileNoAtomic[] arr = new VolatileNoAtomic[100]; for (int i = 0; i &lt; 10; i++) { arr[i] = new VolatileNoAtomic(); } for (int i = 0; i &lt; 10; i++) { arr[i].start(); } }} 运行结果，随机因为volatile没有原子性，所以最终打印结果不是10000 示例代码2123456789101112131415161718192021222324252627public class VolatileNoAtomic extends Thread { private static AtomicInteger count = new AtomicInteger(0); private static void addCount() { for (int i = 0; i &lt; 1000; i++) { count.incrementAndGet(); } System.out.println(count); } public void run() { addCount(); } public static void main(String[] args) { VolatileNoAtomic[] arr = new VolatileNoAtomic[100]; for (int i = 0; i &lt; 10; i++) { arr[i] = new VolatileNoAtomic(); } for (int i = 0; i &lt; 10; i++) { arr[i].start(); } }} 运行最终打印结果是:10000 小结:volatile关键字只有可见性，没有原子性。要实现原子性建议使用atomic类的系列对象，支持原子性操作。 注意atomic类只保证本身方法的原子性，并不保证多次操作的原子性。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package org.xujin.multithread.sync007;import java.util.ArrayList;import java.util.List;import java.util.concurrent.atomic.AtomicInteger;/** * @author xujin */public class AtomicUse { private static AtomicInteger count = new AtomicInteger(0); // 多个addAndGet在一个方法内是非原子性的，需要加synchronized进行修饰，保证4个addAndGet整体原子性 /** synchronized */ public synchronized int multiAdd() { try { Thread.sleep(100); } catch (InterruptedException e) { e.printStackTrace(); } count.addAndGet(1); count.addAndGet(2); count.addAndGet(3); count.addAndGet(4); // +10,执行到这里相当于加10-&gt;1+2+3+4=10， return count.get(); } public static void main(String[] args) { final AtomicUse au = new AtomicUse(); List&lt;Thread&gt; ts = new ArrayList&lt;Thread&gt;(); for (int i = 0; i &lt; 100; i++) { ts.add(new Thread(new Runnable() { @Override public void run() { System.out.println(au.multiAdd()); } })); } for (Thread t : ts) { t.start(); } }}","link":"/bf/bf-volatile/"},{"title":"并发编程总结之同类容器和异步容器","text":"一. 同步类容器1.1 同步类容器都是线程安全的，但在某些场景下可能需要加锁来保护复合操作。 复合操作如： 迭代(反复访问元素，遍历容器中所有的元素)， 跳转（根据指定的顺序找到当前元素的下一个元素），以及条件运算。 这些复合操作在多线并发地修改容器时，可能会表现出意外的行为，最经典的便是ConcurrentModificationException，原因是当容器迭代的过程中，被并发的修改了内容，这是由于早期迭代器设计的时候并没有考虑并发修改的问题。 1234567891011121314151617public class Tickets { public static void main(String[] args) { //初始化火车票池并添加火车票:避免线程同步可采用Vector替代ArrayList HashTable替代HashMap final Vector&lt;String&gt; tickets = new Vector&lt;String&gt;(); for (int i = 1; i &lt;= 1000; i++) { tickets.add(\"火车票\" + i); } for (Iterator iterator = tickets.iterator(); iterator.hasNext(); ) { String string = (String) iterator.next(); tickets.remove(20); } }} 运行出现，如下错误: 1234Exception in thread &quot;main&quot; java.util.ConcurrentModificationException at java.util.Vector$Itr.checkForComodification(Vector.java:1184) at java.util.Vector$Itr.next(Vector.java:1137) at org.xujin.janus.poc.server.Tickets.main(Tickets.java:35) 1.2 同步类容器:如古老的Vector，HashTable。这些容器的同步功能其实都是由jdk的Collections.synchronized*** 比如:Collections.synchronizedMap等工厂方法去创建实现的。比如,如下： 1Map&lt;String, String&gt; map = Collections.synchronizedMap(new HashMap&lt;String, String&gt;()); 本身hashMap不是线程安全的，但是Collections.synchronizedMap(new HashMap&lt;String, String&gt;())工厂方法包裹之后，就变成线程安全的。 其底层的机制无非就是传统的synchronized关键字对每个公用的方法都进行同步，使得每次只能有一个线程访问容器的状态。这很明显不满足我们今天互联网时代高并发的需求，在保证线程安全的同时，也必须要有足够好的性能。 123456789101112131415161718192021public class Tickets { public static void main(String[] args) { final Vector&lt;String&gt; tickets = new Vector&lt;String&gt;(); for (int i = 1; i &lt;= 1000; i++) { tickets.add(\"火车票\" + i); } for (int i = 1; i &lt;= 10; i++) { new Thread(\"线程\" + i) { public void run() { while (true) { if (tickets.isEmpty()) break; System.out.println(Thread.currentThread().getName() + \"---\" + tickets.remove(0)); } } }.start(); } }} Ps:在实际开发中，尽量使用并发类容器替代同步类容器。 并发类容器并发类容器概述jdk5.0之后提供了多种并发类容器来替代同步类容器从而改善性能。同步类容器的状态都是串行化的，他们虽然实现了线程安全，但是严重降低了并发性，在多线程环境时，严重降低了应用程序的吞吐量。 并发类容器是专门针对并发设计的，使用ConcurrentHashMap来替代给予散列的传统hashTable，而且在ConcurrentHashMap中，添加了一些常见复合操作的支持。以及使用了CopyOnWriteArrayList代替Voctor，并发的CopOnwriteArraySet，以及并发的Queue，ConcurrentLinkedQueue和LinkedBlockingQueue，前者是高性能的队列，后者是以阻塞形式的队列，具体实现Queue还有很多，例如ArrayBlockQueue，PriorityBlockingQueue，SynchronousQueue等。 ConcurrentMapConcurrentMap接口下有两个重要的实现: ConcurrentHashMap,ConcurrentSkipListMap(支持并发排序功能，弥补ConcurrentHashMap) ConcurrentHashMap内部使用分段锁(segment)来标识这些不同的部门，在每个段其实就是一个小的hashTable，它们有自己的锁。只要多个修改操作发生在不同的段上，它们就是可以并发进行。把一个整体划分成了16个段(segment)。也就是最高支持16个线程的并发修改操作，这也是在多线程场景时减小锁的粒度从而减低锁竞争的一种方案。并且代码中大多共享变量使用volatile关键字声明，目的是第一时间获取修改的内容，性能非常好。 ConcurrentHashMap最高支持分16个段。 Copy-On-Write容器 未完待续。。。。。","link":"/bf/bf01/"},{"title":"基础架构及中间件体系概述","text":"摘要: 本文主要是记录自己对基础架构职责和中间件技术体系理解的，渐进式理解记录。 一.基础架构职责 设计和开发新一代的基础组件，为重构项目提供技术平台 设计和构建统一的应用开发框架，提高应用开发效率和质量 建立统一的应用构建标准，为实现对应用的管理，监控和治理的自动化建立基础 评估和引进各种国外先进技术，提高公司平台的技术水准 建立公司的开源项目，对内部开发的含金量高的项目实现开源，以提高公司的知名度 二.基础架构解决方案2.1 技术体系方案 这些技术解决方案包括：统一的服务化框架体系 服务化是IT技术架构升级改造的核心内容，提供统一的完整的服务化框架体系尤为重要，该体系为构建“分布式服务架构”提供了技术平台，它涵盖了构建和管理一个服务的整个生命周期所需的各种框架和工具。 移动客户端和服务端中间层框架 随着越来越多的用户使用移动App购物，快速研发不同的移动App十分重要，因此构建统一的移动客户端和服务端中间层框架就十分有意义，它不仅能加快移动App的研发，也为提高移动App的产品质量提供了保障。 系统集成组件—消息总线 随着互联网应用平台包含各种各样的应用，各应用之间需要保持不同形式的信息交换，有些是同步的，有些是异步的，系统集成组件—消息总线则提供了一组组件以满足应用之间异步通讯之需要。 服务的授权，监控和治理随着系统变得越来越大，越来越复杂，服务数目越来越多，如何对该庞大的系统进行有效的管理，安全的管控以及服务质量的监控就非常重要，因此需要有一整套的工具确保监控，授权和服务的治理。 三.目前中间件3.1 服务治理中间件 例如：dubbo，Spring Cloud等 3.2 服务网关中间件Spring Cloud Zuul，包括目前自研的Janus网关 3.2 配置中心例如:Spring Cloud Config，携程阿波罗 3.3 全链路监控例如:点评Cat，Spring Cloud Selut+Pinpoint，唯品的Mercury 3.4 应用框架应用框架存在的意义就是把分散的中间件，以最佳案例使用的方式，结合代码生成器，生成一套带有公司风格的代码。 3.5 数据库中间件例如:Mycat,Kingsoft(Go语言) 3.6 代码生成器工业化生成代码，提高开发效率，代码质量。 3.7 多级缓存或分布式缓存3.8 服务鉴权中间件3.9 消息中间件3.10 分布式调度中心Scheduler 是定时任务调度中心，旨在为业务系统提供统一通用的任务调度服务，提供定时任务的管理监控平台，减轻业务系统开发和后续线上运维的工作量，并通过任务拆分和负载均衡等方案提升大数据量任务的性能。 集中管控：开发人员和配置管理员可以在界面上配置管理做任意周期性调度任务。触发策略可定制:提供可定制化的策略脚本，满足各种业务不同的定制化需求。高性能:显著提升大数据量的批任务处理的性能。 Switch开关中间件开关switch提供统一的方式来定义开关、统一的控制台和api来对开关进行查询和操控。Switch定义的开关包含丰富的可读性属性，为开关信息的维护和传承提供便利。 优点使用简单:switch框架提供非常简单的使用方式，对应用方原来的使用侵入小 功能 未完待续。。。。。","link":"/mw/insArch/"},{"title":"代码生成器的设计","text":"摘要: 本文主要讲述什么是代码生成器和代码生成器相关的设计，以及由Venus Team(Spring Cloud中国社区开源组织）打造的针对Spring Cloud的代码生成器 代码生成器什么是代码生成器 早起进行软件工程开发，用文本编辑器去开发写代码，后来为了加快开发效率，出现一系列IDE（开发集成开发工具),比如Eclipse,IDEA等。创建Maven或者Gradle工程都是通过IDE去创建，但是有些重复的工作，比如单表的CRUD操作，或者重复性劳动的配置，包括Maven或者Gradle的配置。 代码生成器现状代码生成器设计如下图所示，代码生成器的生成的工程，由元数据+模板(工程模板或代码模板)组装而成。 元数据 模板 Smart CodeGen","link":"/mw/codegen01/"},{"title":"Hexo使用技巧汇总","text":"摘要: 本文主要记录在Node,hexo等使用经验。 使用淘宝镜像安装npm install hexo –save –registry=https://registry.npm.taobao.org npm install –registry=https://registry.npm.taobao.org npm install hexo-cli -g –registry=https://registry.npm.taobao.org npm install –save hexo-renderer-sass –registry=https://registry.npm.taobao.org 自己的主题https://segmentfault.com/a/1190000010065946 sudo npm install -g n –registry=https://registry.npm.taobao.org 升级Node.js版本http://blog.csdn.net/chwshuang/article/details/54965100","link":"/node/01/"},{"title":"云计算Saas的简单描述以及多租户实现和Saas部署图","text":"一.SAAS概述与概念1.1 Saas概述 传统软件开发模式是软件即产品，但是云计算Saas是软件即服务，也就是说使用软件就像使用服务一样。SaaS的应用越来越流行了，它作为越来越多的公有云提供基础的应用平台服务，有效减少中小企业的前期投入及运营成本，使得中小企业在成立发展过程中，把更多的精力投入于发展业务，更多的信息化管理不用关注。 从以前中小企业使用后，中大型企业慢慢也接受这种模式，特别是微信的流行后，很多中大型企业也把可以对外的或授权对外的信息，通过自身建设的平台或第三方的SaaS平台发布出来，借助微信的社区朋友圈，有效扩展业务及维护客户关系。建设及维护这种第三方的平台，是企业必须要考虑的，像传统的很多开发商，借助自身的开发及客户资源，正在打造自己行业内的SaaS应用平台。而大型企业，则考虑如何通过Saas应用统一规范其下的分公司或部门的业务管理，希望达到业务可分或汇。 在设计及说明SaaS平台的实现方案时， 1.2 SaaS的几个重要的概念我们先来说明一下以下的概念： 租户：表示SaaS的一个独立法人组织，如企业、单位和团体等。租户在系统中表现为一个注册机构组织。 租户用户：每个租户下面有若干用户，用户是实际使用系统的人。 租户用户组：每个租户会对其下面的用户进行分组管理 二.多租户的实现多租户最主要的就是数据的隔离与共享，数据隔离级别越高，共享程度越低。在以往实施过的项目中，同样有SaaS的业务扩展需求，细节各有不同，但实现方式总体而言可以归纳为下面两大类： 1.独立Schema,即每个租户单独一套数据库 优点是:数据隔离级别相对高，对于数据的安全性很好。 缺点是：数据隔离级别相对高，浪费资源。比如：对于注册使用的用户来说，通过数据库隔离就浪费资源。 2.共享Schema、通过租户区分数据，所有租户共享数据 缺点是：数据隔离级别相对低，数据安全性不是很好，但是这种隔离方式适合基础的公共的数据隔离。 三.SaaS的部署模式 如图所示，Saas统一访问服务器为统一管理入口，主要用于对Saas整个系统的运营管理，比如计费，Saas应用购买等等。 Saas中央数据库，记录着多组户用户的信息，租户登陆时，Saas统一访问服务器验证check之后，通过动态数据切换，切换到租户 对应的Saas应用上去。 所有租户的访问统一地址 租户要使用平台，先需要统一注册，注册信息存放在中央数据库，由平台的管员进行统一审批管理员根据的租户的用户的使用规模及数据量，选择是共享数据库还是独立数据库，同时根据应用的访问量，是否扩展多台应用服务器 目前在流行的开发语言中，要实现这些业务租用及业务扩展，目前均无标准化的开发模式，仅有一些大型的软件厂商上作了一些云应用的开发，但他们都不会公开这些开发模式的源代码。因此对于一些想实现类似业务的企业或软件厂商，只能自身进行研发。 根据目前JAVA流行的轻量级框架进行封装及扩展，打造适合中国国情的SAAS应用开发平台。而国内目前更多的是私有云的建设，公有云应用也越来越流行，也慢慢被很多中大型企业接受。因此通常会选择两种方案混合来实现SaaS应用，即共享数据库与独立数据库。而客户在实施时，可根据业务的需要，进行配置使用。 如：集团需要上一套CRM，即可选择共享数据库，因为集团内的CRM数据需要共享及统一管理。而某政府部门需要上一套行政审批系统，其各个子级部门数据需要单独分割并不可访问，并且有自身的个性化要求，这时建议采用独立数据库模式","link":"/saas/saas/"},{"title":"Spring Cloud Gateway翻译","text":"摘要: 本文主要对Spring Cloud Gateway v2.0.0.M3原文地址 版本文档进行翻译,持续更新至稳定版本，然后公布。 spring-cloud-gatewayThis project provides an API Gateway built on top of the Spring Ecosystem, including: Spring 5, Spring Boot 2 and Project Reactor. Spring Cloud Gateway aims to provide a simple, yet effective way to route to APIs and provide cross cutting concerns to them such as: security, monitoring/metrics, and resiliency. 这个项目提供了一个构建在Spring生态系统之上的API网关，包括：Spring 5，Spring Boot 2和Project Reactor。 Spring Cloud Gateway旨在提供一种简单而有效的API路由方式，并为其提供横切关注点，例如：安全，监控/指标，和弹性。 How to Include Spring Cloud GatewayTo include Spring Cloud Gateway in your project use the starter with group org.springframework.cloud and artifact id spring-cloud-starter-gateway. See the Spring Cloud Project page for details on setting up your build system with the current Spring Cloud Release Train. 要在项目中包含Spring Cloud Gateway，请使用组org.springframework.cloud和工件id spring-cloud-starter-gateway。请参阅Spring Cloud Project页面，以获取有关使用当前Spring Cloud Release Train设置构建系统的详细信息。 If you include the starter, but, for some reason, you do not want the gateway to be enabled, set spring.cloud.gateway.enabled=false. 如果你项目中包含了Spring Cloud Gateway这个starter，但是由于某种原因，你不想让它在你的项目中生效，你可以设置spring.cloud.gateway.enabled=false Glossary Route: Route the basic building block of the gateway. It is defined by an ID, a destination URI, a collection of predicates and a collection of filters. A route is matched if aggregate predicate is true. 路由：路由是网关的基本构建模块。它由一个ID，一个目标URI，一组断言和一个过滤器的集合定义。如果聚合谓词为真，则路由匹配 Predicate: This is a Java 8 Function Predicate. The input type is a Spring Framework ServerWebExchange. This allows developers to match on anything from the HTTP request, such as headers or parameters. 谓词：这是一个Java 8函数谓词。输入类型是一个Spring框架的ServerWebExchange。这允许开发人员匹配来自HTTP请求的任何内容，例如标题或参数 Filter: These are instances Spring Framework GatewayFilter constructed in with a specific factory. Here, requests and responses can be modified before or after sending the downstream request. 过滤器：这是实例Spring Framework GatewayFilter与特定工厂构建的实例。这里，可以在发送下游请求之前或之后修改请求和响应 How It WorksClients make requests to Spring Cloud Gateway. If the Gateway Handler Mapping determines that a request matches a Route, it is sent to the Gateway Web Handler. This handler runs sends the request through a filter chain that is specific to the request. The reason the filters are divided by the dotted line, is that filters may execute logic before the proxy request is sent or after. All “pre” filter logic is executed, then the proxy request is made. After the proxy request is made, the “post” filter logic is executed. Route Predicate FactoriesSpring Cloud Gateway matches routes as part of the Spring WebFlux HandlerMapping infrastructure. Spring Cloud Gateway includes many built-in Route Predicate Factories. All of these predicates match on different attributes of the HTTP request. Multiple Route Predicate Factories can be combined and are combined via logical and. After Route Predicate FactoryThe After Route Predicate Factory takes one parameter, a datetime. This predicate matches requests that happen after the current datetime. application.yml 123456789spring: cloud: gateway: routes: # ===================================== - id: after_route uri: http://example.org predicates: - After=2017-01-20T17:42:47.789-07:00[America/Denver] This route matches any request after Jan 20, 2017 17:42 Mountain Time (Denver). Before Route Predicate FactoryThe Before Route Predicate Factory takes one parameter, a datetime. This predicate matches requests that happen before the current datetime. application.yml 123456789spring: cloud: gateway: routes: # ===================================== - id: before_route uri: http://example.org predicates: - Before=2017-01-20T17:42:47.789-07:00[America/Denver] This route matches any request before Jan 20, 2017 17:42 Mountain Time (Denver). Between Route Predicate FactoryThe Between Route Predicate Factory takes two parameters, datetime1 and datetime2. This predicate matches requests that happen after datetime1 and before datetime2. The datetime2 parameter must be after datetime1. application.yml 123456789spring: cloud: gateway: routes: # ===================================== - id: between_route uri: http://example.org predicates: - Betweeen=2017-01-20T17:42:47.789-07:00[America/Denver], 2017-01-21T17:42:47.789-07:00[America/Denver] This route matches any request after Jan 20, 2017 17:42 Mountain Time (Denver) and before Jan 21, 2017 17:42 Mountain Time (Denver). This could be useful for maintenance windows. Cookie Route Predicate FactoryThe Cookie Route Predicate Factory takes two parameters, the cookie name and a regular expression. This predicate matches cookies that have the given name and the value matches the regular expression. application.yml 123456789spring: cloud: gateway: routes: # ===================================== - id: cookie_route uri: http://example.org predicates: - Cookie=chocolate, ch.p This route matches the request has a cookie named chocolate who’s value matches the ch.p regular expression. Header Route Predicate FactoryThe Header Route Predicate Factory takes two parameters, the header name and a regular expression. This predicate matches with a header that has the given name and the value matches the regular expression. application.yml 123456789spring: cloud: gateway: routes: # ===================================== - id: header_route uri: http://example.org predicates: - Header=X-Request-Id, \\d+ This route matches if the request has a header named X-Request-Id whos value matches the \\d+ regular expression (has a value of one or more digits). Host Route Predicate FactoryThe Host Route Predicate Factory takes one parameter: the host name pattern. The pattern is an Ant style pattern with . as the separator. This predicates matches the Host header that matches the pattern. application.yml 123456789spring: cloud: gateway: routes: # ===================================== - id: host_route uri: http://example.org predicates: - Host=**.somehost.org This route would match if the request has a Host header has the value www.somehost.org or beta.somehost.org. Method Route Predicate FactoryThe Method Route Predicate Factory takes one parameter: the HTTP method to match. application.yml 123456789spring: cloud: gateway: routes: # ===================================== - id: method_route uri: http://example.org predicates: - Method=GET This route would match if the request method was a GET. Path Route Predicate FactoryThe Path Route Predicate Factory takes one parameter: a Spring PathMatcher pattern. 123456789spring: cloud: gateway: routes: # ===================================== - id: host_route uri: http://example.org predicates: - Path=/foo/{segment} This route would match if the request path was, for example: /foo/1 or /foo/bar. This predicate extracts the URI template variables (like segment defined in the example above) as a map of names and values and places it in the ServerWebExchange.getAttributes() with a key defined in PathRoutePredicate.URL_PREDICATE_VARS_ATTR. Those values are then available for use byGatewayFilter Factories Query Route Predicate FactoryThe Query Route Predicate Factory takes two parameters: a required param and an optional regexp. application.yml 123456789spring: cloud: gateway: routes: # ===================================== - id: query_route uri: http://example.org predicates: - Query=baz This route would match if the request contained a baz query parameter. application.yml 123456789spring: cloud: gateway: routes: # ===================================== - id: query_route uri: http://example.org predicates: - Query=foo, ba. This route would match if the request contained a foo query parameter whose value matched the ba. regexp, so bar and baz would match. RemoteAddr Route Predicate Factory（远程地址路由Predicate工厂） 远程地址路由Predicate工厂需要维护一个CIDR-notation的字符串列表，该列表的大小大于1，比如192.168.0.1/16 (192.168.0.1一个ip地址，16 是一个子网掩码。 配置文件application.yml如下： 123456789spring: cloud: gateway: routes: # ===================================== - id: remoteaddr_route uri: http://example.org predicates: - RemoteAddr=192.168.1.1/24 这个路由将会匹配比如像192.168.1.10这样的远程请求。 GatewayFilter Factories（网关过滤器工厂链）路由过滤器能够以某种方式允许修改进入的Http请求或输出的对外的Http响应。路由过滤器的作用域是一个特定的路由。 Spring Cloud Gateway包含许多内置的GatewayFilter工厂。 AddRequestHeader GatewayFilter Factory（添加请求头的过滤器工厂）添加请求头的过滤器工厂可以在请求头中添加一对键值对参数。 配置文件application.yml： 12345678910spring: cloud: gateway: routes: # ===================================== - id: add_request_header_route uri: http://example.org filters: - AddRequestHeader=X-Request-Foo, Bar 以上的配置会将X-Request-Foo：Bar头添加到所有匹配请求的下游请求头。 AddRequestParameter GatewayFilter Factory（添加请求参数的过滤器工厂）添加请求参数的过滤器工厂可以在请求中添加一对请求参数的键值对。 123456789spring: cloud: gateway: routes: # ===================================== - id: add_request_parameter_route uri: http://example.org filters: - AddRequestParameter=foo, bar 以上的配置会将foo：bar参数添加到所有匹配请求的下游请求中。 AddResponseHeader GatewayFilter Factory（添加响应头的过滤器工厂）添加响应头的过滤器工厂可以在响应头中添加键值对。 配置文件application.yml： 123456789spring: cloud: gateway: routes: # ===================================== - id: add_request_header_route uri: http://example.org filters: - AddResponseHeader=X-Response-Foo, Bar 以上的配置会将X-Response-Foo, Bar头添加到所有匹配请求的下游请求的相响应头中。 Hystrix GatewayFilter Factory（熔断过滤器工厂）Hystrix GatewayFilter Factory采用单个名称的参数，即HystrixCommand的名称。 （未来版本中可能会添加更多选项）。 配置文件application.yml： 123456789spring: cloud: gateway: routes: # ===================================== - id: hytstrix_route uri: http://example.org filters: - Hystrix=myCommandName 以上的配置将使用命令名称myCommandName将剩余的过滤器包装在HystrixCommand中。 PrefixPath GatewayFilter Factory（前缀路径过滤器工厂）前缀路径过滤器工厂使用的是一个简单的prefix参数。 配置文件application.yml： 123456789spring: cloud: gateway: routes: # ===================================== - id: prefixpath_route uri: http://example.org filters: - PrefixPath=/mypath 这将前缀/mypath到所有匹配的请求的路径。 所以/hello的请求将被发送到/mypath/hello。 RequestRateLimiter GatewayFilter Factory（请求限流过滤器工厂）请求限流过滤器工厂需要三个参数：replenishRate, burstCapacity 和keyResolverName. replenishRate 允许用户每秒处理多少个请求。 burstCapacity TODO：文件的爆发能力 keyResolver是一个实现KeyResolver接口的bean。在配置中，使用SpEL通过名称引用bean。＃{@myKeyResolver}是引用名为myKeyResolver的bean的SpEL表达式。 KeyResolver.java 123public interface KeyResolver { Mono&lt;String&gt; resolve(ServerWebExchange exchange);} KeyResolver接口允许可插入策略派生出限制请求的密钥。 在未来的里程碑版本中，将会有一些KeyResolver具体实现类。 Redis的实现基于Stripe工作的。 它需要使用spring-boot-starter-data-redis-reactive 的起步依赖。 配置文件application.yml： 123456789spring: cloud: gateway: routes: # ===================================== - id: requestratelimiter_route uri: http://example.org filters: - RequestRateLimiter=10, 20, #{@userKeyResolver} Config.java 1234@BeanKeyResolver userKeyResolver() { return exchange -&gt; Mono.just(exchange.getRequest().getQueryParams().getFirst(&quot;user&quot;));} 以上的配置定义了每个用户10个请求速率限制。 KeyResolver是一个简单的获取用户请求参数（注意：这不建议用于生产）。 RedirectTo GatewayFilter Factory（重定向过滤器工厂）重定向过滤器工厂接受一个状态和一个url参数。 该状态是一个300系列重定向http代码，如301.该网址应该是一个有效的网址。 并将它们组合成一个Location的header. 配置文件application.yml： 123456789spring: cloud: gateway: routes: # ===================================== - id: prefixpath_route uri: http://example.org filters: - RedirectTo=302, http://acme.org 以上的配置将使用Location：http：//acme.org标头发送状态302以执行重定向。 RemoveNonProxyHeaders GatewayFilter Factory（去掉非代理头的过滤器工厂）去掉非代理头的过滤器工厂从转发的请求中删除请求头。 被删除的请求头的默认列表来自IETF。 默认删除请求头如下： Connection Keep-Alive Proxy-Authenticate Proxy-Authorization TE Trailer Transfer-Encoding Upgrade 要改变这一点，请将spring.cloud.gateway.filter.remove-non-proxy-headers.headers属性设置为要删除的标题名称列表。 RemoveRequestHeader GatewayFilter Factory（去掉请求头的过滤器工厂）去掉请求头的过滤器工厂需要一个名称的参数，这个名称参数是需要去掉的请求头名。 配置文件application.yml： 123456789spring: cloud: gateway: routes: # ===================================== - id: removerequestheader_route uri: http://example.org filters: - RemoveRequestHeader=X-Request-Foo 以上的配置将在下游发送之前删除X-Request-Foo头。 RemoveResponseHeader GatewayFilter Factory （去掉响应头的过滤器工厂）去掉响应头的过滤器工厂需要一个名称的参数，这个名称参数是需要去掉的响应头名。 配置文件application.yml： 123456789spring: cloud: gateway: routes: # ===================================== - id: removeresponseheader_route uri: http://example.org filters: - RemoveResponseHeader=X-Response-Foo 这将在返回到网关客户端之前从响应中删除X-Response-Foo头。 RewritePath GatewayFilter Factory（重些url路径的过滤器工厂）重些url网关过滤器工厂采用路径正则表达式参数和一个替换参数。 使用的是Java正则表达式来灵活地重写请求路径。 配置文件application.yml： 12345678910spring: cloud: gateway: routes: # ===================================== - id: rewritepath_route uri: http://example.org - Path=/foo/** filters: - RewritePath=/foo/(?&lt;segment&gt;.*), /$\\{segment} 以上的配置，对于/foo/bar的请求路径，将在进行下游请求之前将路径设置为/ bar。 注意由于YAML规范，”$\\” 被 “$” 替换。 SecureHeaders GatewayFilter Factory（安全头过滤工厂）安全头过滤工厂给响应添加了一些列的安全头，这些安全头在这篇文章有详细的介绍，文章地址：https://blog.appcanary.com/2017/http-security-headers.html 以下的安全头被采纳，并且有默认值： X-Xss-Protection:1; mode=block Strict-Transport-Security:max-age=631138519 X-Frame-Options:DENY X-Content-Type-Options:nosniff Referrer-Policy:no-referrer Content-Security-Policy:default-src ‘self’ https:; font-src ‘self’ https: data:; img-src ‘self’ https: data:; object-src ‘none’; script-src https:; style-src ‘self’ https: ‘unsafe-inline’ X-Download-Options:noopen X-Permitted-Cross-Domain-Policies:none 如果要更改默认值，在spring.cloud.gateway.filter.secure-headers命名空间中设置适当的属性： 要更改的属性： xss-protection-header strict-transport-security frame-options content-type-options referrer-policy content-security-policy download-options permitted-cross-domain-policies SetPath GatewayFilter Factory（设置路径过滤器工厂）设置路径过滤器工厂需要路径模板参数。 它提供了一种简单的方法来通过允许路径的模板化段来操纵请求路径。 使用了Spring框架的uri模板。 允许多个匹配段。 配置文件application.yml： 1234567891011spring: cloud: gateway: routes: # ===================================== - id: setpath_route uri: http://example.org predicates: - Path=/foo/{segment} filters: - SetPath=/{segment} 对于/foo/bar的请求路径，这将在进行下游请求之前将路径设置为/bar。 SetResponseHeader GatewayFilter Factory（设置响应头网关过滤器工厂）设置响应头网关过滤器工厂需要参数名和参数的值的键值对参数。 配置文件application.yml： 123456789spring: cloud: gateway: routes: # ===================================== - id: setresponseheader_route uri: http://example.org filters: - SetResponseHeader=X-Response-Foo, Bar 这个网关过滤器将用给定的响应头的值替换掉原来请求响应头的值，注意不是添加而是替换。 在上面的配置中，如果下游服务器使用X-Response-Foo：1234进行响应，则将被X-Response-Foo：Bar取代，网关客户端收到的响应头为X-Response-Foo：Bar而不是X-Response-Foo：1234。 SetStatus GatewayFilter Factory (请求响应状态网关过滤器工厂)The SetStatus GatewayFilter Factory takes a single status parameter. It must be a valid Spring HttpStatus. It may be the integer value 404 or the string representation of the enumeration NOT_FOUND. 请求响应网关过滤器工厂需要一个status参数。该参数值必须是一个有效的Spring HttpStatus。该值可以是整型404或者是表示枚举类型NOT_FOUND的字符串。 application.yml 12345678910111213spring: cloud: gateway: routes: # ===================================== - id: setstatusstring_route uri: http://example.org filters: - SetStatus=BAD_REQUEST - id: setstatusint_route uri: http://example.org filters: - SetStatus=401 In either case, the HTTP status of the response will be set to 401. 如上配置下，无论什么情况，http的响应状态都会被置为401 Global Filters （全局过滤器）The GlobalFilter interface has the same signature as GatewayFilter. These are special filters that are conditionally applied to all routes. (This interface and usage are subject to change in future milestones). GlobalFilter全局过滤器接口有和GatewayFilter相同的签名。这些特殊的过滤器有条件性的应用到全部路由中。（这类接口和用法将会在未来里程碑版本中发生变化） Combined Global Filter and GatewayFilter Ordering （组合全局过滤器和网关过滤器定序）TODO: document ordering 接下来要做：文档化定序方式 Forward Routing Filter （转发路由过滤器）The ForwardRoutingFilter looks for a URI in the exchange attribute ServerWebExchangeUtils.GATEWAY_REQUEST_URL_ATTR. If the url has a forward scheme (ie forward:///localendpoint), it will use the Spring DispatcherHandler to handler the request. The unmodified original url is appended to the list in the ServerWebExchangeUtils.GATEWAY_ORIGINAL_REQUEST_URL_ATTR attribute. ForwardRoutingFilter通过以ServerWebExchangeUtils.GATEWAY_REQUEST_URL_ATTR为key在交换属性中获得URI（统一资源标识符）。如果这个url(统一资源定位符)是forward协议，（比如：forward:///localendpoint），那么就会通过SpringDispatcherHandler 去处理该请求。这个未修改的原始路径会被添加到以ServerWebExchangeUtils.GATEWAY_ORIGINAL_REQUEST_URL_ATTR为key的列表中。 LoadBalancerClient Filter (客户端负载均衡过滤器)The LoadBalancerClientFilter looks for a URI in the exchange attribute ServerWebExchangeUtils.GATEWAY_REQUEST_URL_ATTR. If the url has a lb scheme (ie lb://myservice), it will use the Spring Cloud LoadBalancerClient to resolve the name (myservice in the previous example) to an actual host and port and replace the URI in the same attribute. The unmodified original url is appended to the list in the ServerWebExchangeUtils.GATEWAY_ORIGINAL_REQUEST_URL_ATTR attribute. LoadBalancerClientFilter通过以ServerWebExchangeUtils.GATEWAY_REQUEST_URL_ATTR为key在交换属性中获得URI。如果这个url是lb协议（比如lb://myservice），那么就会通过Spring Cloud LoadBalancerClient去处理这个myservice（这个名字是与前面的例子中匹配的）找到真实的主机和端口，然后在uri的同类属性中进行替换。这个未修改的原始路径会被添加到以ServerWebExchangeUtils.GATEWAY_ORIGINAL_REQUEST_URL_ATTR为key的LinkedHashSet列表中。 Netty Routing Filter （Netty路由过滤器）The Netty Routing Filter runs if the url located in the ServerWebExchangeUtils.GATEWAY_REQUEST_URL_ATTR exchange attribute has a http or https scheme. It uses the Netty HttpClient to make the downstream proxy request. The response is put in the ServerWebExchangeUtils.CLIENT_RESPONSE_ATTR exchange attribute for use in a later filter. (There is an experimental WebClientHttpRoutingFilter that performs the same function, but does not require netty) 如果在交换属性中以ServerWebExchangeUtils.GATEWAY_REQUEST_URL_ATTR为key获得的url是以http或者是https为请求协议，那么Netty路由过滤器就会生效工作。其是使用NettyHttpClient去生成一个下游的代理请求。请求的响应根据ServerWebExchangeUtils.CLIENT_RESPONSE_ATTR添加进交换属性中以供后面的过滤器使用。（有一个实验性的过滤器WebClientHttpRoutingFilter执行相同的函数，但是不需要Netty） Netty Write Response Filter （Netty响应过滤器）The NettyWriteResponseFilter runs if there is a Netty HttpClientResponse in the ServerWebExchangeUtils.CLIENT_RESPONSE_ATTR exchange attribute. It is run after all other filters have completed and writes the proxy response back to the gateway client response. (There is an experimental WebClientWriteResponseFilter that performs the same function, but does not require netty) 如果在交换属性中以ServerWebExchangeUtils.GATEWAY_REQUEST_URL_ATTR为key获得的请求响应是一个Netty的响应 HttpClientResponse，那么Netty响应过滤器NettyWriteResponseFilter就会生效工作。其是在所有的其他过滤器处理完成之后开始工作的，并且写入代理请求返回给网关客户端响应。（有一个实验性的过滤器WebClientWriteResponseFilter执行相同的函数，但是不需要Netty） RouteToRequestUrl Filter (路由到请求地址过滤器)The RouteToRequestUrlFilter runs if there is a Route object in the ServerWebExchangeUtils.GATEWAY_ROUTE_ATTR exchange attribute. It creates a new URI, based off of the request URI, but updated with the URI attribute of the Route object. The new URI is placed in the ServerWebExchangeUtils.GATEWAY_REQUEST_URL_ATTR exchange attribute`. 如果在交换属性中以ServerWebExchangeUtils.GATEWAY_REQUEST_URL_ATTR为key获得一个Route对象，那么路由请求地址过滤器RouteToRequestUrlFilter就会生效工作。其创建一个新的URI是基于请求的URI，但是根据Route对象的URI属性进行更新。新的URI会以ServerWebExchangeUtils.GATEWAY_REQUEST_URL_ATTR为key放置到交换属性当中。 Websocket Routing Filter （Websocket路由过滤器）The Websocket Routing Filter runs if the url located in the ServerWebExchangeUtils.GATEWAY_REQUEST_URL_ATTR exchange attribute has a ws or wss scheme. It uses the Spring Web Socket infrastructure to forward the Websocket request downstream. 如果在交换属性中以ServerWebExchangeUtils.GATEWAY_REQUEST_URL_ATTR为key获得的url是以ws或者是wss为请求协议，那么Netty路由过滤器就会生效工作。其使用Spring Web Socket底层代码处理，来将Websocket请求转发到下游。 Configuration （配置）Configuration for Spring Cloud Gateway is driven by a collection of RouteDefinitionLocator s. Spring Cloud Gateway的配置是被一系列的RouteDefinitionLocator类来管理的。 RouteDefinitionLocator.java 123public interface RouteDefinitionLocator { Flux&lt;RouteDefinition&gt; getRouteDefinitions();} By default, a PropertiesRouteDefinitionLocator loads properties using Spring Boot’s @ConfigurationProperties mechanism. 默认方式下，PropertiesRouteDefinitionLocator是通过使用Spring Boot的 @ConfigurationProperties 原理来进行加载配置的。 The configuration examples above all use a shortcut notation that uses positional arguments rather than named ones. The two examples below are equivalent: 以上的配置例子全部都是使用一个指定位置参数（译者注：“genkey”+i）的快捷方式，而不是指定命名的。下面两个例子是等价的： application.yml 123456789101112131415spring: cloud: gateway: routes: # ===================================== - id: setstatus_route uri: http://example.org filters: - name: SetStatus args: status: 401 - id: setstatusshortcut_route uri: http://example.org filters: - SetStatus=401 For some usages of the gateway, properties will be adequate, but some production use cases will benefit from loading configuration from an external source, such as a database. Future milestone versions will have RouteDefinitionLocator implementations based off of Spring Data Repositories such as: Redis, MongoDB and Cassandra. 在gateway网关的一些使用方法上，properties配置会是合适的，但是有些生产使用案例中使用从外部来源加载配置将会更好，比如从一个数据库。未来的里程碑版本将会有 RouteDefinitionLocator基于Spring Data Repositories来实现，例如：Redis, MongoDB and Cassandra。 Fluent Java Routes API （流式Java路由API）To allow for simple configuration in Java, there is a fluent API defined in the Routes class. 为了在Java中更简单的配置，在Routes类中定义了流式API。 GatewaySampleApplication.java 12345678910111213141516171819202122// static imports from GatewayFilters and RoutePredicates@Beanpublic RouteLocator customRouteLocator(ThrottleGatewayFilterFactory throttle) { return Routes.locator() .route(\"test\") .predicate(host(\"**.abc.org\").and(path(\"/image/png\"))) .addResponseHeader(\"X-TestHeader\", \"foobar\") .uri(\"http://httpbin.org:80\") .route(\"test2\") .predicate(path(\"/image/webp\")) .add(addResponseHeader(\"X-AnotherHeader\", \"baz\")) .uri(\"http://httpbin.org:80\") .route(\"test3\") .order(-1) .predicate(host(\"**.throttle.org\").and(path(\"/get\"))) .add(throttle.apply(tuple().of(\"capacity\", 1, \"refillTokens\", 1, \"refillPeriod\", 10, \"refillUnit\", \"SECONDS\"))) .uri(\"http://httpbin.org:80\") .build();} This style also allows for more custom predicate assertions. The predicates defined by RouteDefinitionLocator beans are combined using logical and. By using the fluent Java API, you can use the and(), or() and negate() operators on the Predicate class. 这类风格也允许更多的自定义predicates断言。被 RouteDefinitionLocator 实例定义的predicates通过使用逻辑 and 来组合。通过使用Java流式API，你能使用and(), or() 和 negate()来操作Predicate类。 Actuator API （执行器API）TODO: document the /gateway actuator endpoint 接下来要做：/gateway执行器端点文档 Developer Guide （开发者指南）TODO: overview of writing custom integrations 接下来要做：编写自定义集成概述 Writing Custom Route Predicate Factories （编写自定义路由Predicate工厂）TODO: document writing Custom Route Predicate Factories 接下来要做：文档化编写自定义路由Predicate工厂 Writing Custom GatewayFilter Factories （编写自定义GatewayFilter工厂）TODO: document writing Custom GatewayFilter Factories 接下来要做：文档化编写自定义GatewayFilter工厂 Writing Custom Global Filters （编写自定义全局过滤器）TODO: document writing Custom Global Filters 接下来要做：文档化编写自定义全局过滤器 Writing Custom Route Locators and Writers （编写自定义路由定位器和写入器）TODO: document writing Custom Route Locators and Writers 接下来要做：文档化编写自定义路由定位器和写入器 Building a Simple Gateway Using Spring MVC （使用Spring MVC构建一个简单的网关）Spring Cloud Gateway provides a utility object called ProxyExchange which you can use inside a regular Spring MVC handler as a method parameter. It supports basic downstream HTTP exchanges via methods that mirror the HTTP verbs, or forwarding to a local handler via the forward() method. Spring Cloud Gateway 提供了名为 ProxyExchange 一个实用化对象，你可以使用它来内置一个正确的Spring MVC处理器作为方法参数。它支持通过真实的HTTP的方法来替换下游的内部HTTP，或者通过 forward() 方法转发到一个本地的处理器。 Example (proxying a request to “/test” downstream to a remote server): 例如下：（代理请求”/test”的请求到下游的一个远程服务） 12345678910111213@RestController@SpringBootApplicationpublic class GatewaySampleApplication { @Value(\"${remote.home}\") private URI home; @GetMapping(\"/test\") public ResponseEntity&lt;?&gt; proxy(ProxyExchange&lt;Object&gt; proxy) throws Exception { return proxy.uri(home.toString() + \"/image/png\").get(); }} There are convenience methods on the ProxyExchange to enable the handler method to discover and enhance the URI path of the incoming request. For example you might want to extract the trailing elements of a path to pass them downstream: 在ProxyExchange有简单的方式去通过处理器方法发现并完善请求的URI路径。比如你可能想提取路径后的元素，以便将它们传递到下游： 12345@GetMapping(\"/proxy/path/**\")public ResponseEntity&lt;?&gt; proxyPath(ProxyExchange&lt;?&gt; proxy) throws Exception { String path = proxy.path(\"/proxy/path/\"); return proxy.uri(home.toString() + \"/foos/\" + path).get();} All the features of Spring MVC are available to Gateway handler methods. So you can inject request headers and query parameters, for instance, and you can constrain the incoming requests with declarations in the mapping annotation. See the documentation for @RequestMapping in Spring MVC for more details of those features. 所有的Spring MVC的特性都可以使用到网关的处理器方法。因此你可以注入请求头和查询参数，你可以使用映射注解声明来约束请求。 查看Spring MVC中的 @RequestMapping 文档可以了解更多的特性。 Headers can be added to the downstream response using the header() methods on ProxyExchange. 通过 ProxyExchange 的 header() 方法可以添加头信息到下游的响应中。 You can also manipulate response headers (and anything else you like in the response) by adding a mapper to the get() etc. method. The mapper is a Function that takes the incoming ResponseEntity and converts it to an outgoing one. 通过向 get() 之类的方法添加一个映射，你也可以操作响应头（包括在响应中你想要的）。这个映射是一个需要输入ResponseEntity 和转化指定输出的 Function 函数。 First class support is provided for “sensitive” headers (“cookie” and “authorization” by default) which are not passed downstream, and for “proxy” headers (x-forwarded-*). 最高优先级的类支持处理让 sensitive 敏感头信息（cookie和authorization是默认的）不往下游传递，并且对于 proxy 代理头信息处理为（x-forwarded-*）。","link":"/sc/sc-gw-fy/"},{"title":"Spring Cloud Zuul遗失的世界(三)","text":"摘要: 接着上一篇《Spring Cloud Zuul遗失的世界(二)》，本文主要介绍Netflix Zuul core模块的Filter链的设计和Fifter Loader和Filter Manager相关代码的设计与分析。 一.Zuul Filter的抽象设计1.1 自定义Zuul Filter当我们使用Spring Cloud Zuul都会直接继承ZuulFilter，覆盖实现抽象类中定义的方法，如下所示: 12345678910111213141516171819202122232425262728293031323334public class PreFilter extends ZuulFilter { private static final Logger logger = LoggerFactory.getLogger(PreFilter.class); @Override public String filterType() { return \"pre\"; } @Override public int filterOrder() { return 0; } @Override public boolean shouldFilter() { return true; } @Override public Object run() { RequestContext ctx = RequestContext.getCurrentContext(); String token = ctx.getRequest().getHeader(HttpHeaders.AUTHORIZATION); String labels = TOKEN_LABEL_MAP.get(token); logger.info(\"label: \" + labels); CoreHeaderInterceptor.initHystrixRequestContext(labels); // zuul本身调用微服务 ctx.addZuulRequestHeader(CoreHeaderInterceptor.HEADER_LABEL, labels); // 传递给后续微服务 return null; }} 1.2 IZuulFilter代码定义 IZuulFilter interface，共同的常用方法 12345678910111213141516public interface IZuulFilter { /** * a \"true\" return from this method means that the run() method should be invoked * * @return true if the run() method should be invoked. false will not invoke the run() method */ boolean shouldFilter(); /** * if shouldFilter() is true, this method will be invoked. this method is the core method of a ZuulFilter * * @return Some arbitrary artifact may be returned. Current implementation ignores it. */ Object run();} 1.2 抽象类ZuulFilter代码抽象类ZuulFilter实现IZuulFilter，如下所示 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public abstract class ZuulFilter implements IZuulFilter, Comparable&lt;ZuulFilter&gt; { private final DynamicBooleanProperty filterDisabled = DynamicPropertyFactory.getInstance().getBooleanProperty(disablePropertyName(), false); //filter类型 abstract public String filterType(); // Filter的执行顺序 abstract public int filterOrder(); //是否是静态Filter public boolean isStaticFilter() { return true; } public String disablePropertyName() { return \"zuul.\" + this.getClass().getSimpleName() + \".\" + filterType() + \".disable\"; } //Filter是否启动 public boolean isFilterDisabled() { return filterDisabled.get(); } public ZuulFilterResult runFilter() { ZuulFilterResult zr = new ZuulFilterResult(); if (!isFilterDisabled()) { if (shouldFilter()) { Tracer t = TracerFactory.instance().startMicroTracer(\"ZUUL::\" + this.getClass().getSimpleName()); try { Object res = run(); zr = new ZuulFilterResult(res, ExecutionStatus.SUCCESS); } catch (Throwable e) { t.setName(\"ZUUL::\" + this.getClass().getSimpleName() + \" failed\"); zr = new ZuulFilterResult(ExecutionStatus.FAILED); zr.setException(e); } finally { t.stopAndLog(); } } else { zr = new ZuulFilterResult(ExecutionStatus.SKIPPED); } } return zr; } public int compareTo(ZuulFilter filter) { return Integer.compare(this.filterOrder(), filter.filterOrder()); } } 二.Spring Cloud Zuul的Filter管理 zuul支持动加载Filter类文件。实现原理是监控存放Filter文件的目录，定期扫描这些目录，如果发现有新Filter源码文件或者Filter源码文件有改动，则对文件进行编译加载。目前zuul支持使用Groovy编写的Filter。 2.1 FilterFileManager groovy的文件filter加载,通过FilterFileManager，开启一个线程，开始轮询GroovyFilterFile的目录 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137public class FilterFileManager { private static final Logger LOG = LoggerFactory.getLogger(FilterFileManager.class); String[] aDirectories; int pollingIntervalSeconds; Thread poller; boolean bRunning = true; static FilenameFilter FILENAME_FILTER; static FilterFileManager INSTANCE; private FilterFileManager() { } public static void setFilenameFilter(FilenameFilter filter) { FILENAME_FILTER = filter; } /** * Initialized the GroovyFileManager. * * @param pollingIntervalSeconds the polling interval in Seconds * @param directories Any number of paths to directories to be polled may be specified * @throws IOException * @throws IllegalAccessException * @throws InstantiationException */ public static void init(int pollingIntervalSeconds, String... directories) throws Exception, IllegalAccessException, InstantiationException { if (INSTANCE == null) INSTANCE = new FilterFileManager(); INSTANCE.aDirectories = directories; INSTANCE.pollingIntervalSeconds = pollingIntervalSeconds; INSTANCE.manageFiles(); INSTANCE.startPoller(); } public static FilterFileManager getInstance() { return INSTANCE; } /** * Shuts down the poller */ public static void shutdown() { INSTANCE.stopPoller(); } void stopPoller() { bRunning = false; } // 开启一个线程，开始轮询 void startPoller() { poller = new Thread(\"GroovyFilterFileManagerPoller\") { public void run() { while (bRunning) { try { sleep(pollingIntervalSeconds * 1000); manageFiles(); } catch (Exception e) { e.printStackTrace(); } } } }; poller.setDaemon(true); poller.start(); } /** * Returns the directory File for a path. A Runtime Exception is thrown if the directory is in valid * * @param sPath * @return a File representing the directory path */ public File getDirectory(String sPath) { File directory = new File(sPath); if (!directory.isDirectory()) { URL resource = FilterFileManager.class.getClassLoader().getResource(sPath); try { directory = new File(resource.toURI()); } catch (Exception e) { LOG.error(\"Error accessing directory in classloader. path=\" + sPath, e); } if (!directory.isDirectory()) { throw new RuntimeException(directory.getAbsolutePath() + \" is not a valid directory\"); } } return directory; } /** * Returns a List&lt;File&gt; of all Files from all polled directories * * @return */ List&lt;File&gt; getFiles() { List&lt;File&gt; list = new ArrayList&lt;File&gt;(); for (String sDirectory : aDirectories) { if (sDirectory != null) { File directory = getDirectory(sDirectory); File[] aFiles = directory.listFiles(FILENAME_FILTER); if (aFiles != null) { list.addAll(Arrays.asList(aFiles)); } } } return list; } /** * puts files into the FilterLoader. The FilterLoader will only addd new or changed filters * * @param aFiles a List&lt;File&gt; * @throws IOException * @throws InstantiationException * @throws IllegalAccessException */ void processGroovyFiles(List&lt;File&gt; aFiles) throws Exception, InstantiationException, IllegalAccessException { for (File file : aFiles) { //更新则通过FilterLoader.putFilter()置入FilterRegistr FilterLoader.getInstance().putFilter(file); } } //每次轮询，处理目录内的所有*.groovy文件，即调用FilterLoader.getInstance().putFilter(file); void manageFiles() throws Exception, IllegalAccessException, InstantiationException { List&lt;File&gt; aFiles = getFiles(); processGroovyFiles(aFiles); } } 2.2 FilterLoader com.netflix.zuul.FilterLoader，编译、加载filter文件，并且检查源文件是否有变更，除此之外，它还按照filterType组织并维护List 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152public class FilterLoader { final static FilterLoader INSTANCE = new FilterLoader(); private static final Logger LOG = LoggerFactory.getLogger(FilterLoader.class); private final ConcurrentHashMap&lt;String, Long&gt; filterClassLastModified = new ConcurrentHashMap&lt;String, Long&gt;(); private final ConcurrentHashMap&lt;String, String&gt; filterClassCode = new ConcurrentHashMap&lt;String, String&gt;(); private final ConcurrentHashMap&lt;String, String&gt; filterCheck = new ConcurrentHashMap&lt;String, String&gt;(); private final ConcurrentHashMap&lt;String, List&lt;ZuulFilter&gt;&gt; hashFiltersByType = new ConcurrentHashMap&lt;String, List&lt;ZuulFilter&gt;&gt;(); private FilterRegistry filterRegistry = FilterRegistry.instance(); static DynamicCodeCompiler COMPILER; static FilterFactory FILTER_FACTORY = new DefaultFilterFactory(); /** * Sets a Dynamic Code Compiler * * @param compiler */ public void setCompiler(DynamicCodeCompiler compiler) { COMPILER = compiler; } // overidden by tests public void setFilterRegistry(FilterRegistry r) { this.filterRegistry = r; } /** * Sets a FilterFactory * * @param factory */ public void setFilterFactory(FilterFactory factory) { FILTER_FACTORY = factory; } /** * @return Singleton FilterLoader */ public static FilterLoader getInstance() { return INSTANCE; } /** * Given source and name will compile and store the filter if it detects that the filter code has changed or * the filter doesn't exist. Otherwise it will return an instance of the requested ZuulFilter * * @param sCode source code * @param sName name of the filter * @return the ZuulFilter * @throws IllegalAccessException * @throws InstantiationException */ public ZuulFilter getFilter(String sCode, String sName) throws Exception { if (filterCheck.get(sName) == null) { filterCheck.putIfAbsent(sName, sName); if (!sCode.equals(filterClassCode.get(sName))) { LOG.info(\"reloading code \" + sName); filterRegistry.remove(sName); } } ZuulFilter filter = filterRegistry.get(sName); if (filter == null) { Class clazz = COMPILER.compile(sCode, sName); if (!Modifier.isAbstract(clazz.getModifiers())) { filter = (ZuulFilter) FILTER_FACTORY.newInstance(clazz); } } return filter; } /** * @return the total number of Zuul filters */ public int filterInstanceMapSize() { return filterRegistry.size(); } /** * From a file this will read the ZuulFilter source code, compile it, and add it to the list of current filters * a true response means that it was successful. * * @param file * @return true if the filter in file successfully read, compiled, verified and added to Zuul * @throws IllegalAccessException * @throws InstantiationException * @throws IOException */ public boolean putFilter(File file) throws Exception { String sName = file.getAbsolutePath() + file.getName(); // 如果文件在上次加载后发生了变化，重新编译加载 if (filterClassLastModified.get(sName) != null &amp;&amp; (file.lastModified() != filterClassLastModified.get(sName))) { LOG.debug(\"reloading filter \" + sName); filterRegistry.remove(sName); } ZuulFilter filter = filterRegistry.get(sName); if (filter == null) { // 编译、加载文件 Class clazz = COMPILER.compile(file); if (!Modifier.isAbstract(clazz.getModifiers())) { filter = (ZuulFilter) FILTER_FACTORY.newInstance(clazz); // 清空filter.filterType()类型的List&lt;Filter&gt;缓存，重新构建 List&lt;ZuulFilter&gt; list = hashFiltersByType.get(filter.filterType()); if (list != null) { //重新构建某种类型Filter的List hashFiltersByType.remove(filter.filterType()); //rebuild this list } //向Filter Registry放入新的Filter filterRegistry.put(file.getAbsolutePath() + file.getName(), filter); filterClassLastModified.put(sName, file.lastModified()); return true; } } return false; } /** * 根据Filter类型返回同一类型的Filter * * @param filterType * @return a List&lt;ZuulFilter&gt; */ public List&lt;ZuulFilter&gt; getFiltersByType(String filterType) { List&lt;ZuulFilter&gt; list = hashFiltersByType.get(filterType); if (list != null) return list; list = new ArrayList&lt;ZuulFilter&gt;(); Collection&lt;ZuulFilter&gt; filters = filterRegistry.getAllFilters(); for (Iterator&lt;ZuulFilter&gt; iterator = filters.iterator(); iterator.hasNext(); ) { ZuulFilter filter = iterator.next(); if (filter.filterType().equals(filterType)) { list.add(filter); } } //根据 Collections.sort(list); hashFiltersByType.putIfAbsent(filterType, list); return list; }} 把Groovy源码进行编译并加载进jvm里。 2.3 FilterRegistry com.netflix.zuul.filters.FilterRegistry可以理解为就是用ConcurrentHashMap，在运行过程中存储Filter的数据结构，进行Put或Revome操作。 12345678910111213141516171819202122232425262728293031323334public class FilterRegistry { private static final FilterRegistry INSTANCE = new FilterRegistry(); public static final FilterRegistry instance() { return INSTANCE; } private final ConcurrentHashMap&lt;String, ZuulFilter&gt; filters = new ConcurrentHashMap&lt;String, ZuulFilter&gt;(); private FilterRegistry() { } public ZuulFilter remove(String key) { return this.filters.remove(key); } public ZuulFilter get(String key) { return this.filters.get(key); } public void put(String key, ZuulFilter filter) { this.filters.putIfAbsent(key, filter); } public int size() { return this.filters.size(); } public Collection&lt;ZuulFilter&gt; getAllFilters() { return this.filters.values(); }} 2.4 DynamicCodeCompiler com.netflix.zuul.DynamicCodeCompiler.java,主要是一个接口，定义两种加载编译源码的方法： 12345public interface DynamicCodeCompiler { Class compile(String sCode, String sName) throws Exception; Class compile(File file) throws Exception;} 三.参考文章 http://microservices.io/patterns/apigateway.html","link":"/sc/sc-zuul-s3/"},{"title":"使用Spring Cloud Eureka实现服务注册与发现","text":"摘要:由于目前，网上的Spring Cloud的学习的案列，比较凌乱而且没有形成整个体系，因此特开一个专题为跟我学Spring Cloud，希望帮助到有需要的人。本文主要介绍如何使用Spring Cloud中的Eureka组件快速实现微服务的服务注册与发现。至于安全模式和Eureka Server的HA,后面的文章会详细介绍。如果您觉得，有想了解的内容，参与评论留言。 什么是服务注册与发现服务注册与发现 在服务化的早期，服务不是很多，服务的注册与发现并不是什么新鲜的名词，Nginx+内部域名服务器方式，甚至Nginx+host文件配置方式也能完成服务的注册与发现。服务上下线需要在nginx,服务器做相应的配置，一旦服务的IP端口发生变化，都需要在nginx上做相应的配置，为了解决这个问题引入服务注册中心。 服务注册,即服务在启动的时候就将服务的IP,端口,版本号等EndPoint注册到注册中心(Eueka,Zookeeper,Consul)对服务进行统一管理. 服务发现,简单的就是说，不管服务上下线，当对某个服务发起请求时，能够快速的从本地缓存或者注册中心的注册列表中，快速找到服务提供者。 服务化早期的做法示例工程说明 Tips：代码示例:https://github.com/SoftwareKing/spring-cloud-study/tree/master/sc-eureka-first Spring MVC中基于无状态的REST 工程可以参考sc-rest-demo下面的sc-rest-provider和sc-rest-consumer，具体使用如下代码所示：123456789101112131415161718192021@RestController@RequestMapping(\"/sc\")public class ConsumerController { @Autowired private RestTemplate restTemplate; // 从属性文件中读取服务提供的URL @Value(\"${order.orderServiceUrl}\") private String orderServiceUrl; @GetMapping(\"/consumer/{id}\") public OrderModel getOrderInfo(@PathVariable Long id) { // this.restTemplate.getForObject(\"http://localhost:8000/sc/order/\" + // id,OrderModel.class); return this.restTemplate.getForObject(this.orderServiceUrl + \"/sc/order/\" + id, OrderModel.class); }} 大家注意到没，把http://localhost:8000 ,硬编码到程序中，是不是比较low。可以采用上面代码中的方式：orderServiceUrl解决。但是这样还是比较low,下面介绍一下引入Eureka实现服务注册与发现的处理。 使用Eureka实现服务的注册与发现搭建注册中心-Eureka Server 1.引入依赖123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;?xml version=\"1.0\"?&gt;&lt;project xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\" xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;!-- 引入spring boot的依赖 --&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.4.3.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;artifactId&gt;sc-eureka-first-server-HA01&lt;/artifactId&gt; &lt;name&gt;sc-eureka-first-server-HA01&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!-- 引入Spring Cloud Eureka依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;!-- 引入spring cloud的依赖 --&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Camden.SR5&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; &lt;!-- 添加spring-boot的maven插件--&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 在Resources目录下创建application.yml123456789101112131415server: port: 8761 # 指定该Eureka实例的端口eureka: client: #表示是否将自己注册到Eureka Server上，默认为true，当前应用为Eureka Server所以无需注册 registerWithEureka: false #表示是否从Eureka Server获取注册信息，默认为true。因为这是一个单点的Eureka Server，不需要同步其他的Eureka Server节点的数据，故而设为false。 fetchRegistry: false #Eureka Server的访问地址，服务注册和client获取服务注册信息均通过该URL，多个服务注册地址用,隔开 serviceUrl: defaultZone: http://localhost:8761/eureka/# 参考文档：http://projects.spring.io/spring-cloud/docs/1.0.3/spring-cloud.html#_standalone_mode# 参考文档：http://my.oschina.net/buwei/blog/618756 3.创建Spring Boot主应用程序启动代码12345678910111213141516171819package org.xujin.sc.eureka.server;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.netflix.eureka.server.EnableEurekaServer;/** * Eureka Server * @author xujin */@SpringBootApplication@EnableEurekaServerpublic class SpringCloudEurekaServer { public static void main(String[] args) { SpringApplication.run(SpringCloudEurekaServer.class, args); }} 启动Eureka server测试： 启动sc-eureka-first-server-HA01，访问http://localhost:8761/ ,如下图所示: 创建服务提供者 1.服务提供者，为了演示在这里提供一个简单的订单查询服务，如工程sc-eureka-first-provider01和sc-eureka-first-provider02所示。 2.主程序入口代码，如下所示：123456789101112131415161718192021package org.xujin.sc.eureka.first.order;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;/** * 服务提供者端，加上@EnableDiscoveryClient注解，完成服务注册。 * @author xujin * @site http://xujin.org */@SpringBootApplication@EnableDiscoveryClient// @EnableEurekaClientpublic class OrderProviderSpringBootAppliaction { public static void main(String[] args) { SpringApplication.run(OrderProviderSpringBootAppliaction.class, args); }} Tips:如果使用Eureka, 可以使用@EnableEurekaClient注解，但是推荐使用@EnableDiscoveryClient代替@EnableEurekaClient注解，因为@EnableDiscoveryClient是一个高度的抽象， 来自于spring-cloud-commons， 由于Spring Cloud选型是中立的因此抽象出该接口， 当服务注册中心选型改变为Eureka，ZK，Consul时，不需要修改原有代码中的注解。 3.服务提供者暴露的服务-OrderController.java12345678910111213@RestControllerpublic class OrderController { @Autowired private OrderService orderService; @GetMapping(\"/sc/order/{id}\") public OrderModel findOrderById(@PathVariable Long id) { OrderModel orderModel = orderService.findOrderByOrderId(id); return orderModel; }} 启动服务提供者，把服务注册信息，注册到Eureka Server注册中心启动sc-eureka-first-provider01,当启动其中一个服务后刷新Eureka Server会出现安全模式,如下图所示: 启动sc-eureka-first-provider02，刷新Eureka Server如下图所示。 创建服务消费者 服务消费者主要是一个简单的用户服务，用户服务查询订单服务的订单信息。 1.引入相应的依赖 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869 &lt;?xml version=\"1.0\"?&gt;&lt;project xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\" xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;org.xujin.sc&lt;/groupId&gt; &lt;artifactId&gt;sc-eureka-first-consumer&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;sc-eureka-first-consumer&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;!-- 引入spring boot的依赖 --&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.4.3.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.16.6&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;!-- 引入spring cloud的依赖 --&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Camden.SR4&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;!-- 添加spring-boot的maven插件 --&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 2.主程序入口代码12345678910111213141516171819202122package org.xujin.sc.eureka.user;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;import org.springframework.context.annotation.Bean;import org.springframework.web.client.RestTemplate;//消费者端加入服务发现注解@EnableDiscoveryClient@SpringBootApplicationpublic class UserConsumerApplication { @Bean public RestTemplate restTemplate() { return new RestTemplate(); } public static void main(String[] args) { SpringApplication.run(UserConsumerApplication.class, args); }} 消费者调用Controller。 12345678910111213141516171819202122232425262728@RestControllerpublic class UserController { private static final Logger logger = LoggerFactory.getLogger(UserController.class); @Autowired private RestTemplate restTemplate; @Autowired private DiscoveryClient discoveryClient; // discoveryClient获取服务列表中，应用名为sc-eureka-first-provider一个服务注册信息 public String serviceUrl() { List&lt;ServiceInstance&gt; list = discoveryClient .getInstances(\"sc-eureka-first-provider\"); if (list != null &amp;&amp; list.size() &gt; 0) { return String.valueOf(list.get(0).getUri()); } return null; } @GetMapping(\"/sc/user/{id}\") public Order findByIdByEurekaServer(@PathVariable Long id) { String providerServiceUrl = serviceUrl(); return this.restTemplate.getForObject(providerServiceUrl + \"sc/order/\" + id, Order.class); }} 如上述代码，所示使用discoveryClient.getInstances(&quot;sc-eureka-first-provider&quot;)获取服务名为sc-eureka-first-provider的服务注册列表信息。 测试先后启动sc-eureka-first-consumer,如没有异常，打开浏览器访问:http://localhost:8010/sc/user/2 ,debug如下所示可以看到 在刷新一下Eureka Server，如图下所示,此时安全模式关闭。 关于安全模式，在本篇文章中，暂不讨论，后面将会专写一篇文章介绍，请暂时忽略。 获取消费者获取服务端消费列表 使用EurekaClient获取服务注册信息 1234567 @Autowiredprivate EurekaClient discoveryClient;public String serviceUrl() { InstanceInfo instance = discoveryClient.getNextServerFromEureka(\"STORES\", false); return instance.getHomePageUrl();} 使用DiscoveryClient获取服务注册信息 12345678910 @Autowiredprivate DiscoveryClient discoveryClient;public String serviceUrl() { List&lt;ServiceInstance&gt; list = discoveryClient.getInstances(\"STORES\"); if (list != null &amp;&amp; list.size() &gt; 0 ) { return list.get(0).getUri(); } return null;} 参考链接：https://github.com/spring-cloud/spring-cloud-netflix/blob/master/docs/src/main/asciidoc/spring-cloud-netflix.adoc 小结 上面这个例子使用Eureka实现了服务的注册与发现，但是有一个问题就是获取服务注册列表的方式比较low并且太方便，还有一个问题就是没有使用负载均衡（Load Balance)，这样就没法实现微服务的HA。在后面的文章将会介绍Eureka Server的HA和使用Robbin实现LB。。","link":"/sc/sc-eureka-01/"},{"title":"Spring Cloud Eureka服务续约(Renew)源码分析","text":"摘要:在本篇文章中主要对Eureka的Renew(服务续约)，从服务提供者发起续约请求开始分析，通过阅读源码和画时序图的方式，展示Eureka服务续约的整个生命周期。服务续约主要是把服务续约的信息更新到自身的Eureka Server中，然后再同步到其它Eureka Server中。 Renew(服务续约)概述Renew（服务续约）操作由Service Provider定期调用，类似于heartbeat。目的是隔一段时间Service Provider调用接口，告诉Eureka Server它还活着没挂，不要把它T了。通俗的说就是它们两之间的心跳检测，避免服务提供者被剔除掉。请参考:Spring Cloud Eureka名词解释 服务续约配置 Renew操作会在Service Provider定时发起，用来通知Eureka Server自己还活着。 这里有两个比较重要的配置需要如下，可以在Run之前配置。1eureka.instance.leaseRenewalIntervalInSeconds Renew频率。默认是30秒，也就是每30秒会向Eureka Server发起Renew操作。1eureka.instance.leaseExpirationDurationInSeconds 服务失效时间。默认是90秒，也就是如果Eureka Server在90秒内没有接收到来自Service Provider的Renew操作，就会把Service Provider剔除。 Renew源码分析服务提供者实现细节 服务提供者发发起服务续约的时序图，如下图所示,大家先直观的看一下时序图，等阅读完源码再回顾一下。 在com.netflix.discovery.DiscoveryClient.initScheduledTasks()中的1272行，TimedSupervisorTask会定时发起服务续约，代码如下所示:123456789101112// Heartbeat timer scheduler.schedule( new TimedSupervisorTask( \"heartbeat\", scheduler, heartbeatExecutor, renewalIntervalInSecs, TimeUnit.SECONDS, expBackOffBound, new HeartbeatThread() ), renewalIntervalInSecs, TimeUnit.SECONDS); 2.在com.netflix.discovery.DiscoveryClient中的1393行，有一个HeartbeatThread线程发起续约操作123456789 private class HeartbeatThread implements Runnable { public void run() { //调用eureka-client中的renew if (renew()) { lastSuccessfulHeartbeatTimestamp = System.currentTimeMillis(); } }} renew()调用eureka-client-1.4.11.jarcom.netflix.discovery.DiscoveryClient中829行renew()发起PUT Reset请求，调用com.netflix.eureka.resources.InstanceResource中的renewLease()续约。12345678910111213141516171819/** * Renew with the eureka service by making the appropriate REST call */ boolean renew() { EurekaHttpResponse&lt;InstanceInfo&gt; httpResponse; try { httpResponse = eurekaTransport.registrationClient.sendHeartBeat(instanceInfo.getAppName(), instanceInfo.getId(), instanceInfo, null); logger.debug(\"{} - Heartbeat status: {}\", PREFIX + appPathIdentifier, httpResponse.getStatusCode()); if (httpResponse.getStatusCode() == 404) { REREGISTER_COUNTER.increment(); logger.info(\"{} - Re-registering apps/{}\", PREFIX + appPathIdentifier, instanceInfo.getAppName()); return register(); } return httpResponse.getStatusCode() == 200; } catch (Throwable e) { logger.error(\"{} - was unable to send heartbeat!\", PREFIX + appPathIdentifier, e); return false; } } Netflix中的Eureka Core实现细节 NetFlix中Eureka Core中的服务续约时序图，如下图所示。 打开com.netflix.eureka.resources.InstanceResource中的106行的renewLease()方法，代码如下: 123456789101112private final PeerAwareInstanceRegistry registry@PUTpublic Response renewLease( @HeaderParam(PeerEurekaNode.HEADER_REPLICATION) String isReplication, @QueryParam(\"overriddenstatus\") String overriddenStatus, @QueryParam(\"status\") String status, @QueryParam(\"lastDirtyTimestamp\") String lastDirtyTimestamp) { boolean isFromReplicaNode = \"true\".equals(isReplication); //调用 boolean isSuccess = registry.renew(app.getName(), id, isFromReplicaNode); //其余省略} 点开registry.renew(app.getName(), id, isFromReplicaNode);我们可以看到，调用了org.springframework.cloud.netflix.eureka.server.InstanceRegistry中的renew（）方法，代码如下: 1234567891011121314151617181920212223 @Override public boolean renew(final String appName, final String serverId, boolean isReplication) { log(\"renew \" + appName + \" serverId \" + serverId + \", isReplication {}\" + isReplication); List&lt;Application&gt; applications = getSortedApplications(); for (Application input : applications) { if (input.getName().equals(appName)) { InstanceInfo instance = null; for (InstanceInfo info : input.getInstances()) { if (info.getHostName().equals(serverId)) { instance = info; break; } } publishEvent(new EurekaInstanceRenewedEvent(this, appName, serverId, instance, isReplication)); break; } } //调用com.netflix.eureka.registry.PeerAwareInstanceRegistryImpl中的renew方法 return super.renew(appName, serverId, isReplication);} 3.从super.renew()看到调用了父类中的com.netflix.eureka.registry.PeerAwareInstanceRegistryImpl中420行的renew()方法，代码如下:123456789 public boolean renew(final String appName, final String id, final boolean isReplication) { //服务续约成功， if (super.renew(appName, id, isReplication)) { //然后replicateToPeers同步其它Eureka Server中的数据 replicateToPeers(Action.Heartbeat, appName, id, null, null, isReplication); return true; } return false;} 3.1 从上面代码中super.renew(appName, id, isReplication)可以看出调用的是com.netflix.eureka.registry.AbstractInstanceRegistry中345行的renew()方法，代码如下所示12345678910111213141516171819202122232425262728293031323334353637383940public boolean renew(String appName, String id, boolean isReplication) { RENEW.increment(isReplication); Map&lt;String, Lease&lt;InstanceInfo&gt;&gt; gMap = registry.get(appName); Lease&lt;InstanceInfo&gt; leaseToRenew = null; if (gMap != null) { leaseToRenew = gMap.get(id); } if (leaseToRenew == null) { RENEW_NOT_FOUND.increment(isReplication); logger.warn(\"DS: Registry: lease doesn't exist, registering resource: {} - {}\", appName, id); return false; } else { InstanceInfo instanceInfo = leaseToRenew.getHolder(); if (instanceInfo != null) { // touchASGCache(instanceInfo.getASGName()); InstanceStatus overriddenInstanceStatus = this.getOverriddenInstanceStatus( instanceInfo, leaseToRenew, isReplication); if (overriddenInstanceStatus == InstanceStatus.UNKNOWN) { logger.info(\"Instance status UNKNOWN possibly due to deleted override for instance {}\" + \"; re-register required\", instanceInfo.getId()); RENEW_NOT_FOUND.increment(isReplication); return false; } if (!instanceInfo.getStatus().equals(overriddenInstanceStatus)) { Object[] args = { instanceInfo.getStatus().name(), instanceInfo.getOverriddenStatus().name(), instanceInfo.getId() }; logger.info( \"The instance status {} is different from overridden instance status {} for instance {}. \" + \"Hence setting the status to overridden status\", args); instanceInfo.setStatus(overriddenInstanceStatus); } } renewsLastMin.increment(); leaseToRenew.renew(); return true; } } 其中 leaseToRenew.renew()是调用com.netflix.eureka.lease.Lease中的62行的renew()方法123456789/** * Renew the lease, use renewal duration if it was specified by the * associated {@link T} during registration, otherwise default duration is * {@link #DEFAULT_DURATION_IN_SECS}. */public void renew() { lastUpdateTimestamp = System.currentTimeMillis() + duration;} 3.2 replicateToPeers(Action.Heartbeat, appName, id, null, null, isReplication);调用自身的replicateToPeers()方法，在com.netflix.eureka.registry.PeerAwareInstanceRegistryImpl中的618行，主要接口实现方式和register基本一致：首先更新自身Eureka Server中服务的状态，再同步到其它Eureka Server中。12345678910111213141516171819202122232425private void replicateToPeers(Action action, String appName, String id, InstanceInfo info /* optional */, InstanceStatus newStatus /* optional */, boolean isReplication) { Stopwatch tracer = action.getTimer().start(); try { if (isReplication) { numberOfReplicationsLastMin.increment(); } // If it is a replication already, do not replicate again as this will create a poison replication if (peerEurekaNodes == Collections.EMPTY_LIST || isReplication) { return; } // 同步把续约信息同步到其它的Eureka Server中 for (final PeerEurekaNode node : peerEurekaNodes.getPeerEurekaNodes()) { // If the url represents this host, do not replicate to yourself. if (peerEurekaNodes.isThisMyUrl(node.getServiceUrl())) { continue; } //根据action做相应操作的同步 replicateInstanceActionsToPeers(action, appName, id, info, newStatus, node); } } finally { tracer.stop(); } } 至此，Eureka服务续约源码分析结束，大家有兴趣可自行阅读。 源码分析链接 其它源码分析链接: Spring Cloud中@EnableEurekaClient源码分析: http://blog.xujin.org/sc/sc-enableEurekaClient-annonation/ Spring Cloud Eureka服务注册源码分析： http://blog.xujin.org/sc/sc-eureka-register/","link":"/sc/sc-eureka-renew/"},{"title":"Spring Cloud中@EnableEurekaClient源码分析","text":"摘要:在这篇文章中主要介绍一下Spring Cloud中的@EnableEurekaClient注解，从源码的角度分析是如何work的，让大家能了解Spring Cloud如何通过@EnableEurekaClient注解对NetFlix Eureka Client进行封装为它所用。 NetFlix Eureka client简介NetFlix Eureka clientEureka client 负责与Eureka Server 配合向外提供注册与发现服务接口。首先看下eureka client是怎么定义，Netflix的 eureka client的行为在LookupService中定义，Lookup service for finding active instances，定义了，从outline中能看到起“规定”了如下几个最基本的方法。服务发现必须实现的基本类：com.netflix.discovery.shared.LookupService，可以自行查看源码。 Eureka client与Spring Cloud类关系 Eureka client与Spring Cloud Eureka Client类图，如下所示:在上图中，我加了前缀，带有S的是Spring Cloud封装的，带有N是NetFlix原生的。 org.springframework.cloud.netflix.eureka.EurekaDiscoveryClient中49行的eurekaClient就是com.netflix.discovery.EurekaClient，代码如下所示:12345678@RequiredArgsConstructorpublic class EurekaDiscoveryClient implements DiscoveryClient { public static final String DESCRIPTION = \"Spring Cloud Eureka Discovery Client\"; private final EurekaInstanceConfig config; // Netflix中的Eureka Client private final EurekaClient eurekaClient; //其余省略} Tips:org.springframework.cloud.netflix.eureka.EurekaDiscoveryClient实现了DiscoveryClient，并依赖于com.netflix.discovery.EurekaClient 点开com.netflix.discovery.EurekaClient查看代码，可以看出EurekaClient继承了LookupService并实现了EurekaClient接口。 1234@ImplementedBy(DiscoveryClient.class)public interface EurekaClient extends LookupService { //其余省略} com.netflix.discovery.DiscoveryClient是netflix使用的客户端，从其class的注释可以看到他主要做这几件事情：a) Registering the instance with Eureka Serverb) Renewalof the lease with Eureka Serverc) Cancellation of the lease from Eureka Server during shutdown 其中com.netflix.discovery.DiscoveryClient实现了com.netflix.discovery.EurekaClient,而spring Cloud中的org.springframework.cloud.netflix.eureka.EurekaDiscoveryClient，依赖于com.netflix.discovery.EurekaClient，因此Spring Cloud与NetFlix的关系由此联系到一起。12345678@Singletonpublic class DiscoveryClient implements EurekaClient { private static final Logger logger = LoggerFactory.getLogger(DiscoveryClient.class); // Constants public static final String HTTP_X_DISCOVERY_ALLOW_REDIRECT = \"X-Discovery-AllowRedirect\"; //其余省略} @EnableEurekaClient注解入口分析 在上面小节中，理清了NetFlix Eureka与Spring cloud中类的依赖关系，下面将以@EnableEurekaClient为入口，分析主要调用链中的类和方法。 @EnableEurekaClient使用 用过spring cloud的同学都知道，使用@EnableEurekaClient就能简单的开启Eureka Client中的功能，如下代码所示。123456789@EnableEurekaClient@SpringBootApplicationpublic class CloudEurekaClientApplication { public static void main(String[] args) { new SpringApplicationBuilder(CloudEurekaClientApplication.class).web(true).run(args); }} 通过@EnableEurekaClient这个简单的注解，在spring cloud应用启动的时候，就可以把EurekaDiscoveryClient注入，继而使用NetFlix提供的Eureka client。 打开EnableEurekaClient这个类，可以看到这个自定义的annotation @EnableEurekaClient里面没有内容。它的作用就是开启Eureka discovery的配置，正是通过这个标记，autoconfiguration就可以加载相关的Eureka类。那我们看下它是怎么做到的。 12345678@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@EnableDiscoveryClientpublic @interface EnableEurekaClient {} 在上述代码中，我们看到，EnableEurekaClient上面加入了另外一个注解@EnableDiscoveryClient，看看这个注解的代码如下所示: 123456789101112/** * Annotation to enable a DiscoveryClient implementation. * @author Spencer Gibb */@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@Import(EnableDiscoveryClientImportSelector.class)public @interface EnableDiscoveryClient {} 这个注解import了EnableDiscoveryClientImportSelector.class这样一个类，其实就是通过这个类来加载需要用到的bean。点开EnableDiscoveryClientImportSelector类，如下代码: 12345678910111213141516@Order(Ordered.LOWEST_PRECEDENCE - 100)public class EnableDiscoveryClientImportSelector extends SpringFactoryImportSelector&lt;EnableDiscoveryClient&gt; { @Override protected boolean isEnabled() { return new RelaxedPropertyResolver(getEnvironment()).getProperty( \"spring.cloud.discovery.enabled\", Boolean.class, Boolean.TRUE); } @Override protected boolean hasDefaultFactory() { return true; }} 看到这里有覆盖了父类SpringFactoryImportSelector的一个方法isEnabled，注意，默认是TRUE，也就是只要import了这个配置，就会enable。 在其父类org.springframework.cloud.commons.util.SpringFactoryImportSelector的String[] selectImports(AnnotationMetadata metadata)方法中正是根据这个标记类判定是否加载如下定义的类。在源码第59行，局部代码如下所示。1234567891011121314151617181920212223242526272829@Override public String[] selectImports(AnnotationMetadata metadata) { if (!isEnabled()) { return new String[0]; } AnnotationAttributes attributes = AnnotationAttributes.fromMap( metadata.getAnnotationAttributes(this.annotationClass.getName(), true)); Assert.notNull(attributes, \"No \" + getSimpleName() + \" attributes found. Is \" + metadata.getClassName() + \" annotated with @\" + getSimpleName() + \"?\"); // Find all possible auto configuration classes, filtering duplicates List&lt;String&gt; factories = new ArrayList&lt;&gt;(new LinkedHashSet&lt;&gt;(SpringFactoriesLoader .loadFactoryNames(this.annotationClass, this.beanClassLoader))); if (factories.isEmpty() &amp;&amp; !hasDefaultFactory()) { throw new IllegalStateException(\"Annotation @\" + getSimpleName() + \" found, but there are no implementations. Did you forget to include a starter?\"); } if (factories.size() &gt; 1) { // there should only ever be one DiscoveryClient, but there might be more than // one factory log.warn(\"More than one implementation \" + \"of @\" + getSimpleName() + \" (now relying on @Conditionals to pick one): \" + factories); } return factories.toArray(new String[factories.size()]); } 在源码中70-71行，即在org.springframework.core.io.support.SpringFactoriesLoader 中的109行的loadFactoryNames(Class&lt;?&gt; factoryClass, ClassLoader classLoader)方法12345678910111213141516171819 public static List&lt;String&gt; loadFactoryNames(Class&lt;?&gt; factoryClass, ClassLoader classLoader) { String factoryClassName = factoryClass.getName(); try { Enumeration&lt;URL&gt; urls = (classLoader != null ? classLoader.getResources(FACTORIES_RESOURCE_LOCATION) : ClassLoader.getSystemResources(FACTORIES_RESOURCE_LOCATION)); List&lt;String&gt; result = new ArrayList&lt;String&gt;(); while (urls.hasMoreElements()) { URL url = urls.nextElement(); Properties properties = PropertiesLoaderUtils.loadProperties(new UrlResource(url)); String factoryClassNames = properties.getProperty(factoryClassName); result.addAll(Arrays.asList(StringUtils.commaDelimitedListToStringArray(factoryClassNames))); } return result; } catch (IOException ex) { throw new IllegalArgumentException(\"Unable to load [\" + factoryClass.getName() + \"] factories from location [\" + FACTORIES_RESOURCE_LOCATION + \"]\", ex); }} 实际调用loadFactoryNames其实加载META-INF/spring.factories下的class。12345 /*** The location to look for factories.* &lt;p&gt;Can be present in multiple JAR files. */ public static final String FACTORIES_RESOURCE_LOCATION = \"META-INF/spring.factories\"; 而在spring-cloud-netflix-eureka-client\\src\\main\\resources\\META-INF\\spring.factories中配置，用于加载一系列配置信息和Dependences Bean可以看到EnableAutoConfiguration的包含了EurekaClientConfigServerAutoConfiguration。1234567891011org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\org.springframework.cloud.netflix.eureka.config.EurekaClientConfigServerAutoConfiguration,\\org.springframework.cloud.netflix.eureka.config.EurekaDiscoveryClientConfigServiceAutoConfiguration,\\org.springframework.cloud.netflix.eureka.EurekaClientAutoConfiguration,\\org.springframework.cloud.netflix.ribbon.eureka.RibbonEurekaAutoConfigurationorg.springframework.cloud.bootstrap.BootstrapConfiguration=\\org.springframework.cloud.netflix.eureka.config.EurekaDiscoveryClientConfigServiceBootstrapConfigurationorg.springframework.cloud.client.discovery.EnableDiscoveryClient=\\org.springframework.cloud.netflix.eureka.EurekaDiscoveryClientConfiguration 打开org.springframework.cloud.netflix.eureka.config.EurekaClientConfigServerAutoConfiguration可以看到EurekaClientAutoConfiguration具体的注入信息。 具体@EnableEurekaClien注解开启之后，服务启动后，是服务怎么注册的请参考，下面链接：http://blog.xujin.org/sc/sc-eureka-register/ 其它源码分析链接 Spring Cloud中@EnableEurekaClient源码分析: http://blog.xujin.org/sc/sc-enableEurekaClient-annonation/ Spring Cloud Eureka服务注册源码分析： http://blog.xujin.org/sc/sc-eureka-register/ Spring Cloud Eureka服务续约(Renew)源码分析 http://blog.xujin.org/sc/sc-eureka-renew/ Spring Cloud Eureka服务下线(Cancel)源码分析 http://blog.xujin.org/sc/sc-eureka-cancle/","link":"/sc/sc-enableEurekaClient-annonation/"},{"title":"Spring Cloud Zuul遗失的世界(二)","text":"摘要: 接着上一篇《Spring Cloud Zuul遗失的世界(一)》，ZuulController继承了ServletWrappingController，将当前应用中的ZuulServlet直接包装为一个Controller，暴露为入口访问，在本篇文章中介绍etflix-zuul-core的代码Zuul的执行的生命周期等。 一.Netflix zuul core源码分析com.netflix.zuul.http.ZuulServlet是ZuulFilter链执行的入口，通过service方法，提取请求到RequestContext，然后通过调用ZuulRunner，依次按顺序执行每种类型的Filter，完成整个Filter的生命周期，架构图如下所示。 1.1 ZuulServlet代码分析 在ZuulConfiguration中点击com.netflix.zuul.http.ZuulServlet打开代码如下所示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104public class ZuulServlet extends HttpServlet { private static final long serialVersionUID = -3374242278843351500L; private ZuulRunner zuulRunner; @Override public void init(ServletConfig config) throws ServletException { super.init(config); String bufferReqsStr = config.getInitParameter(\"buffer-requests\"); boolean bufferReqs = bufferReqsStr != null &amp;&amp; bufferReqsStr.equals(\"true\") ? true : false; zuulRunner = new ZuulRunner(bufferReqs); } @Override public void service(javax.servlet.ServletRequest servletRequest, javax.servlet.ServletResponse servletResponse) throws ServletException, IOException { try { //调用zuulRunner.init(servletRequest, servletResponse)进行请求上下文的传递 init((HttpServletRequest) servletRequest, (HttpServletResponse) servletResponse); // Marks this request as having passed through the \"Zuul engine\", as opposed to servlets // explicitly bound in web.xml, for which requests will not have the same data attached RequestContext context = RequestContext.getCurrentContext(); context.setZuulEngineRan(); try { preRoute(); } catch (ZuulException e) { error(e); postRoute(); return; } try { route(); } catch (ZuulException e) { error(e); postRoute(); return; } try { postRoute(); } catch (ZuulException e) { error(e); return; } } catch (Throwable e) { error(new ZuulException(e, 500, \"UNHANDLED_EXCEPTION_\" + e.getClass().getName())); } finally { RequestContext.getCurrentContext().unset(); } } /** * 执行 \"post\" ZuulFilters * * @throws ZuulException */ void postRoute() throws ZuulException { zuulRunner.postRoute(); } /** * 执行 \"route\" filters * * @throws ZuulException */ void route() throws ZuulException { zuulRunner.route(); } /** * 执行 \"pre\" filters * * @throws ZuulException */ void preRoute() throws ZuulException { zuulRunner.preRoute(); } /** * initializes request * * @param servletRequest * @param servletResponse */ void init(HttpServletRequest servletRequest, HttpServletResponse servletResponse) { zuulRunner.init(servletRequest, servletResponse); } /** * sets error context info and executes \"error\" filters * * @param e */ void error(ZuulException e) { RequestContext.getCurrentContext().setThrowable(e); zuulRunner.error(); } } 如上所示，ZuulServlet其实就是一个Servlet，service方法包含了Zuul的整个生命周期。 1.1.1 ZuulServlet init代码拆解分析1234//init() - 注册一个ZuulRunner用于调用整个filter 链void init(HttpServletRequest servletRequest, HttpServletResponse servletResponse) { zuulRunner.init(servletRequest, servletResponse); } 1.1.2 ZuulServlet service代码分析123456789101112131415161718192021222324252627282930313233343536373839// 调用init将req,res置入上下文.获取并标记上下文此session已经通过进入@Override public void service(javax.servlet.ServletRequest servletRequest, javax.servlet.ServletResponse servletResponse) throws ServletException, IOException { try { init((HttpServletRequest) servletRequest, (HttpServletResponse) servletResponse); // Marks this request as having passed through the \"Zuul engine\", as opposed to servlets // explicitly bound in web.xml, for which requests will not have the same data attached RequestContext context = RequestContext.getCurrentContext(); context.setZuulEngineRan(); try { preRoute(); } catch (ZuulException e) { error(e); postRoute(); return; } try { route(); } catch (ZuulException e) { error(e); postRoute(); return; } try { postRoute(); } catch (ZuulException e) { error(e); return; } } catch (Throwable e) { error(new ZuulException(e, 500, \"UNHANDLED_EXCEPTION_\" + e.getClass().getName())); } finally { RequestContext.getCurrentContext().unset(); } } 正常情况下，请求只经过pre -&gt; route -&gt; post。两层try…catch，内层只捕获ZuulException，而其他异常由外层捕获。内层3个try…catch语句，只有pre,route抛出ZuulException时，才会执行errror，再执行post。而当post(88行)抛出ZuulException后，只会执行error。外层捕获其他异常(内层try语句块中抛出的非ZuulException异常以及内层catch语句中抛出的所有异常)后，将HTTP状态码设置为500，同时交给error处理。整个流程的终点有两个：post及error；而非只有post一个。 1.2 Zuul的请求上下文 RequestContext com.netflix.zuul.context.RequestContext继承了ConcurrentHashMap&lt;String, Object&gt;，是Zuul Filter生命周期中处理http请求上下文,是一个threadlocal的Map. 1234567891011121314151617181920public class RequestContext extends ConcurrentHashMap&lt;String, Object&gt; { private static final Logger LOG = LoggerFactory.getLogger(RequestContext.class); protected static Class&lt;? extends RequestContext&gt; contextClass = RequestContext.class; private static RequestContext testContext = null; protected static final ThreadLocal&lt;? extends RequestContext&gt; threadLocal = new ThreadLocal&lt;RequestContext&gt;() { @Override protected RequestContext initialValue() { try { return contextClass.newInstance(); } catch (Throwable e) { throw new RuntimeException(e); } } }; //其余省略} 1.3 ContextLifecycleFilter com.netflix.zuul.context.ContextLifecycleFilter是调用链外围finally中remove上文中threadlocal. 1234567891011121314151617 public class ContextLifecycleFilter implements Filter { public void destroy() {} public void init(FilterConfig filterConfig) throws ServletException {} public void doFilter(ServletRequest req, ServletResponse res, FilterChain chain) throws IOException, ServletException { try { chain.doFilter(req, res); } finally { RequestContext.getCurrentContext().unset(); } }} 1.4 Zuul的运行执行器-ZuulRunnercom.netflix.zuul.ZuulRunner， 1234567891011121314151617181920212223242526272829303132333435363738public class ZuulRunner { private boolean bufferRequests; /** * Creates a new &lt;code&gt;ZuulRunner&lt;/code&gt; instance. */ public ZuulRunner() { this.bufferRequests = true; } /** * * @param bufferRequests - whether to wrap the ServletRequest in HttpServletRequestWrapper and buffer the body. */ public ZuulRunner(boolean bufferRequests) { this.bufferRequests = bufferRequests; } /** * sets HttpServlet request and HttpResponse * * @param servletRequest * @param servletResponse */ // ZuulRunner内传入的req/res就会被替换为wrapper类增强功能: public void init(HttpServletRequest servletRequest, HttpServletResponse servletResponse) { RequestContext ctx = RequestContext.getCurrentContext(); if (bufferRequests) { ctx.setRequest(new HttpServletRequestWrapper(servletRequest)); } else { ctx.setRequest(servletRequest); } ctx.setResponse(new HttpServletResponseWrapper(servletResponse)); }} com.netflix.zuul.filters.ZuulServletFilter跟跟ZuulServlet是同一份代码.com.netflix.zuul.monitoring，预留了CounterFactory与TracerFactory的接口，用来扩展实现counter与timer.","link":"/sc/sc-zuul-s2/"},{"title":"Mybatis代码生成+分页+Mapper继承扩展","text":"摘要 本篇文章主要介绍使用mybatis-gennerator快速生成代码，但是每次生成的Mapper或接口都会覆盖自定义的Mapper，因此介绍了Mapper接口的继承方式解决，还介绍了如何使用分页工具使用pagehelper结合Mybatis快速实现分页。 一. mybatis-gennerator1.1 mybatis-gennerator自动生成代码1.1.1 mybatis-gennerator的安装Mybatis-Generator的下载地址:https://github.com/mybatis/generator/releases 在Eclipse安装mybatis-gennerator插件。 https://marketplace.eclipse.org/content/mybatis-generator 2.在项目中安装Maven插件 123456789101112131415161718192021222324252627282930313233&lt;build&gt; &lt;finalName&gt;janus-admin&lt;/finalName&gt; &lt;pluginManagement&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;/configuration&gt; &lt;version&gt;3.3&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;6.0.6&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;configuration&gt; &lt;!--配置文件的路径 --&gt; &lt;configurationFile&gt;${basedir}/generatorConfig.xml&lt;/configurationFile&gt; &lt;overwrite&gt;true&lt;/overwrite&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;/build&gt; 使用命令:mybatis-generator:generate生成 推荐安装IDE插件的方式或者Maven插件的方式，生成的代码直接刷新工程即可 generatorConfig.xml示例 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt; &lt;!DOCTYPE generatorConfiguration PUBLIC \"-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN\" \"http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd\" &gt; &lt;generatorConfiguration&gt; &lt;!-- 数据库驱动包位置 --&gt; &lt;classPathEntry location=\"D:\\develop\\apache-maven-3.5.0\\res\\mysql\\mysql-connector-java\\5.1.35\\mysql-connector-java-5.1.35.jar\" /&gt; &lt;context id=\"context1\"&gt; &lt;commentGenerator&gt; &lt;!-- 是否去除自动生成的注释 true：是 ： false:否 --&gt; &lt;property name=\"suppressAllComments\" value=\"true\"/&gt; &lt;/commentGenerator&gt; &lt;!-- 数据库链接URL、用户名、密码 --&gt; &lt;jdbcConnection driverClass=\"com.mysql.jdbc.Driver\" connectionURL=\"jdbc:mysql://主机:3306/数据库\" userId=\"用户名\" password=\"密码\" /&gt; &lt;!-- 生成模型的包名和位置 --&gt; &lt;javaModelGenerator targetPackage=\"org.xujin.janus.admin.entity\" targetProject=\"janus-admin/src/main/java\" /&gt; &lt;!-- 生成的映射文件报名和位置 --&gt; &lt;sqlMapGenerator targetPackage=\"mapper\" targetProject=\"janus-admin/src/main/resources\" /&gt; &lt;!-- 生成DAO的包名和位置 --&gt; &lt;javaClientGenerator targetPackage=\"org.xujin.janus.admin.mapper\" targetProject=\"janus-admin/src/main/java\" type=\"XMLMAPPER\" /&gt; &lt;!-- 要生成的那些表(更改tableName 和domainObjectName 就可以了) --&gt; &lt;table schema=\"janus_admin\" tableName=\"cluster\" domainObjectName=\"Cluster\" enableCountByExample=\"false\" enableUpdateByExample=\"false\" enableDeleteByExample=\"false\" enableSelectByExample=\"false\" selectByExampleQueryId=\"false\"&gt; &lt;/table&gt; &lt;table schema=\"janus_admin\" tableName=\"route_info\" domainObjectName=\"RouteInfo\" enableCountByExample=\"false\" enableUpdateByExample=\"false\" enableDeleteByExample=\"false\" enableSelectByExample=\"false\" selectByExampleQueryId=\"false\"&gt; &lt;/table&gt; &lt;!-- 或者使用 tableName=\"%\"通配全部生成 &lt;table tableName=\"%\" enableCountByExample=\"false\" enableUpdateByExample=\"false\" enableDeleteByExample=\"false\" enableSelectByExample=\"false\" selectByExampleQueryId=\"false\"&gt; &lt;!--mysql 配置--&gt; &lt;generatedKey column=\"id\" sqlStatement=\"Mysql\" identity=\"true\"/&gt; &lt;!--oracle 配置--&gt; &lt;!--&lt;generatedKey column=\"id\" sqlStatement=\"select SEQ_{1}.nextval from dual\" identity=\"false\" type=\"pre\"/&gt;--&gt; &lt;/table&gt; --&gt; &lt;/context&gt; &lt;/generatorConfiguration&gt; 二.Mybatis分页插件2.1 引入maven依赖12345&lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.3&lt;/version&gt;&lt;/dependency&gt; 2.2 使用pagehelper1234567891011public interface ExRouteInfoMapper extends RouteInfoMapper { public List&lt;RouteInfo&gt; selectAll(); /** * 分页查询数据 * @return */ Page&lt;RouteInfo&gt; findByPage();} 业务层使用代码示li 1234567@Overridepublic PageInfo&lt;RouteInfo&gt; findByPage(int pageNo, int pageSize) { PageHelper.startPage(pageNo, pageSize); Page&lt;RouteInfo&gt; pagelist = routeMapper.findByPage(); PageInfo&lt;RouteInfo&gt; pageInfo = new PageInfo&lt;&gt;(pagelist); return pageInfo;} 三.Mybatis的Mapper继承3.1 为什么使用Mapper继承使用mybatis-gennerator自动生成代码，每次自动生成代码都会覆盖之前的Mapper文件，为了将自定义的Mapper和接口与生成的Mapper与接口分开，使用继承方式处理。 3.2 代码示例处理1.mybatis-gennerator自动生成的Mapper接口 12345678910111213public interface RouteInfoMapper { int deleteByPrimaryKey(Long id); int insert(RouteInfo record); int insertSelective(RouteInfo record); RouteInfo selectByPrimaryKey(Long id); int updateByPrimaryKeySelective(RouteInfo record); int updateByPrimaryKey(RouteInfo record);} 2.自动生成的Mapper文件 123456789101112&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt;&lt;mapper namespace=\"org.xujin.janus.admin.mapper.RouteInfoMapper\"&gt; &lt;resultMap id=\"BaseResultMap\" type=\"org.xujin.janus.admin.entity.RouteInfo\"&gt; &lt;id column=\"id\" jdbcType=\"BIGINT\" property=\"id\" /&gt; &lt;result column=\"domain_id\" jdbcType=\"INTEGER\" property=\"domainId\" /&gt; &lt;result column=\"type\" jdbcType=\"VARCHAR\" property=\"type\" /&gt; &lt;result column=\"name\" jdbcType=\"VARCHAR\" property=\"name\" /&gt; &lt;/resultMap&gt; &lt;!-- 其余省略 --&gt;&lt;/mapper&gt; 3.继承RouteInfoMapper扩展的接口 1234567891011public interface ExRouteInfoMapper extends RouteInfoMapper { public List&lt;RouteInfo&gt; selectAll(); /** * 分页查询数据 * @return */ Page&lt;RouteInfo&gt; findByPage();} 4.扩展的Mapper文件 123456789101112&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt;&lt;mapper namespace=\"org.xujin.janus.admin.mapper.ex.ExRouteInfoMapper\"&gt; &lt;resultMap id=\"BaseResultMap\" type=\"org.xujin.janus.admin.entity.RouteInfo\"&gt; &lt;id column=\"id\" jdbcType=\"BIGINT\" property=\"id\" /&gt; &lt;result column=\"domain_id\" jdbcType=\"INTEGER\" property=\"domainId\" /&gt; &lt;result column=\"type\" jdbcType=\"VARCHAR\" property=\"type\" /&gt; &lt;result column=\"name\" jdbcType=\"VARCHAR\" property=\"name\" /&gt; &lt;/resultMap&gt; &lt;!-- 其余省略 --&gt;&lt;/mapper&gt; 5.Service层依赖注入ExRouteInfoMapper使用 1234567891011121314@Service@Transactional(readOnly = true)public class RouteInfoServiceImpl implements RouteInfoService { @Autowired private ExRouteInfoMapper routeMapper; @Override @Transactional public void insert(RouteInfoModel routeInfoModel) { RouteInfo RouteInfo = BeanMapper.map(routeInfoModel, RouteInfo.class); routeMapper.insert(RouteInfo); }}","link":"/mybatis/mybatis-01/"},{"title":"Elastic Search java客户端封装使用","text":"摘要:ES所提供的Http服务适合用作集群状态和数据的监控，而不适合直接用于数据操作。ES提供了多种语言（包括Java、Python、PHP、Ruby等）版本的Client API，可以使用这些Client API编程实现数据操作功能。在这里主要介绍使用Java版本的Client来操作数据。ES中所有的Java API调用都要使用Client对象，ES为API调用者提供了两类Client对象：NodeClient和TransportClient。TransportClient适合用于生产环境中，本文主要介绍TransportClient。 使用TransportClient连接ES使用elastic search Client 为5.2.2版本，引入如下依赖。12345&lt;dependency&gt; &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt; &lt;artifactId&gt;transport&lt;/artifactId&gt; &lt;version&gt;5.2.2&lt;/version&gt;&lt;/dependency&gt; Tips: 建议API的版本与ES集群所使用的版本保持一致，以免出现因版本不一致而导致的冲突。由于org.elasticsearch.client依赖Log4j，因此还需要配置如下依赖 12345678910&lt;dependency&gt; &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j-api&lt;/artifactId&gt; &lt;version&gt;2.7&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j-core&lt;/artifactId&gt; &lt;version&gt;2.7&lt;/version&gt;&lt;/dependency&gt; Tips https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.2/_maven_repository.html 封装ES Client工具类1.在实际使用中，我们会把ES的相关配置信息，抽取到elasticsearch.yaml中 12345port: 9300#address: \"192.168.67.200,192.168.67.149,192.168.67.215,192.168.67.156,192.168.67.178,192.168.67.240,192.168.67.153,192.168.67.90,192.168.67.228,192.168.67.125\"address: \"192.168.113.250\"cluster: \"elasticsearch\"index: \"mt-apm-*\" 根据Java SDK的写法，需要做写如下硬编码操作的Code。1234567891011121314151617181920212223String deviceId = \"23566d22-6a30-30a9-a874-e1bf75ab688b\"; Settings settings =Settings.builder().put(\"cluster.name\",\"vpc-ops-elk-elastic-cluster\").build(); Client client = new PreBuiltTransportClient(settings) .addTransportAddress(new InetSocketTransportAddress(InetAddress.getByName(\"192.168.67.200\"), 9300)) .addTransportAddress(new InetSocketTransportAddress(InetAddress.getByName(\"192.168.67.149\"), 9300)) .addTransportAddress(new InetSocketTransportAddress(InetAddress.getByName(\"192.168.67.215\"), 9300)) .addTransportAddress(new InetSocketTransportAddress(InetAddress.getByName(\"192.168.67.156\"), 9300)) .addTransportAddress(new InetSocketTransportAddress(InetAddress.getByName(\"192.168.67.178\"), 9300)) .addTransportAddress(new InetSocketTransportAddress(InetAddress.getByName(\"192.168.67.240\"), 9300)) .addTransportAddress(new InetSocketTransportAddress(InetAddress.getByName(\"192.168.67.153\"), 9300)) .addTransportAddress(new InetSocketTransportAddress(InetAddress.getByName(\"192.168.67.90\"), 9300)) .addTransportAddress(new InetSocketTransportAddress(InetAddress.getByName(\"192.168.67.228\"), 9300)) .addTransportAddress(new InetSocketTransportAddress(InetAddress.getByName(\"192.168.67.125\"), 9300)); QueryBuilder qb = matchQuery( \"@message.deviceInfo.deviceId\", deviceId ); SearchResponse response = client.prepareSearch(\"mt-apm-*\") .setQuery(qb) .execute() .actionGet(); System.out.println(response); client.close(); 上述写法存在很多硬编码，无法做到配置和程序代码分离，因此需要设计一个ES工具类用于生成调用Client,下面ESClientHelper工具类如下。 设计ESClientHelperESClientHelper.java123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384/** * * ESClientHelper 按照Elasticsearch API，在Java端使用是ES服务需要创建Java * Client，但是每一次连接都实例化一个client，对系统的消耗很大， 即使在使用完毕之后将client * close掉，由于服务器不能及时回收socket资源，极端情况下会导致服务器达到最大连接数。为了解决上述问题并提高client利用率，可以参考使用池化技术复用client。 * * @author xujin * */public class ESClientHelper { private static final Log logger = LogFactory.getLog(ESClientHelper.class); private static ESClientHelper instance; private Settings setting; private Map&lt;String, Client&gt; clientMap = new ConcurrentHashMap&lt;String, Client&gt;(); // HostName与Port private Map&lt;String, Integer&gt; ips = new HashMap&lt;String, Integer&gt;(); private String clusterName = Configs.ES_CONFIG.getCluster(); public static synchronized ESClientHelper getInstance() { if (instance == null) { instance = new ESClientHelper(); } return instance; } private ESClientHelper() { init(); } /** * 初始化默认的client */ public void init() { String address = Configs.ES_CONFIG.getAddress(); if (StringUtils.isNotEmpty(address)) { StringTokenizer stokenizer = new StringTokenizer(address, \",\"); while (stokenizer.hasMoreTokens()) { String ip = stokenizer.nextToken(); ips.put(ip, Configs.ES_CONFIG.getPort()); } } setting = Settings.builder().put(\"cluster.name\", Configs.ES_CONFIG.getCluster()).build(); addClient(setting, getAllAddress(ips)); } /** * 获得所有的地址端口 * * @return */ public List&lt;InetSocketTransportAddress&gt; getAllAddress(Map&lt;String, Integer&gt; ips) { List&lt;InetSocketTransportAddress&gt; addressList = new ArrayList&lt;InetSocketTransportAddress&gt;(); for (String ip : ips.keySet()) { try { addressList.add(new InetSocketTransportAddress(InetAddress.getByName(ip), ips.get(ip))); } catch (UnknownHostException e) { logger.error(\" add InetSocketTransportAddress exception:[{}],ip:[{}]\", e.getMessage(), ip); } } return addressList; } public Client getClient() { return getClient(clusterName); } public Client getClient(String clusterName) { return clientMap.get(clusterName); } public void addClient(Settings setting, List&lt;InetSocketTransportAddress&gt; transportAddress) { Client client = new PreBuiltTransportClient(setting).addTransportAddresses( transportAddress.toArray(new InetSocketTransportAddress[transportAddress.size()])); clientMap.put(setting.get(\"cluster.name\"), client); }} 相对于 java API 2.4.4 版本来说，升级依赖之后，需要做如下改动。将下面的代码修改上述中的代码。12Client client = TransportClient.builder().settings(setting).build().addTransportAddresses( transportAddress.toArray(new InetSocketTransportAddress[transportAddress.size()])); 使用ESClientHelper使用ESClientHelper.getInstance()获取ESClient1Client client = ESClientHelper.getInstance().getClient(Configs.ES_CONFIG.getCluster()); 1.匹配查询123456789Client client = ESClientHelper.getInstance().getClient(Configs.ES_CONFIG.getCluster()); String index = Configs.ES_CONFIG.getIndex(); QueryBuilder qb = matchQuery(\"@message.deviceInfo.deviceId\", deviceId); SearchResponse response = client .prepareSearch(index).setQuery(qb) .setPostFilter( QueryBuilders.rangeQuery(\"@message.apmLog.network.time.beginTime\") .gte(DateUtils.StringToDate(beginTime)).lte(DateUtils.StringToDate(endTime))) .execute().actionGet(); 2.根据时间段聚合查询123456789101112131415161718192021222324252627282930313233343536373839404142434445@Override public AppReqHistoryInfo getAppReqHistoryInfoByDeviceIdAndTime(String deviceId, int hourNum) throws ServiceException { String day = \"now-\" + String.valueOf(hourNum) + \"h\"; String index = Configs.ES_CONFIG.getIndex(); Client client = ESClientHelper.getInstance().getClient(Configs.ES_CONFIG.getCluster()); QueryBuilder qb = matchQuery(\"@message.deviceInfo.deviceId\", deviceId); MultiSearchRequestBuilder req = client.prepareMultiSearch().add(client.prepareSearch(index) .setPostFilter(boolQuery().must(qb).must(QueryBuilders.rangeQuery(\"@timestamp\").gt(day).lt(\"now\"))) .addAggregation(AggregationBuilders.sum(\"REQ_SUM\").field(\"@message.apmLog.network.reqLength\")) .addAggregation(AggregationBuilders.sum(\"RSP_SUM\").field(\"@message.apmLog.network.complete.respLength\")) .setSize(0)) .add(client.prepareSearch(index) .setPostFilter( boolQuery().must(qb).must(QueryBuilders.rangeQuery(\"@timestamp\").gt(day).lt(\"now\")) .must(QueryBuilders.rangeQuery(\"@message.apmLog.network.complete.statusCode\") .gt(399).lt(999))) .setSize(0)) .add(client.prepareSearch(index).setPostFilter( boolQuery().must(qb).must(QueryBuilders.rangeQuery(\"@timestamp\").gt(day).lt(\"now\")) .must(QueryBuilders.existsQuery(\"@message.apmLog.network.netError.errorDomain\"))) .setSize(0)); AppReqHistoryInfo appReqHisInfo = new AppReqHistoryInfo(); MultiSearchResponse rsp; try { rsp = req.execute().get(); MultiSearchResponse.Item[] items = rsp.getResponses(); MultiSearchResponse.Item totalItem = items[0]; long total = totalItem.getResponse().getHits().getTotalHits(); appReqHisInfo.setRequestNum(total); Double REQ_SUM = (Double) (totalItem.getResponse().getAggregations().get(\"REQ_SUM\").getProperty(\"value\")); Double RSP_SUM = (Double) (totalItem.getResponse().getAggregations().get(\"RSP_SUM\").getProperty(\"value\")); Double totalFlow = REQ_SUM + RSP_SUM; appReqHisInfo.setTotalFlow(totalFlow.longValue()); MultiSearchResponse.Item statusCodeItem = items[1]; appReqHisInfo.setHttpError(statusCodeItem.getResponse().getHits().getTotalHits()); MultiSearchResponse.Item errorDomainItem = items[2]; appReqHisInfo.setNetError(errorDomainItem.getResponse().getHits().getTotalHits()); } catch (InterruptedException | ExecutionException e) { logger.info(\"getAppReqHistoryInfoByDeviceIdAndTime exception:[{}]\", e.getMessage()); throw new ServiceException(\"500\", \"getAppVisitTraceInfo exception\", e.getCause()); } return appReqHisInfo; }","link":"/ex/es-client/"},{"title":"使用Spring MVC拦截器自定义注解实现审计日志收集","text":"前言 Spring WebMvc框架中的Interceptor，与Servlet API中的Filter十分类似，用于对Web请求进行预处理/后处理。通常情况下这些预处理/后处理逻辑是通用的，可以被应用于所有或多个Web请求，例如： 记录Web请求相关日志，可以用于做一些信息监控、统计、分析 检查Web请求访问权限，例如发现用户没有登录后，重定向到登录页面 打开/关闭数据库连接——预处理时打开，后处理关闭，可以避免在所有业务方法中都编写类似代码，也不会忘记关闭数据库连接 场景需求使用手动埋点，收集用户审计日志，包括操作人，对应的Url，操作的模块，调用的方法(url),方法的描述。 实现思路手动在每个Controller方法中，逐一埋点审计日志，这样的方式比较low，而且无法做到组件式通用。因此，采用Spring MVC的HandlerInterceptor(拦截器)+自定义注解实现。 实现细节方法拦截器HandlerInterceptor在HandlerInterceptor中有三个方法:123456789101112 public interface HandlerInterceptor { // 在执行目标方法之前执行 boolean preHandle(HttpServletRequest request,HttpServletResponse response, Object handler)throws Exception; // 执行目标方法之后执行 void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView)throws Exception; // 在请求已经返回之后执行 void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex)throws Exception;} 在以上注释中已经写明执行顺序: preHandle()：预处理回调方法，若方法返回值为true，请求继续（调用下一个拦截器或处理器方法）；若方法返回值为false，请求处理流程中断，不会继续调用其他的拦截器或处理器方法，此时需要通过response产生响应； postHandle()：后处理回调方法，实现处理器的后处理（但在渲染视图之前），此时可以通过modelAndView对模型数据进行处理或对视图进行处理 afterCompletion()：整个请求处理完毕回调方法，即在视图渲染完毕时调用 12345 @Overridepublic boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { System.out.println(handler.getClass()); return true;} 所有请求都是从DispatcherServlet来调用请求url对应的方法的,因此我们可以获取到URL对应的Controller方法。 自定义注解定义一个@interface类，AuditLog注解 123456789101112131415161718import java.lang.annotation.*;@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface AuditLog { String url() default \"\"; String module() default \"\"; String operation() default \"\"; String description() default \"\"; String objType() default \"\";} @Target注解是标注这个类它可以标注的位置，常用的元素类型(ElementType)如下： 123456789101112131415161718192021222324252627282930313233343536public enum ElementType { /** Class, interface (including annotation type), or enum declaration */ // TYPE类型可以声明在类上或枚举上或者是注解上 TYPE, /** Field declaration (includes enum constants) */ // FIELD声明在字段上 FIELD, /** Method declaration */ // 声明在方法上 METHOD, /** Formal parameter declaration */ // 声明在形参列表中 PARAMETER, /** Constructor declaration */ // 声明在构造方法上 CONSTRUCTOR, /** Local variable declaration */ // 声明在局部变量上 LOCAL_VARIABLE, /** Annotation type declaration */ ANNOTATION_TYPE, /** Package declaration */ PACKAGE, /** * Type parameter declaration * * @since 1.8 */ TYPE_PARAMETER, /** * Use of a type * * @since 1.8 */ TYPE_USE} @Retention注解表示的是本注解(标注这个注解的注解保留时期) 12345678910111213141516171819202122 public enum RetentionPolicy { /** * Annotations are to be discarded by the compiler. */ // 源代码时期 SOURCE, /** * Annotations are to be recorded in the class file by the compiler * but need not be retained by the VM at run time. This is the default * behavior. */ // 字节码时期, 编译之后 CLASS, /** * Annotations are to be recorded in the class file by the compiler and * retained by the VM at run time, so they may be read reflectively. * * @see java.lang.reflect.AnnotatedElement */ // 运行时期, 也就是一直保留, 通常也都用这个 RUNTIME} @Documented是否生成文档的标注, 也就是生成接口文档是, 是否生成注解文档。 Controller使用示例1234567 @ResponseBody @RequestMapping(value = \"/{id}\", method = RequestMethod.DELETE) @AuditLog(module = AuditLogModule.CHANNEL, operation = AuditLogOperate.DELETE, description = \"deleteBuild\", objType = AuditLogObjType.CHANNELBUILD) public ResponseEntity deleteBuild(HttpServletRequest request, @PathVariable(value = \"id\") long id) { //其它代码省略} AuditLogHandlerInterceptor主要代码示例12345678910111213141516171819202122232425@Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception { if (handler instanceof HandlerMethod) { HandlerMethod handlerMethod = (HandlerMethod) handler; LOGGER.error(\"auditlog create\"); Method method = handlerMethod.getMethod(); AuditLog auditLog = method.getAnnotation(AuditLog.class); if (auditLog == null) { return; } try { AuditLogInfo auditLogInfo = createAuditLog(auditLog, request, response); if (auditLogInfo != null) { AuditLogHandler.createAuditLog(auditLogInfo); } } catch (Exception e) { LOGGER.error(\"auditlog create error\", e); } } } 扩展自定义注解实现权限控制自定义注解123456789101112 @Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface Access { String[] value() default {}; String[] authorities() default {}; String[] roles() default {};} 在方法上配置权限12345678910 @RestControllerpublic class HelloController { @RequestMapping(value = \"/admin\", produces = MediaType.APPLICATION_JSON_UTF8_VALUE, method = RequestMethod.GET) // 配置注解权限, 允许身份为admin, 或者说允许权限为admin的人访问 @Access(authorities = {\"admin\"}) public String hello() { return \"Hello, admin\"; }} 权限逻辑12345678910111213141516171819202122232425262728293031323334353637 // 自定义一个权限拦截器, 继承HandlerInterceptorAdapter类public class AuthenticationInterceptor extends HandlerInterceptorAdapter { // 在调用方法之前执行拦截 @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { // 将handler强转为HandlerMethod, 前面已经证实这个handler就是HandlerMethod HandlerMethod handlerMethod = (HandlerMethod) handler; // 从方法处理器中获取出要调用的方法 Method method = handlerMethod.getMethod(); // 获取出方法上的Access注解 Access access = method.getAnnotation(Access.class); if (access == null) { // 如果注解为null, 说明不需要拦截, 直接放过 return true; } if (access.authorities().length &gt; 0) { // 如果权限配置不为空, 则取出配置值 String[] authorities = access.authorities(); Set&lt;String&gt; authSet = new HashSet&lt;&gt;(); for (String authority : authorities) { // 将权限加入一个set集合中 authSet.add(authority); } String role = request.getParameter(\"role\"); if (StringUtils.isNotBlank(role)) { if (authSet.contains(role)) { // 校验通过返回true, 否则拦截请求 return true; } } } // 拦截之后应该返回公共结果, 这里没做处理 return false; }}","link":"/ex/ex-mt-anto/"},{"title":"深入理解HashMap上篇","text":"前言: HashMap是Java程序员使用频率最高的用于映射(键值对)处理的数据类型。随着JDK（Java Developmet Kit）版本的更新，JDK1.8对HashMap底层的实现进行了优化，例如引入红黑树的数据结构和扩容的优化等。最近刚好有时间，刚好把HashMap相关的内容和之前做唯品会网关的一些经验整理一下。 一.HashMap的概述1.1 HashMap的数据结构HashMap的内存结构和原理，以及线程安全都是面试的热点问题。Java中的数据结构基本可以用数组+链表的解决。 数组的优缺点:通过下标索引方便查找，但是在数组中插入或删除一个元素比较困难。 链表的优缺点:由于在链表中查找一个元素需要以遍历链表的方式去查找，而插入，删除快速。因此链表适合快速插入和删除的场景，不利于查找。 而HashMap就是综合了上述的两种数据结构的优点，HashMap由Entry数组+链表组成，如下图所示。 从上图我们可以发现HashMap是由Entry数组+链表组成的，一个长度为16的数组中，每个元素存储的是一个链表的头结点。那么这些元素是按照什么样的规则存储到数组中呢。一般情况是通过hash(key)%len获得，也就是元素的key的哈希值对数组长度取模得到。比如上述哈希表中，12%16=12,28%16=12,108%16=12,140%16=12。所以12、28、108以及140都存储在数组下标为12的位置。 1.2 HashMap的存取实现简单说明1.2.1 HashMap put方法实现1.首先HashMap里面实现一个静态内部类Entry，其重要的属性有 key , value, next，从属性key,value我们就能很明显的看出来Entry就是HashMap键值对实现的一个基础bean，我们上面说到HashMap的基础就是一个线性数组，这个数组就是Entry[]，Map里面的内容都保存在Entry[]里面。 123456static class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; { final K key;//Key-value结构的key V value;//存储值 Entry&lt;K,V&gt; next;//指向下一个链表节点 final int hash;//哈希值} 2.既然是线性数组，为什么能随机存取？这里HashMap用了一个小算法，大致是这样实现： 1234567891011121314//存储时:// 这个hashCode方法这里不详述,只要理解每个key的hash是一个固定的int值int hash = key.hashCode();int index = hash % Entry[].length;Entry[index] = value;//取值时:int hash = key.hashCode();int index = hash % Entry[].length;return Entry[index]; 到这里我们轻松的理解了HashMap通过键值对实现存取的基本原理 3.疑问：如果两个key通过hash%Entry[].length得到的index相同，会不会有覆盖的危险？ 这里HashMap里面用到链式数据结构的一个概念。上面我们提到过Entry类里面有一个next属性，作用是指向下一个Entry。打个比方， 第一个键值对A进来，通过计算其key的hash得到的index=0，记做:Entry[0] = A。一会后又进来一个键值对B，通过计算其index也等于0，现在怎么办？HashMap会这样做:B.next = A,Entry[0] = B,如果又进来C,index也等于0,那么C.next = B,Entry[0] = C；这样我们发现index=0的地方其实存取了A,B,C三个键值对,他们通过next这个属性链接在一起。所以疑问不用担心。也就是说数组中存储的是最后插入的元素。到这里为止，HashMap的大致实现，我们应该已经清楚了。 当然HashMap里面也包含一些优化方面的实现，这里也说一下。比如：Entry[]的长度一定后，随着map里面数据的越来越长，这样同一个index的链就会很长，会不会影响性能？HashMap里面设置一个因素（也称为因子），随着map的size越来越大，Entry[]会以一定的规则加长长度。 二.HashMap非线程安全2.1 HashMap进行Put操作2.1.1 Jdk8以下HashMap的Put操作put操作主要是判空，对key的hashcode执行一次HashMap自己的哈希函数，得到bucketindex位置，还有对重复key的覆盖操作。 在HashMap做put操作的时候会调用到以下的方法，addEntry和createEntry 1234567891011121314151617181920212223242526public V put(K key, V value) { if (key == null) return putForNullKey(value); //得到key的hashcode，同时再做一次hash操作 int hash = hash(key.hashCode()); //对数组长度取余，决定下标位置 int i = indexFor(hash, table.length); /** * 首先找到数组下标处的链表结点， * 判断key对一个的hash值是否已经存在，如果存在将其替换为新的value */ for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) { Object k; //Hash碰撞的解决 if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) { V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; } } modCount++; addEntry(hash, key, value, i); return null; } 涉及到的几个方法： 12345678static int hash(int h) { h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4); } static int indexFor(int h, int length) { return h &amp; (length-1); } 现在假如A线程和B线程同时进入addEntry，然后计算出了相同的哈希值对应了相同的数组位置，因为此时该位置还没数据，然后对同一个数组位置调用createEntry，两个线程会同时得到现在的头结点，然后A写入新的头结点之后，B也写入新的头结点，那B的写入操作就会覆盖A的写入操作造成A的写入操作丢失。 2.1.2 jdk8中HashMap的Put操作 ①.判断键值对数组table[i]是否为空或为null，否则执行resize()进行扩容； ②.根据键值key计算hash值得到插入的数组索引i，如果table[i]==null，直接新建节点添加，转向⑥，如果table[i]不为空，转向③； ③.判断table[i]的首个元素是否和key一样，如果相同直接覆盖value，否则转向④，这里的相同指的是hashCode以及equals； ④.判断table[i] 是否为treeNode，即table[i] 是否是红黑树，如果是红黑树，则直接在树中插入键值对，否则转向⑤； ⑤.遍历table[i]，判断链表长度是否大于8，大于8的话把链表转换为红黑树，在红黑树中执行插入操作，否则进行链表的插入操作；遍历过程中若发现key已经存在直接覆盖value即可； ⑥.插入成功后，判断实际存在的键值对数量size是否超多了最大容量threshold，如果超过，进行扩容。 JDK1.8HashMap的put方法源码如下: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657 public V put(K key, V value) { // 对key的hashCode()做hash return putVal(hash(key), key, value, false, true); } final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; // 步骤①：tab为空则创建 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // 步骤②：计算index，并对null做处理 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else { Node&lt;K,V&gt; e; K k; // 步骤③：节点key存在，直接覆盖value if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; // 步骤④：判断该链为红黑树 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); // 步骤⑤：该链为链表 else { for (int binCount = 0; ; ++binCount) { if ((e = p.next) == null) { p.next = newNode(hash, key,value,null); //链表长度大于8转换为红黑树进行处理 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; } // key已经存在直接覆盖value if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; } } if (e != null) { // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; } } ++modCount; // 步骤⑥：超过最大容量 就扩容 if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null;} 2.2 HashMap进行Get操作1234567891011121314public V get(Object key) { if (key == null) return getForNullKey(); int hash = hash(key.hashCode()); /** * 先定位到数组元素，再遍历该元素处的链表 * 判断的条件是key的hash值相同，并且链表的存储的key值和传入的key值相同 */ for (Entry&lt;K,V&gt; e = table[indexFor(hash, table.length)];e != null;e = e.next) { Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) return e.value; } return null; 看一下链表的结点数据结构，保存了四个字段，包括key，value，key对应的hash值以及链表的下一个节点： 123456static class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; { final K key;//Key-value结构的key V value;//存储值 Entry&lt;K,V&gt; next;//指向下一个链表节点 final int hash;//哈希值} 2.3 HashMap扩容的时候扩容(resize)就是重新计算容量，向HashMap对象里不停的添加元素，而HashMap对象内部的数组无法装载更多的元素时，对象就需要扩大数组的长度，以便能装入更多的元素。当然Java里的数组是无法自动扩容的，方法是使用一个新的数组代替已有的容量小的数组，就像我们用一个小桶装水，如果想装更多的水，就得换大水桶。 还是上面那个addEntry方法中，有个扩容的操作，这个操作会新生成一个新的容量的数组，然后对原数组的所有键值对重新进行计算和写入新的数组，之后指向新生成的数组。来看一下扩容的源码： 12345678910111213141516171819//用新的容量来给table扩容 void resize(int newCapacity) { Entry[] oldTable = table; //引用扩容前的Entry数组 int oldCapacity = oldTable.length; //保存old capacity // 如果旧的容量已经是系统默认最大容量了(扩容前的数组大小如果已经达到最大(2^30)了 )，那么将阈值设置成整形的最大值，退出 , if (oldCapacity == MAXIMUM_CAPACITY) { threshold = Integer.MAX_VALUE; return; } //初始化一个新的Entry数组 Entry[] newTable = new Entry[newCapacity]; //将数据转移到新的Entry数组里 transfer(newTable, initHashSeedAsNeeded(newCapacity)); //HashMap的table属性引用新的Entry数组 table = newTable; //设置阈值 threshold = (int)Math.min(newCapacity * loadFactor, MAXIMUM_CAPACITY + 1); } 这里就是使用一个容量更大的数组来代替已有的容量小的数组，transfer()方法将原有Entry数组的元素拷贝到新的Entry数组里。 那么问题来了，当多个线程同时进来，检测到总数量超过门限值的时候就会同时调用resize操作，各自生成新的数组并rehash后赋给该map底层的数组table，结果最终只有最后一个线程生成的新数组被赋给table变量，其他线程的均会丢失。而且当某些线程已经完成赋值而其他线程刚开始的时候，就会用已经被赋值的table作为原始数组，这样也会有问题。所以在扩容操作的时候也有可能会引起一些并发的问题。 2.4 删除数据的时候123456789101112131415161718192021222324252627282930313233343536 //根据指定的key删除Entry，返回对应的value public V remove(Object key) { Entry&lt;K,V&gt; e = removeEntryForKey(key); return (e == null ? null : e.value); } //根据指定的key，删除Entry,并返回对应的value final Entry&lt;K,V&gt; removeEntryForKey(Object key) { if (size == 0) { return null; } int hash = (key == null) ? 0 : hash(key); int i = indexFor(hash, table.length); Entry&lt;K,V&gt; prev = table[i]; Entry&lt;K,V&gt; e = prev; while (e != null) { Entry&lt;K,V&gt; next = e.next; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) { modCount++; size--; if (prev == e) //如果删除的是table中的第一项的引用 table[i] = next;//直接将第一项中的next的引用存入table[i]中 else prev.next = next; //否则将table[i]中当前Entry的前一个Entry中的next置为当前Entry的next e.recordRemoval(this); return e; } prev = e; e = next; } return e; } 删除这一块可能会出现两种线程安全问题，第一种是一个线程判断得到了指定的数组位置i并进入了循环，此时，另一个线程也在同样的位置已经删掉了i位置的那个数据了，然后第一个线程那边就没了。但是删除的话，没了倒问题不大。 再看另一种情况，当多个线程同时操作同一个数组位置的时候，也都会先取得现在状态下该位置存储的头结点，然后各自去进行计算操作，之后再把结果写会到该数组位置去，其实写回的时候可能其他的线程已经就把这个位置给修改过了，就会覆盖其他线程的修改。 总之HashMap是非线程安全的，在高并发的场合使用的话，要用Collections.synchronizedMap进行包装一下。 三.参考文章https://zhuanlan.zhihu.com/p/21673805http://www.importnew.com/7099.htmlhttp://www.admin10000.com/document/3322.htmlhttp://www.cnblogs.com/chenssy/p/3521565.html","link":"/java/hm01/"},{"title":"自研网关纳管Spring Cloud(一)","text":"摘要: 本文主要从网关的需求，以及Spring Cloud Zuul的线程模型和源码瓶颈分析结合，目前最近一段时间自研网关中间件纳管Spring Cloud的经验汇总整理。 一.自研网关纳管Spring Cloud的原因1.1 为什么要自研网关1.网关配置实时生效，配置灰度，回滚等2.网关的性能，特别是防刷，限流，WAF等3.动态Filter ，目前Zuul可以做到动态Filter，Filter配置下发，实时动态Filter4.对网关的监控，告警，流量调拨，网关集群。5.流程审计，增加Dsboard便捷的操作。 1.2 回顾Web容器线程模型Servlet只是基于Java技术的web组件，该组件由容器托管，用于生成动态内容。Servlet容器是web Server或application server 的一部分，供基于Request/Response发送模型的网络服务，解码基于MIME的请求，并格式化基于MIME的响应。Servlet容器包含并管理Servlet生命周期。典型的Servlet容器有Tomcat、Jetty。 如上图所示，Tomcat基于NIO的多线程模型，如下图所示，其基于典型的Acceptor/Reactor线程模型，在Tomcat的线程模型中，Worker线程用来处理Request。当容器收到一个Request后，调度线程从Worker线程池中选出一个Worker线程，将请求传递给该线程，然后由该线程来执行Servlet的service()方法。且该worker线程只能同时处理一个Request请求，如果过程中发生了阻塞，那么该线程就会被阻塞，而不能去处理其他任务。 Servlet默认情况下一个单例多线程。 回到zuul，zuul逻辑的入口是ZuulServlet.service(ServletRequest servletRequest, ServletResponse servletResponse)，ZuulServlet本质就是一个Servlet。 RequestContext提供了执行filter Pipeline所需要的Context，因为Servlet是单例多线程，这就要求RequestContext即要线程安全又要Request安全。context使用ThreadLocal保存，这样每个worker线程都有一个与其绑定的RequestContext，因为worker仅能同时处理一个Request，这就保证了Request Context 即是线程安全的，又是Request安全的。所谓Request 安全，即该Request的Context不会与其他同时处理Request冲突。 RequestContext继承了ConcurrentHashMap。 三个核心的方法preRoute(),route(), postRoute()，zuul对request处理逻辑都在这三个方法里，ZuulServlet交给ZuulRunner去执行。由于ZuulServlet是单例，因此ZuulRunner也仅有一个实例。 因此综上所述，Spring Cloud Zuul的Qps在1000-2000Qps之间是有原因的，网关作为如此重要的组件，基于如上所述的需求，觉得自研网关中间件纳管Spring Cloud很有必要。 二.自研网关纳管Spring Cloud2.1 网关整合Spring Cloud服务治理体系2.1.1 整合服务治理体系思路 如果服务注册中心使用的是Eureka，可以不引入Spring Cloud Eureka相关的依赖，直接通过定时任务发起Eureka REST请求，网关自身维护一个缓存列表，自己写LB，找到服务列表转发。 优点：不需要引入Spring Cloud，对网关Server进行瘦身，洁癖讨厌各种引入无用的jar；缺点: 注册中心使用Eureka，可以通过Eureka REST接口获取服务注册列表，但是换成ZK，Consul，或者Etcd，直接歇菜。 通过集成Spring Cloud Common中高度抽象的DiscoveryClient。 优点: 通过高度抽象的DiscoveryClient，无需关心实现细节和定时任务去刷新注册列表。缺点：换注册中心，需要相应的更换对应配置和依赖，一堆有些无关紧要的jar，需要自己对其瘦身。 2.1.2 网关整合Spring Cloud Eureka1.引入Spring Cloud Eureka Starter，排除不用的依赖，还需要努力瘦身ing。 1234567891011121314151617181920212223242526272829&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;version&gt;1.3.1.RELEASE&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-netflix-core&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;com.netflix.ribbon&lt;/groupId&gt; &lt;artifactId&gt;ribbon-eureka&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-ribbon&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt; spring-cloud-starter-archaius &lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;artifactId&gt;hibernate-validator&lt;/artifactId&gt; &lt;groupId&gt;org.hibernate&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt; 2、同Zuul一样，把网关自身注册到Eureka Server上，目的是为了获取服务注册列表。 123456server.port=8082spring.application.name=janus-servereureka.client.service-url.defaultZone=http://localhost:8761/eureka/ PS:鄙视的一点就是，Spring Cloud应该提供一个轻量级的java client，配置注册中心的地址，还不需要把网关自身注册到注册中心上。原因是：网关中间件，不需要和服务治理框架耦合的很深。 2.1.3 Netty Server与Spring Cloud内置的Server的整合Netty Http Servert提供端口用于接收网关对外的请求，Spring Boot内置的server提供端口用于和Gateway-console交互，目前没找到Spring Boot内置Server和Netty Server合二为一的方法，但是一个服务暴露两个端口，很有必要。 1234567891011121314151617181920212223242526272829303132@SpringBootApplication@EnableDiscoveryClientpublic class JanusServerAppliaction { private static Logger logger = LoggerFactory.getLogger(JanusServerAppliaction.class); // 非SSL的监听HTTP端口 public static int httpPort = 8081; public static void main(String[] args) throws Exception { //①先启动Spring Boot内置Server SpringApplication.run(JanusServerAppliaction.class, args); // logger.info(\"services: {}\", context.getBean(\"discoveryClient\", // DiscoveryClient.class).getServices()); logger.info(\"Gateway Server Application Start...\"); // 解析启动参数 parseArgs(args); // 初始化网关Filter和配置 logger.info(\"init Gateway Server ...\"); JanusBootStrap.initGateway(); logger.info(\"start netty Server...\"); final JanusNettyServer gatewayServer = new JanusNettyServer(); // ②启动HTTP容器 gatewayServer.startServer(httpPort); }} NettyServer服务启动后，阻塞监听端口,会导致集成spring boot内置Server启动无日志打印，spring Boot容器也没启动。因此注意启动顺序。 2.2 提高自研网关的QPS必杀技2.2.1 NettyServer初始化及启动代码自研网关使用netty自带的线程池，共有三组线程池，分别为bossGroup、workerGroup和executorGroup，bossGroup用于接收客户端的TCP连接，workerGroup用于处理I/O等，executorGroup用于处理网关作业(执行Filter链)。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public void startServer(int noSSLPort) throws InterruptedException { // http请求ChannelInbound final HttpInboundHandler httpInboundHandler = new HttpInboundHandler(); ServerBootstrap insecure = new ServerBootstrap(); insecure.group(bossGroup, workerGroup).channel(NioServerSocketChannel.class) // SO_REUSEADDR,表示允许重复使用本地地址和端口 .option(ChannelOption.SO_REUSEADDR, Boolean.TRUE) .option(ChannelOption.ALLOCATOR, ByteBufManager.byteBufAllocator) /** * SO_KEEPALIVE * 该参数用于设置TCP连接，当设置该选项以后，连接会测试链接的状态，这个选项用于可能长时间没有数据交流的连接。当设置该选项以后， * 如果在两小时内没有数据的通信时，TCP会自动发送一个活动探测数据报文。 */ .childOption(ChannelOption.SO_KEEPALIVE, Boolean.TRUE) .childOption(ChannelOption.TCP_NODELAY, Boolean.TRUE) .childOption(ChannelOption.ALLOCATOR, ByteBufManager.byteBufAllocator) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() { @Override public void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); // 对channel监控的支持 暂不支持 // keepalive_timeout 的支持 pipeline.addLast( new IdleStateHandler(ProperityConfig.keepAliveTimeout, 0, 0, TimeUnit.MILLISECONDS)); // pipeline.addLast(new JanusHermesHandler()); pipeline.addLast(new HttpResponseEncoder()); // 经过HttpRequestDecoder会得到N个对象HttpRequest,first HttpChunk,second // HttpChunk,....HttpChunkTrailer pipeline.addLast(new HttpRequestDecoder( ProperityConfig.maxInitialLineLength, ProperityConfig.maxHeaderSize, 8192, ProperityConfig.validateHeaders)); // 把HttpRequestDecoder得到的N个对象合并为一个完整的http请求对象 pipeline.addLast(new HttpObjectAggregator( ProperityConfig.httpAggregatorMaxLength)); // gzip的支持 if (ProperityConfig.gzip) { pipeline.addLast(new JanusHttpContentCompressor( ProperityConfig.gzipLevel, ProperityConfig.gzipMinLength)); } pipeline.addLast(httpInboundHandler); } }); ChannelFuture insecureFuture = insecure.bind(noSSLPort).sync(); logger.info(\"[listen HTTP NoSSL][\" + noSSLPort + \"]\"); /** * Wait until the server socket is closed.&lt;/br&gt; * 找到之前的无日志打印spring 容器也没启动的原因了，集成spring boot * 和eureka放上放下并不是问题，是因为JanusNettyServer服务启动后，阻塞监听端口导致的 **/ insecureFuture.channel().closeFuture().sync(); logger.info(\"[stop HTTP NoSSL success]\"); } 2.2.2 基于Netty Channel Pool实现REST的异步转发RestInvokerFilter异步转发Filter，基于Netty Channel Pool实现REST的异步转发,提高自网关的性能的必杀技。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class RestInvokerFilter extends AbstractFilter { @Override public void run(final AbstractFilterContext filterContext, final JanusHandleContext janusHandleContext) throws Exception { // 自定义LB从Spring Cloud中服务注册缓存列表中获取服务实例 ServiceInstance serviceInstance = SpringCloudHelper.getServiceInstanceByLB( janusHandleContext, janusHandleContext.getAPIInfo().getRouteServiceId()); // 生成发送的Request对象 FullHttpRequest outBoundRequest = getOutBoundHttpRequest(janusHandleContext); // 转发的时候设置LB获取到的主机IP和端口即可 AsyncHttpRequest.builder() .remoteAddress( serviceInstance.getHost() + \":\" + serviceInstance.getPort()) .sessionContext(janusHandleContext) /** * connection holding 500ms */ .holdingTimeout(ProperityConfig.janusHttpPoolOauthMaxHolding).build() .execute(new SimpleHttpCallback(janusHandleContext) { @Override public void onSuccess(FullHttpResponse result) { // testResult(result); janusHandleContext.setRestFullHttpResponse(result); // 跳转到下一个Filter filterContext.skipNextFilter(janusHandleContext); } @Override public void onError(Throwable e) { //省略 } @Override public void onTimeout() { //省略 } }, outBoundRequest); } //其余省略} 三.自研网关Filter链的设计一层接口，一层 abstract类，一层基于Event观察者模式的抽象类，一个基于观察者模式的接口， 自定义Filter根据需要继承处理，在这里不做过多介绍。 四.自研网关纳管Spring Cloud的结果4.1 自研网关注册到Eureka Server上把自研网关注册到Eureka Server上，用于获取服务列表，如下图所示。 上图中有两个服务提供者1，2，以及一个网关Server。 4.2 无缝支持REST转REST的GET和POST的转发自定义LB，基于Netty Channel Pool实现了GET，POST的协议适配和异步转发，如下所示。 http://localhost:8081/，是本地网关Server的主机和端口。 五.参考文章Netty系列之Netty线程模型","link":"/janus/janus-01/"},{"title":"并发编程总结之多线程基础","text":"线程安全线程安全概念 当多个线程访问访问某一个类(对象或方法)时，这个类或对象或方法始终能表现出正确的行为或我们想要的结果，那么这个类(对象或方法)就是线程安全的。 synchronized：可以在任意的对象及方法上加锁，而加锁的这段代码称之为互斥区或者临界区。代码示例说明1运行main方法，main方法里有5个线程t1到t5，同一时间启动去访问MyThread类的Run方法。 不加synchronized关键字修饰run()方法的代码1234567891011121314151617181920212223242526272829package org.xujin.multithread;public class MyThread extends Thread { private int count = 5; public void run() { count--; System.out.println(this.currentThread().getName() + \" count = \" + count); } public static void main(String[] args) { /** * 分析：当多个线程访问myThread的run方法时，以排队的方式进行处理（这里排对是按照CPU分配的先后顺序而定的）， 一个线程想要执行synchronized修饰的方法里的代码： 1 尝试获得锁 2 * 如果拿到锁，执行synchronized代码体内容；拿不到锁，这个线程就会不断的尝试获得这把锁，直到拿到为止， 而且是多个线程同时去竞争这把锁。（也就是会有锁竞争的问题） */ MyThread myThread = new MyThread(); Thread t1 = new Thread(myThread, \"t1\"); Thread t2 = new Thread(myThread, \"t2\"); Thread t3 = new Thread(myThread, \"t3\"); Thread t4 = new Thread(myThread, \"t4\"); Thread t5 = new Thread(myThread, \"t5\"); t1.start(); t2.start(); t3.start(); t4.start(); t5.start(); }} 运行结果如下，没有出现我们想要的结果,打印出来的线程名是无序的 count值也没按正常–，运行多次不能保证count打印的值每次一致，因此出现了线程安全问题。12345t1 count = 2t2 count = 2t5 count = 0t3 count = 2t4 count = 1 代码示例说明2 当我们加上synchronized关键字修饰run()方法后，代码如下。 123456789101112131415161718192021222324252627public class MyThread extends Thread { private int count = 5; public synchronized void run() { count--; System.out.println(this.currentThread().getName() + \" count = \" + count); } public static void main(String[] args) { /** * 分析：当多个线程访问myThread的run方法时，以排队的方式进行处理（这里排对是按照CPU分配的先后顺序而定的）， 一个线程想要执行synchronized修饰的方法里的代码： 1 尝试获得锁 2 * 如果拿到锁，执行synchronized代码体内容；拿不到锁，这个线程就会不断的尝试获得这把锁，直到拿到为止， 而且是多个线程同时去竞争这把锁。（也就是会有锁竞争的问题） */ MyThread myThread = new MyThread(); Thread t1 = new Thread(myThread, \"t1\"); Thread t2 = new Thread(myThread, \"t2\"); Thread t3 = new Thread(myThread, \"t3\"); Thread t4 = new Thread(myThread, \"t4\"); Thread t5 = new Thread(myThread, \"t5\"); t1.start(); t2.start(); t3.start(); t4.start(); t5.start(); }} 加上synchronized运行结果如下，线程名无序，无论你执行多少次程序，count–的值都是显示我们想要的正确结果。 12345t1 count = 4t3 count = 3t4 count = 2t5 count = 1t2 count = 0 小结 当多个线程访问Mythread的run方法时，以排队的方式进行处理(排队的方式是按照CPU分配的饿先后顺序而定的)，一个线程想要执行synchronized修饰的方法里的代码，首先尝试获得锁，如果拿到锁，执行synchronized中代码体内容;拿不到锁，这个线程就会不断的尝试获得这把锁，直到拿到为止，而且是多个线程同时去竞争这把锁，也就是会有竞争锁的问题。 多个线程多个锁多个线程多个锁:多个线程，每个线程都可以拿到自己指定的锁，分别获得锁之后，执行synchronized方法体的内容。 代码示例说明1 两个线程t1,t2分别依次start，访问两个对象的synchronized修饰的printNum方法，Code如下:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657/** * 关键字synchronized取得的锁都是对象锁，而不是把一段代码（方法）当做锁， * 所以代码中哪个线程先执行synchronized关键字的方法，哪个线程就持有该方法所属对象的锁（Lock）， * * 在静态方法上加synchronized关键字，表示锁定.class类，类一级别的锁（独占.class类）。 * @author xujin * */public class MultiThread { private int num = 0; public synchronized void printNum(String tag) { try { if (tag.equals(\"a\")) { num = 100; System.out.println(\"tag a, set num over!\"); Thread.sleep(1000); } else { num = 200; System.out.println(\"tag b, set num over!\"); } System.out.println(\"tag \" + tag + \", num = \" + num); } catch (InterruptedException e) { e.printStackTrace(); } } // 注意观察run方法输出顺序 public static void main(String[] args) { // 两个不同的对象 final MultiThread m1 = new MultiThread(); final MultiThread m2 = new MultiThread(); Thread t1 = new Thread(new Runnable() { @Override public void run() { m1.printNum(\"a\"); } }); Thread t2 = new Thread(new Runnable() { @Override public void run() { m2.printNum(\"b\"); } }); t1.start(); t2.start(); }} 执行结果如下:1234tag a, set num over!tag b, set num over!tag b, num = 200tag a, num = 100 关键字synchronized取得的锁都是对象锁，而不是把一段代码（方法）当做锁，所以代码中哪个线程先执行synchronized关键字的方法，哪个线程就持有该方法所属对象的锁（Lock） 代码示例说明2 在静态方法上printNum（）加一个synchronized关键字修饰的话，那这个线程调用printNum()获得锁，就是这个类级别的锁。这是时候无论你实例化出多少个对象m1,m2都是没有任何关系的，代码Demo如下所示：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class MultiThread { // ②修改为static关键字修饰 private static int num = 0; // ①修改为static修饰该方法 public static synchronized void printNum(String tag) { try { if (tag.equals(\"a\")) { num = 100; System.out.println(\"tag a, set num over!\"); Thread.sleep(1000); } else { num = 200; System.out.println(\"tag b, set num over!\"); } System.out.println(\"tag \" + tag + \", num = \" + num); } catch (InterruptedException e) { e.printStackTrace(); } } // 注意观察run方法输出顺序 public static void main(String[] args) { // 俩个不同的对象 final MultiThread m1 = new MultiThread(); final MultiThread m2 = new MultiThread(); Thread t1 = new Thread(new Runnable() { @Override public void run() { m1.printNum(\"a\"); } }); Thread t2 = new Thread(new Runnable() { @Override public void run() { m2.printNum(\"b\"); } }); t1.start(); t2.start(); }} 运行结果如下,可以看出t1执行完了，然后执行t2,他们之间有一个顺序1234tag a, set num over!tag a, num = 100tag b, set num over!tag b, num = 200 多个线程多个锁小结 关键字synchronized取得的锁都是对象锁，而不是把一段代码或方法当做锁，所以示例中代码中的哪个线程先执行synchronized关键字的方法，哪个线程就持有该方法对象的锁，也就是Lock,两个对象，线程获得的就是两个不同的锁，他们互不影响。 有一种情况则是相同的锁，即在静态方法上加synchronized关键字，表示锁定.class类，类一级别的锁独占.class类。 对象锁的同步和异步锁同步和异步的概念 同步-synchronized 同步的概念就是共享，需要记住共享这个概念，如果不是共享的资源，就没有必要同步。 异步-asynchronized 异步是相互独立的，相互之间不受任何约制，类似于http中的Ajax请求。 同步的目的就是为了线程安全，其实对于线程安全来说，需要满足两个特性：原子性，可见性。 代码示例11234567891011121314151617181920212223242526272829303132333435363738394041424344public class TestObject { /** synchronized */ public synchronized void method1() { try { System.out.println(Thread.currentThread().getName()); //休眠4秒 Thread.sleep(4000); } catch (InterruptedException e) { e.printStackTrace(); } } public void method2() { System.out.println(Thread.currentThread().getName()); } public static void main(String[] args) { final TestObject mo = new TestObject(); /** * 分析： t1线程先持有TestObject对象的Lock锁，t2线程可以以异步的方式调用对象中的非synchronized修饰的方法 * t1线程先持有TestObject对象的Lock锁，t2线程如果在这个时候调用对象中的同步（synchronized）方法则需等待，也就是同步 */ Thread t1 = new Thread(new Runnable() { @Override public void run() { mo.method1(); } }, \"t1\"); Thread t2 = new Thread(new Runnable() { @Override public void run() { mo.method2(); } }, \"t2\"); t1.start(); t2.start(); }} 运行结果如下，因为t1,t2两个线程访问TestObject对象的mo的method1，method2方法是异步的，所以直接打出。12t2t1 分析： t1线程若先持有TestObject对象的Lock锁，t2线程可以以异步的方式调用对象中的非synchronized修饰的方法，这就是异步。 代码示例2把上面代码中的method2，也加上synchronized去修饰，代码如下:1234567891011121314151617181920212223242526272829303132333435363738394041424344public class TestObject { public synchronized void method1() { try { System.out.println(Thread.currentThread().getName()); Thread.sleep(4000); } catch (InterruptedException e) { e.printStackTrace(); } } /** 加上synchronized修饰method2 */ public synchronized void method2() { System.out.println(Thread.currentThread().getName()); } public static void main(String[] args) { final TestObject mo = new TestObject(); /** * 分析： t1线程先持有TestObject对象的Lock锁，t2线程可以以异步的方式调用对象中的非synchronized修饰的方法 * t1线程先持有TestObject对象的Lock锁，t2线程如果在这个时候调用对象中的同步（synchronized）方法则需等待，也就是同步 */ Thread t1 = new Thread(new Runnable() { @Override public void run() { mo.method1(); } }, \"t1\"); Thread t2 = new Thread(new Runnable() { @Override public void run() { mo.method2(); } }, \"t2\"); t1.start(); t2.start(); }} 打印结果如下,由于CPU随机分配，若t1线程先执行，先打印t1,然后t1线程先休眠4s，后释放了Lock，然后打印t2。12t1t2 t1线程先持有TestObject对象的Lock锁，t2线程如果在这个时候调用对象中的同步（synchronized）方法则需等待，也就是同步","link":"/bf/bf-multithread/"},{"title":"并发编程总结之线程间的通信","text":"摘要:使用wait/notify方法实现线程间的通信。wait和notify必须配合synchronized关键字使用，wait方法释放锁，notify方法不释放锁。 线程间通信概念 线程是操作系统中独立的个体，但这些个体如果不经过特殊的处理就不能成为一个整体，线程间的通信就成为整体的必用方式之一。当线程存在通信指挥，系统间的交互会更加强大，在提高CPU利用率的同时还会使开发人员对线程任务在处理的过程中进行有效的把控与监督。 wait/notify实现线程通信 使用wait/notify方法实现线程间的通信。注意这两个方法都是Object的类方法，换句话说Java为所有的对象提供了这个两个方法。 1.wait和notify必须配合synchronized关键字使用 2.wait方法释放锁，notify方法不释放锁。 最原始线程间通信代码如下面代码所示，t1,t2两个线程，t1线程一直循环add，t2线程一直循环，当t1线程把list的size变为5的时候，t2线程抛出异常停止。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758import java.util.ArrayList;import java.util.List;/** * * @author xujin * */public class ListAdd1 { private volatile static List&lt;String&gt; list = new ArrayList(); public void add() { list.add(\"test....\"); } public int size() { return list.size(); } public static void main(String[] args) { final ListAdd1 list1 = new ListAdd1(); Thread t1 = new Thread(new Runnable() { @Override public void run() { try { for (int i = 0; i &lt; 10; i++) { list1.add(); System.out .println(\"当前线程：\" + Thread.currentThread().getName() + \"添加了一个元素..\"); Thread.sleep(500); } } catch (InterruptedException e) { e.printStackTrace(); } } }, \"t1\"); Thread t2 = new Thread(new Runnable() { @Override public void run() { while (true) { if (list1.size() == 5) { System.out.println(\"当前线程收到通知：\" + Thread.currentThread().getName() + \" list size = 5 线程停止..\"); throw new RuntimeException(); } } } }, \"t2\"); t1.start(); t2.start(); }} wait和notify实现线程间通信代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970import java.util.ArrayList;import java.util.List;/** * @author xujin * */public class ListAdd2 { private volatile static List list = new ArrayList(); public void add() { list.add(\"test.......\"); } public int size() { return list.size(); } public static void main(String[] args) { final ListAdd2 list2 = new ListAdd2(); final Object lock = new Object(); Thread t1 = new Thread(new Runnable() { @Override public void run() { try { synchronized (lock) { System.out.println(\"t1启动..\"); for (int i = 0; i &lt; 10; i++) { list2.add(); System.out.println( \"当前线程：\" + Thread.currentThread().getName() + \"添加了一个元素..\"); Thread.sleep(500); if (list2.size() == 5) { System.out.println(\"已经发出通知..\"); lock.notify(); } } } } catch (InterruptedException e) { e.printStackTrace(); } } }, \"t1\"); Thread t2 = new Thread(new Runnable() { @Override public void run() { synchronized (lock) { System.out.println(\"t2启动..\"); if (list2.size() != 5) { try { //t2线程，拿到了锁，但是size不等于5,所以lock.wait(),释放了锁，然后t1得到t2释放的锁。 System.out.println(\"size() != 5,t2 wait释放锁！..\"); lock.wait(); } catch (InterruptedException e) { e.printStackTrace(); } } System.out.println(\"当前线程：\" + Thread.currentThread().getName() + \"收到通知线程停止..\"); throw new RuntimeException(); } } }, \"t2\"); t1.start(); t2.start(); }} 运行结果分析如下: 通过上面的运行结果分析，可以看出线程间的通信，因为持有锁的问题，使用wait、notify线程间通信，没法做到实时通信。 使用java.util.concurrent下的CountDownLatch实现实时通信示例代码，如下所示：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576import java.util.ArrayList;import java.util.List;import java.util.concurrent.CountDownLatch;/** * @author xujin * */public class ListAdd3 { private volatile static List list = new ArrayList(); public void add() { list.add(\"test.......\"); } public int size() { return list.size(); } public static void main(String[] args) { final ListAdd3 list2 = new ListAdd3(); // final Object lock = new Object(); final CountDownLatch countDownLatch = new CountDownLatch(1); Thread t1 = new Thread(new Runnable() { @Override public void run() { try { // synchronized (lock) { System.out.println(\"t1启动..\"); for (int i = 0; i &lt; 10; i++) { list2.add(); System.out.println( \"当前线程：\" + Thread.currentThread().getName() + \"添加了一个元素..\"); Thread.sleep(500); if (list2.size() == 5) { System.out.println(\"已经发出通知..\"); // lock.notify(); countDownLatch.countDown(); } } // } } catch (InterruptedException e) { e.printStackTrace(); } } }, \"t1\"); Thread t2 = new Thread(new Runnable() { @Override public void run() { // synchronized (lock) { System.out.println(\"t2启动..\"); if (list2.size() != 5) { try { // lock.wait(); countDownLatch.await(); } catch (InterruptedException e) { e.printStackTrace(); } } System.out.println( \"当前线程：\" + Thread.currentThread().getName() + \"收到通知线程停止..\"); throw new RuntimeException(); } // } }, \"t2\"); t2.start(); t1.start(); }} countDownLatch.countDown();相当于lock.notify()；countDownLatch.await()相当于lock.wait(); 如果final CountDownLatch countDownLatch = new CountDownLatch(2);需要countDownLatch.countDown()两次如下所示。 12345678910111213141516171819202122232425262728final ListAdd3 list2 = new ListAdd3(); // final Object lock = new Object(); final CountDownLatch countDownLatch = new CountDownLatch(2); Thread t1 = new Thread(new Runnable() { @Override public void run() { try { // synchronized (lock) { System.out.println(\"t1启动..\"); for (int i = 0; i &lt; 10; i++) { list2.add(); System.out.println( \"当前线程：\" + Thread.currentThread().getName() + \"添加了一个元素..\"); Thread.sleep(500); if (list2.size() == 5) { System.out.println(\"已经发出通知..\"); // lock.notify(); countDownLatch.countDown(); countDownLatch.countDown(); } } // } } catch (InterruptedException e) { e.printStackTrace(); } } }, \"t1\"); 使用wait/notify模拟Queue BlockingQueue：顾名思义阻塞队列，首先它是一个队列，并且支持阻塞的机制，阻塞的放入和得到数据。我们要实现LinkedBlockingQueue下面两个简单的方法put和get和take。 put(aObject):把一个对象aobject加到BlockingQueue里，如果BlockQueue没有空间，则调用此方法的线程被阻断，直到BlockingQueue里面有空间再继续。 take：取走BlockingQueue里排在首位的对象，若BlockingQueue为空，阻断进入等待状态，直到BlockingQueue有新的数据被加入。示例代码如下123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120import java.util.LinkedList;import java.util.concurrent.TimeUnit;import java.util.concurrent.atomic.AtomicInteger;/** * 使用wait/notify模拟Queue * @author xujin * */public class ImitateQueue { // 承载元素的集合 private final LinkedList&lt;Object&gt; list = new LinkedList&lt;Object&gt;(); // 计数器进行计数 private final AtomicInteger count = new AtomicInteger(0); // 制定元素的上限和下限 private final int maxSize; private final int minSize = 0; // 初始化一个对象用于加锁 private final Object lock = new Object(); public ImitateQueue(int maxSize) { this.maxSize = maxSize; } // 把一个对象aobject加到BlockingQueue里，如果BlockQueue没有空间，则调用此方法的线程被阻断，直到BlockingQueue里面有空间再继续增加 public void put(Object obj) { synchronized (lock) { while (count.get() == maxSize) { try { // 当队列中数据塞满，线程等待 lock.wait(); } catch (InterruptedException e) { e.printStackTrace(); } } list.add(obj); // 计数器自增 count.getAndIncrement(); System.out.println(\" 元素 \" + obj + \" 被添加 \"); // 唤醒之前等待阻塞的take方法线程取数据 lock.notify(); } } // 取走BlockingQueue里排在首位的对象，若BlockingQueue为空，阻断进入等待状态，直到BlockingQueue有新的数据被加入 public Object take() { Object temp = null; synchronized (lock) { while (count.get() == minSize) { try { // 当队列中的元素，取完，该线程等待 lock.wait(); } catch (InterruptedException e) { e.printStackTrace(); } } // 计数器递减 count.getAndDecrement(); // 取出元素 temp = list.removeFirst(); System.out.println(\" 元素 \" + temp + \" 被消费 \"); // 唤醒之前阻塞的put方法把元素放进去 lock.notify(); } return temp; } public int size() { return count.get(); } public static void main(String[] args) throws Exception { final ImitateQueue m = new ImitateQueue(5); m.put(\"a\"); m.put(\"b\"); m.put(\"c\"); m.put(\"d\"); m.put(\"e\"); System.out.println(\"当前元素个数：\" + m.size()); Thread t1 = new Thread(new Runnable() { @Override public void run() { m.put(\"h\"); m.put(\"i\"); } }, \"t1\"); t1.start(); Thread t2 = new Thread(new Runnable() { @Override public void run() { try { Object t1 = m.take(); System.out.println(\"被取走的元素为：\" + t1); Thread.sleep(1000); Object t2 = m.take(); System.out.println(\"被取走的元素为：\" + t2); } catch (InterruptedException e) { e.printStackTrace(); } } }, \"t2\"); // 休眠2秒钟 TimeUnit.SECONDS.sleep(2); t2.start(); }} 程序运行结果如下123456789101112 元素 a 被添加 元素 b 被添加 元素 c 被添加 元素 d 被添加 元素 e 被添加 当前元素个数：5 元素 a 被消费 被取走的元素为：a 元素 h 被添加 元素 b 被消费 被取走的元素为：b 元素 i 被添加","link":"/bf/bf-thread-singal/"},{"title":"并发编程之ThreadLocal与单例的推荐写法","text":"摘要:本文结合最近网关项目代码重构，总结介绍了ThreadLocal是一种多线程间并发访问变量的解决方案，用空间换时间，并用代码示例说明，还介绍了什么是单例以及单例的推荐两种写法分别是静态内部类写法和dubbl check instance的写法，扩展介绍了其它懒汉，枚举,饿汉的写法等。 一.ThreadLocal的概念1.1 ThreadLocal概念ThreadLocal概念：线程局部变量，是一种多线程间并发访问变量的解决方案。与其synchronized等加锁的方式不同，ThreadLocal完全不提供锁，而使用以空间换时间的手段，为每个线程提供变量的独立副本，以保障线程安全。 从性能上说，ThreadLocal不具有绝对的优势，在并发不是很高的时候，加锁的性能会更好，但作为一套与锁完全无关的线程安全解决方案，在高并发量或者竞争激烈的场景，使用ThreadLocal可以在一定程度上减少锁竞争。 ThreadLocal多线程间并发访问变量的解决方案，为每个线程提供变量的副本，用空间换时间。因为ThreadLocal在每个线程中对该变量会创建一个副本，即每个线程内部都会有一个该变量，且在线程内部任何地方都可以使用，线程之间互不影响，这样一来就不存在线程安全问题，也不会严重影响程序执行性能。 虽然ThreadLocal能够解决上面说的问题，但是由于在每个线程中都创建了副本，所以要考虑它对资源的消耗，比如内存的占用会比不使用ThreadLocal要大。 1.2 ThreadLocal代码示例12345678910111213141516171819202122232425262728293031323334353637383940414243package org.xujin.bf;public class ConnThreadLocal { //用ThreadLocal去存储多线程下访问的变量 public static ThreadLocal&lt;String&gt; th = new ThreadLocal&lt;String&gt;(); public void setTh(String value){ th.set(value); } public void getTh(){ System.out.println(Thread.currentThread().getName() + \":\" + this.th.get()); } public static void main(String[] args) throws InterruptedException { final ConnThreadLocal ct = new ConnThreadLocal(); Thread t1 = new Thread(new Runnable() { @Override public void run() { ct.setTh(\"张三\"); ct.getTh(); } }, \"t1\"); Thread t2 = new Thread(new Runnable() { @Override public void run() { try { Thread.sleep(1000); ct.setTh(\"李四\"); ct.getTh(); } catch (InterruptedException e) { e.printStackTrace(); } } }, \"t2\"); t1.start(); t2.start(); } } 执行结果如下: 12t1:张三t2:李四 如上述代码所示，如果把ct.setTh(“李四”)注释，执行结果如下： 12t1:张三t2:null PS:两个线程之前都使用了ThreadLocal包装的变量th，但是Threadlocal两个线程之间数据独立，因此t1,t2两个线程之间数据访问隔离了。 二.单例与多线程什么是单例? 单例是应用或者系统中保证一个类仅有一个实例，并提供一个访问它的全局访问点。 单例模式，最常见的就是饥饿模式和懒汉模式，一个直接实例化对象，一个是在调用方法时进行实例化对象。在多线程模式中，考虑到性能和线程安全，我们一般选择下面两种比较经典的单例模式，在性能提高的同时，又保证线程安全。 单例推荐的写法有dubble check instance，static inner class(静态内部类的模式)，因为简单安全，源生就支持多线程，对多线程比较友好，因此推荐静态内部的写法。 2.1 饿汉模式这种方法非常简单，因为单例的实例被声明成 static 和 final 变量了，在第一次加载类到内存中时就会初始化，所以创建实例本身是线程安全的。 123456789 public class Singleton{ //类加载时就初始化 private static final Singleton instance = new Singleton(); private Singleton(){} public static Singleton getInstance(){ return instance; }} 这种写法如果完美的话，就没必要在啰嗦那么多双检锁的问题了。缺点是它不是一种懒加载模式（lazy initialization），单例会在加载类后一开始就被初始化，即使客户端没有调用 getInstance()方法。饿汉式的创建方式在一些场景中将无法使用：譬如 Singleton 实例的创建是依赖参数或者配置文件的，在 getInstance() 之前必须调用某个方法设置参数给它，那样这种单例写法就无法使用了。 2.2 枚举写法 用枚举写单例实在太简单了！这也是它最大的优点。下面这段代码就是声明枚举实例的通常做法。 123 public enum EasySingleton{ INSTANCE;} 可以通过EasySingleton.INSTANCE来访问实例，这比调用getInstance()方法简单多了。创建枚举默认就是线程安全的，所以不需要担心double checked locking，而且还能防止反序列化导致重新创建新的对象。 2.3 懒汉式，线程不安全12345678910 public class Singleton { private static Singleton instance; private Singleton (){} public static Singleton getInstance() { if (instance == null) { instance = new Singleton(); } return instance; }} 这段代码简单明了，而且使用了懒加载模式，但是却存在致命的问题。当有多个线程并行调用 getInstance() 的时候，就会创建多个实例。也就是说在多线程下不能正常工作。 2.4 懒汉式，线程安全为了解决上面的问题，最简单的方法是将整个 getInstance() 方法设为同步（synchronized）。 123456 public static synchronized Singleton getInstance() { if (instance == null) { instance = new Singleton(); } return instance;} 虽然做到了线程安全，并且解决了多实例的问题，但是它并不高效。因为在任何时候只能有一个线程调用 getInstance() 方法。但是同步操作只需要在第一次调用时才被需要，即第一次创建单例实例对象时。这就引出了双重检验锁。 2.5 单例模式的两种推荐写法2.5.1 静态内部类(static inner class)的方式个人推荐使用静态内部类的方法，这种方法也是《Effective Java》上所推荐的 123456789101112131415161718package org.xujin.bf;/** * @author xujin */public class InnerSingleton { //使用静态内部类，构造单例 private static class Singletion { private static Singletion single = new Singletion(); } //用过暴露getInstance方法，return静态内部类的方式 public static Singletion getInstance(){ return Singletion.single; } } 这种写法仍然使用JVM本身机制保证了线程安全问题；由于 Singletion 是私有的，除了 getInstance() 之外没有办法访问它，因此它是懒汉式的；同时读取实例的时候不会进行同步，没有性能缺陷；也不依赖 JDK 版本。 2.5.2 Dubble Check的方式理解成Dubble Check的写法之前，大家先看一下，我在Janus网关项目的中的写法，如下所示： 123456789101112131415public class ConfigManager extends Observable { private static ConfigManager instance; private ConfigManager() {} public static ConfigManager getInstance() { if (instance == null) { synchronized (ConfigManager.class) { if (instance == null) { instance = new ConfigManager(); } } } return instance; } } 双重检验锁模式（double checked locking pattern），是一种使用同步块加锁的方法。程序员称其为双重检查锁，因为会有两次检查 instance == null，一次是在同步块外，一次是在同步块内。为什么在同步块内还要再检验一次？因为可能会有多个线程一起进入同步块外的 if，如果在同步块内不进行二次检验的话就会生成多个实例了。 2.5.2.1 只做一次check的写法12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class DubbleSingleton { private static DubbleSingleton ds; public static DubbleSingleton getDs(){ //第一次check if(ds == null){ try { //模拟初始化对象的准备时间... Thread.sleep(3000); } catch (InterruptedException e) { e.printStackTrace(); } synchronized (DubbleSingleton.class) { ds = new DubbleSingleton(); } } return ds; } public static void main(String[] args) { Thread t1 = new Thread(new Runnable() { @Override public void run() { System.out.println(DubbleSingleton.getDs().hashCode()); } },\"t1\"); Thread t2 = new Thread(new Runnable() { @Override public void run() { System.out.println(DubbleSingleton.getDs().hashCode()); } },\"t2\"); Thread t3 = new Thread(new Runnable() { @Override public void run() { System.out.println(DubbleSingleton.getDs().hashCode()); } },\"t3\"); t1.start(); t2.start(); t3.start(); } } 三个线程访问执行结果，打印出来的饿HashCode 12318921053615138969011785098644 如上述所示，只做一次check的写法，导致三个线程访问，hashCode不一致，原因没有做两次check。 2.5.2.2 做两次check的写法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455package org.xujin.bf;/** * @author xujin */public class DubbleSingleton { private static DubbleSingleton ds; public static DubbleSingleton getDs() { //???check if (ds == null) { try { //????????????... Thread.sleep(3000); } catch (InterruptedException e) { e.printStackTrace(); } synchronized (DubbleSingleton.class) { //???check,??????check? if (ds == null) { ds = new DubbleSingleton(); } } } return ds; } public static void main(String[] args) { Thread t1 = new Thread(new Runnable() { @Override public void run() { System.out.println(DubbleSingleton.getDs().hashCode()); } }, \"t1\"); Thread t2 = new Thread(new Runnable() { @Override public void run() { System.out.println(DubbleSingleton.getDs().hashCode()); } }, \"t2\"); Thread t3 = new Thread(new Runnable() { @Override public void run() { System.out.println(DubbleSingleton.getDs().hashCode()); } }, \"t3\"); t1.start(); t2.start(); t3.start(); }} 三个线程访问执行结果，打印出来的饿HashCode 123786514993786514993786514993 这段代码看起来很完美，很可惜，它是有问题。主要在于ds = new DubbleSingleton();这句，这并非是一个原子操作，事实上在 JVM 中这句话大概做了下面 3 件事情。 1.给 instance 分配内存 2.调用 Singleton 的构造函数来初始化成员变量 3.将instance对象指向分配的内存空间（执行完这步instance就为非null了） 但是在 JVM 的即时编译器中存在指令重排序的优化。也就是说上面的第二步和第三步的顺序是不能保证的，最终的执行顺序可能是 1-2-3 也可能是 1-3-2。如果是后者，则在 3 执行完毕、2 未执行之前，被线程二抢占了，这时 instance 已经是非 null 了（但却没有初始化），所以线程二会直接返回 instance，然后使用，然后顺理成章地报错 但是我们只需要将 instance 变量声明成 volatile如下所示，示例代码就OK。 123456789101112131415public class Singleton { private volatile static Singleton instance; //声明成 volatile private Singleton (){} public static Singleton getSingleton() { if (instance == null) { synchronized (Singleton.class) { if (instance == null) { instance = new Singleton(); } } } return instance; } } 有些人认为使用 volatile 的原因是可见性，也就是可以保证线程在本地不会存有 instance 的副本，每次都是去主内存中读取。但其实是不对的。使用 volatile 的主要原因是其另一个特性：禁止指令重排序优化。也就是说，在 volatile 变量的赋值操作后面会有一个内存屏障（生成的汇编代码上），读操作不会被重排序到内存屏障之前。比如上面的例子，取操作必须在执行完 1-2-3 之后或者 1-3-2 之后，不存在执行到 1-3 然后取到值的情况。从「先行发生原则」的角度理解的话，就是对于一个 volatile 变量的写操作都先行发生于后面对这个变量的读操作（这里的“后面”是时间上的先后顺序）。 但是特别注意在 jdk 1.5 以前的版本使用了 volatile 的双检锁还是有问题的。其原因是 Java 5 以前的 JMM （Java 内存模型）是存在缺陷的，即时将变量声明成 volatile 也不能完全避免重排序，主要是 volatile 变量前后的代码仍然存在重排序问题。这个 volatile 屏蔽重排序的问题在 jdk 1.5 中才得以修复，所以在这之后才可以放心使用 volatile 在JDK1.5及其后续版本中，扩充了volatile语义，系统将不允许对 写入一个volatile变量的操作与其之前的任何读写操作 重新排序，也不允许将 读取一个volatile变量的操作与其之后的任何读写操作 重新排序。 三.参考文章使用单例模式需要注意的几个问题 双重检查锁定失败可能性","link":"/bf/bf-th-sing/"},{"title":"网关两种限流调研","text":"背景在开发高并发系统时有三把利器用来保护系统：缓存、降级和限流。缓存的目的是提升系统访问速度和增大系统能处理的容量，可谓是抗高并发流量的银弹；而降级是当服务出问题或者影响到核心流程的性能则需要暂时屏蔽掉，待高峰或者问题解决后再打开；而有些场景并不能用缓存和降级来解决，比如稀缺资源（秒杀、抢购）、写服务（如评论、下单）、频繁的复杂查询（评论的最后几页），因此需有一种手段来限制这些场景的并发/请求量，即限流。 限流的目的是通过对并发访问/请求进行限速或者一个时间窗口内的的请求进行限速来保护系统，一旦达到限制速率则可以拒绝服务（定向到错误页或告知资源没有了）、排队或等待（比如秒杀、评论、下单）、降级（返回兜底数据或默认数据，如商品详情页库存默认有货）。 一般的中间件都会有单机限流框架，支持两种限流模式：控制速率和控制并发。限流这种东西，应该是来源于网络里面的「流量整型」，通过控制数据包的传输速率和时机，来实现一些性能、服务质量方面的东西。 常见的限流算法有：令牌桶、漏桶。计数器也可以进行粗暴限流实现。 常见的限流算法常见的限流算法主要有两种：令牌桶算法和漏桶算法。 漏桶算法：如图packet先进入到漏桶里，漏桶以一定的速度出水（packet），当请求过大会直接溢出，可以看出漏桶算法能强行限制数据的传输速率。 令牌桶(Token Bucket)令牌桶算法的原理是系统会以一个恒定的速度往桶里放入令牌，直到到达令牌桶容量，令牌不在增加，而如果请求需要被处理，则需要先从桶里获取一个令牌，当桶里没有令牌可取时，则拒绝服务。 令牌桶控制的是一个时间窗口内的通过的数据量，在 API 层面我们常说的 QPS、TPS，正好是一个时间窗口内的请求量或者事务量，只不过时间窗口限定在 1s 罢了。 假如项目使用 Java 语言，我们可以轻松地借助 Guava 的 RateLimiter 来实现基于令牌桶的流控。RateLimiter 令牌桶算法的单桶实现，也许是因为在 Web 应用层面单桶实现就够用了，双桶实现就属于过度设计。 RateLimiter 对简单的令牌桶算法做了一些工程上的优化，具体的实现是 SmoothBursty。需要注意的是，RateLimiter 的另一个实现 SmoothWarmingUp，就不是令牌桶了，而是漏桶算法。也许是出于简单起见，RateLimiter 中的时间窗口能且仅能为 1s，如果想搞其他时间单位的限流，只能另外造轮子。 在 Wikipedia 上，令牌桶算法的基本过程如下: 每秒会有 r 个令牌放入桶中，或者说，每过 1/r 秒桶中增加一个令牌 桶中最多存放 b 个令牌，如果桶满了，新放入的令牌会被丢弃 当一个 n 字节的数据包到达时，消耗 n 个令牌，然后发送该数据包 如果桶中可用令牌小于 n，则该数据包将被缓存或丢弃 我们可以使用 Guava 的 RateLimiter 来实现基于令牌桶的流量控制。RateLimiter 令牌桶算法的单桶实现,RateLimiter 对简单的令牌桶算法做了一些工程上的优化，具体的实现是 SmoothBursty。需要注意的是，RateLimiter 的另一个实现 SmoothWarmingUp，就不是令牌桶了，而是漏桶算法。 SmoothBursty 有一个可以放 N 个时间窗口产生的令牌的桶，系统空闲的时候令牌就一直攒着，最好情况下可以扛 N 倍于限流值的高峰而不影响后续请求,就像三峡大坝一样能扛千年一遇的洪水. 下面写个demo 测试一下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263import java.util.concurrent.ConcurrentHashMap;import java.util.concurrent.ConcurrentMap;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import com.google.common.util.concurrent.RateLimiter;public class FlowLimitUtils { private static final ConcurrentMap&lt;String, RateLimiter&gt; resourceRateLimiterMap = new ConcurrentHashMap&lt;String, RateLimiter&gt;(); public static void createFlowLimitMap(String resource, double qps) { RateLimiter limiter = resourceRateLimiterMap.get(resource); if (limiter == null) { limiter =RateLimiter.create(qps); resourceRateLimiterMap.putIfAbsent(resource, limiter); } limiter.setRate(qps); } public static boolean enter(String resource) throws Exception { RateLimiter limiter = resourceRateLimiterMap.get(resource); if (limiter == null) { throw new Exception(resource); } if (!limiter.tryAcquire()) { System.out.println(\"&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;被限流了&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;\"); return true; } return false; } static class TestWork implements Runnable{ @Override public void run() { try { if(!enter(\"test\")){ System.out.println(\"++++++++++++ 没有被限流\"); } } catch (Exception e) { // TODO Auto-generated catch block e.printStackTrace(); } } } public static void main(String[] args) throws InterruptedException { String source=\"test\"; double qps=10; createFlowLimitMap(source, qps); Thread.sleep(1000l); ExecutorService pools=Executors.newFixedThreadPool(40); for(int i=0;i&lt;16;i++){ TestWork testWork=new TestWork(); pools.execute(testWork); } } } 基于Guava RateLimiter实现限流1.在Java项目中pom.xml文件中添加依赖 12345&lt;dependency&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;version&gt;19.0-rc2&lt;/version&gt;&lt;/dependency&gt; 2.在需要限流的控制类中创建一个reteLimiter对象，用来控制某个接口的请求并发线程数 漏桶(Leaky bucket)算法 漏桶算法思路很简单，水（请求）先进入到漏桶里，漏桶以一定的速度出水，当水流入速度过大会直接溢出，可以看出漏桶算法能强行限制数据的传输速率。 如上图所示packet先进入到漏桶里，漏桶以一定的速度出水（packet），当请求过大会直接溢出。 可以看出，漏桶算法可以强制网络传输的速率，但无法处理突发传输，比如接口请求量在某一时刻突然激增到了十多倍，如果应用接口毫无限制的处理请求返回数据包，很有可能造成整个应用的不可用。这个时候我们就需要使用令牌桶算法，来控制这种突发传输。 对于限流来说控制速率，相对来说用的很多，简单的比如线程池；我们可以通过ThreadPoolExecutor来创建一个线程池： 1new ThreadPoolExecutor(corePoolSize, maximumPoolSize, keepAliveTime, milliseconds,runnableTaskQueue, handler); 创建一个线程池需要输入几个参数： corePoolSize（线程池的基本大小）：当提交一个任务到线程池时，线程池会创建一个线程来执行任务，即使其他空闲的基本线程能够执行新任务也会创建线程，等到需要执行的任务数大于线程池基本大小时就不再创建。如果调用了线程池的prestartAllCoreThreads方法，线程池会提前创建并启动所有基本线程。 runnableTaskQueue（任务队列）：用于保存等待执行的任务的阻塞队列。 可以选择以下几个阻塞队列。 ArrayBlockingQueue：是一个基于数组结构的有界阻塞队列，此队列按 FIFO（先进先出）原则对元素进行排序。 LinkedBlockingQueue：一个基于链表结构的阻塞队列，此队列按FIFO （先进先出） 排序元素，吞吐量通常要高于ArrayBlockingQueue。静态工厂方法 Executors.newFixedThreadPool()使用了这个队列。 SynchronousQueue：一个不存储元素的阻塞队列。每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于LinkedBlockingQueue，静态工厂方法Executors.newCachedThreadPool使用了这个队列。 PriorityBlockingQueue：一个具有优先级的无限阻塞队列。 maximumPoolSize（线程池最大大小）：线程池允许创建的最大线程数。如果队列满了，并且已创建的线程数小于最大线程数，则线程池会再创建新的线程执行任务。值得注意的是如果使用了无界的任务队列这个参数就没什么效果。 ThreadFactory：用于设置创建线程的工厂，可以通过线程工厂给每个创建出来的线程设置更有意义的名字。 RejectedExecutionHandler（饱和策略）：当队列和线程池都满了，说明线程池处于饱和状态，那么必须采取一种策略处理提交的新任务。这个策略默认情况下是AbortPolicy，表示无法处理新任务时抛出异常。以下是JDK1.5提供的四种策略。 AbortPolicy：直接抛出异常。 CallerRunsPolicy：只用调用者所在线程来运行任务。 DiscardOldestPolicy：丢弃队列里最近的一个任务，并执行当前任务。 DiscardPolicy：不处理，丢弃掉。 当然也可以根据应用场景需要来实现RejectedExecutionHandler接口自定义策略。如记录日志或持久化不能处理的任务。 keepAliveTime（线程活动保持时间）：线程池的工作线程空闲后，保持存活的时间。所以如果任务很多，并且每个任务执行的时间比较短，可以调大这个时间，提高线程的利用率。 TimeUnit（线程活动保持时间的单位）：可选的单位有天（DAYS），小时（HOURS），分钟（MINUTES），毫秒(MILLISECONDS)，微秒(MICROSECONDS, 千分之一毫秒)和毫微秒(NANOSECONDS, 千分之一微秒)。通过控制以上几个参数的调优，可以最大程度的限制最大引流速率； 参考链接http://blog.csdn.net/jiesa/article/details/50412027","link":"/mw/flowlimit01/"},{"title":"数据库连性池性能测试(hikariCP,druid,tomcat-jdbc,dbcp,c3p0)","text":"摘要: 本文根据唯品会中间件团队对外的测试报告整理，用于学习记录版权归原作者所有。主要是对这hikariCP,druid,tomcat-jdbc,dbcp,c3p0几种连接池的详细的功能和性能测试对比,通过这次测试对目前主流的一些连接池做一个全面的对比，从而给业务系统一个最佳的推荐。而唯品会venus-data支持三种连接池DBCP、C3P0、DRUID，其中C3P0作为默认的连接池。因此需要针对现状，研发一种分布式数据库连接池。 测试结论 性能方面 hikariCP&gt;druid&gt;tomcat-jdbc&gt;dbcp&gt;c3p0 。hikariCP的高性能得益于最大限度的避免锁竞争。 druid功能最为全面，sql拦截等功能，统计数据较为全面，具有良好的扩展性。 综合考虑到目前venus已经支持druid且hikariCP并未发现有太多大规模的生产实践的案例，后续将推荐使用druid并把codegen生成的代码默认连接池为druid。 可开启prepareStatement缓存，对性能会有大概10%的提升。 功能对比 功能 dbcp druid c3p0 tomcat-jdbc HikariCP 是否支持PSCache 是 是 是 否 否 监控 jmx jmx/log/http jmx,log jmx jmx 扩展性 弱 好 弱 弱 弱 sql拦截及解析 无 支持 无 无 无 代码 简单 中等 复杂 简单 简单 更新时间 2015.8.6 2015.10.10 2015.12.09 2015.12.3 特点 依赖于common-pool 阿里开源，功能全面 历史久远，代码逻辑复杂，且不易维护 优化力度大，功能简单，起源于boneCP 连接池管理 LinkedBlockingDeque 数组 FairBlockingQueue threadlocal+CopyOnWriteArrayList 线程 1个线程(心跳) 2个线程 4个 3个 线程的作用 dbcp：一个线程：负责心跳，最小连接数维持，最大空闲时间和防连接泄露。 druid: 两个线程： 其中一个负责异步创建。一个负责最小连接数的维持。 其中心跳是通过获取连接，来判定是否小于心跳间隔。 hikariCP: 三个线程： 其中一个为定时线程，解决最大空闲时间。两个为新建连接和关闭连接。 均是连接池，空闲5s，线程便会关闭。 c3p0: 四个线程；三个helperThread （pollerThread）,一个定时AdminTaskTimer（DeadlockDetector）。由于boneCP被hikariCP替代，并且已经不再更新，boneCP没有进行调研。proxool网上有评测说在并发较高的情况下会出错，proxool便没有进行调研。druid的功能比较全面，且扩展性较好，比较方便对jdbc接口进行监控跟踪等。c3p0历史悠久，代码及其复杂，不利于维护。并且存在deadlock的潜在风险。 国内公司连接池使用情况 公司 数据库连接池 58同城 自己开发 滴滴 druid dbcp 知果果 druid 慧聪 druid dbcp 起步科技 dbcp 和 druid 亚信 hikariCP 唯品会 dbcp,druid,c3p0（默认） 性能测试环境配置: CPU Intel(R) Xeon(R) CPU E5-2430 v2 @ 2.50GHz，24core msyql version 5.5.46 tomcat-jdbc version 8.0.28 HikariCP version 2.4.3 c3p0 Version 0.9.5-pre8 dbcpVersion 2.0.1 druidVersion 1.0.5 获取关闭连接性能测试测试说明如下: 初始连接和最小连接均为5，最大连接为20。在borrow和return均不心跳检测 其中打开关闭次数为: 100w次 测试用例和mysql在同一台机器上面，尽量避免io的影响 使用mock和连接mysql在不同线程并发下的响应时间 mock性能数据 (单位:ms) 连接池 5ms 20ms 50ms 100ms tomcat-jdbc 442 447 1,013 1,264 c3p0 4,480 5,527 7,449 10,725 dbcp 676 689 867 1,292 hikari 38 33 38 30 druid 291 293 562 985 mysql性能数据 (单位:ms) 连接池 5ms 20ms 50ms 100ms tomcat-jdbc 436 453 1,033 1,291 c3p0 4,378 5,726 7,975 10,948 dbcp 671 679 897 1,380 hikari 96 82 87 78 druid 304 424 690 1,130 测试结果： mock和mysql连接性能表现差不多，主要是由于初始化的时候建立了连接后期不再建立连接，和使用mock连接逻辑一致。 性能表现：hikariCP&gt;druid&gt;tomcat-jdbc&gt;dbcp&gt;c3p0。 hikariCP 的性能及其优异。hikariCP号称java平台最快的数据库连接池。 hikariCP在并发较高的情况下，性能基本上没有下降。 c3p0连接池的性能很差，不建议使用该数据库连接池。 hikariCP性能分析： hikariCP通过优化(concurrentBag，fastStatementList )集合来提高并发的读写效率。 hikariCP使用threadlocal缓存连接及大量使用CAS的机制，最大限度的避免lock。单可能带来cpu使用率的上升。 从字节码的维度优化代码。 (default inline threshold for a JVM running the server Hotspot compiler is 35 bytecodes ）让方法尽量在35个字节码一下，来提升jvm的处理效率。 查询一条语句性能测试测试说明： 初始连接和最小连接均为8，最大连接为8。在borrow和return均不心跳检测 测试在不同并发下查询的次数为10w次的总耗时对比，操作步骤为 1：打开连接 2：执行 ：select 3. 关闭连接 测试用例和mysql在同一台机器上面，尽量避免io的影响 测试数据： 连接池 5ms 8ms 20ms 50ms 100ms tomcat-jdbc 2,178 1,495 1,769 1,818 1,858 c3p0 3,237 3,451 4,488 5,994 7,906 dbcp 2,816 1,935 2,097 2,243 2,280 hikari 2,299 1,546 1,682 1,751 1,772 druid 2,297 1,551 1,800 1,977 2,032 测试结果： 在并发比较少的情况下，每个连接池的响应时间差不多。是由于并发少，基本上没有资源竞争。 在并发较高的情况下，随着并发的升高，hikariCP响应时间基本上没有变动。 c3p0随着并发的提高，性能急剧下降。 pscache性能对比测试说明： 通过druid进行设置pscache和不设置pscache的性能对比 初始连接和最小连接均为8，最大连接为8。在borrow和return均不心跳检测。并且执行的并发数为8. 查询10w次。查询流程为：1：建立连接，2：循环查询preparestatement语句 3：close连接 测试用例和mysql在同一台机器上面，尽量避免io的影响 测试数据： cache 1,927 not cache 2,134 测试结果： 开启psCache缓存,性能大概有10%幅度的提升。可考虑开启pscache. 测试说明： psCache是connection私有的，所以不存在线程竞争的问题，开启pscache不会存在竞争的性能损耗。 psCache的key为prepare执行的sql和catalog等，value对应的为prepareStatement对象。开启缓存主要是减少了解析sql的开销。","link":"/mw/dcp-test/"},{"title":"《重新定义Spring Cloud实战》","text":"摘要: 今天是2018年9月24号中秋节，祝福大家中秋节快乐，本文主要介绍《重新定义Spring Cloud实战》。 1. 前言 随着互联网的快速普及，云计算近年来得到蓬勃发展，企业的IT环境和架构体系也逐渐发生变革，其中最典型的就是过去的单体应用架构发展为当今流行的微服务架构。微服务是一种架构风格，其优势是为软件应用开发带来很大的便利，让敏捷开发和复杂的企业应用快速持续交付成为可能。随着微服务架构的流行，很多企业纷纷使用微服务架构来搭建新的系统或者对历史系统进行重构，但是微服务架构的实施和落地会面临很大的挑战。虽然微服务架构的解决方案很多，但是对于如何真正落地微服务架构，目前还没有公认的技术标准和规范。幸运的是，业界已经有一些很有影响力的开源微服务解决方案，比如2015年年初，Spring团队推出的Spring Cloud，其目标是成为Java领域微服务架构落地的标准。Spring Cloud经过高速迭代和发展，至今已经成为Java领域落地微服务架构的推荐解决方案，为企业IT架构变革保驾护航。 Spring Cloud是一个优质的开源项目，它的稳健发展离不开众多开发人员的实践与反馈，开发人员通过一个社区化的平台去交流学习从而使Spring Cloud逐渐完善。Spring Cloud发展到2016年，得到国内越来越多的人的关注，但是相应的学习交流平台和材料比较分散，这阻碍了Spring Cloud在我国的普及和发展。因此Spring Cloud中国社区应运而生。Spring Cloud中国社区 (http://springcloud.cn) 是国内基于Spring Cloud微服务体系创建的非盈利技术社区，是专为Spring Boot或Spring Cloud技术人员提供分享和交流服务的平台，目的是推动Spring Cloud在中国的普及和应用。 2.背景概述 Spring Cloud中国社区(http://springcloud.cn) 是国内基于Spring Cloud微服务体系创建的非盈利技术社区。自2016年10月份创建以来，在北京，上海，深圳，成都等地举办了多次技术沙龙，提供技术交流平台,帮助数万开发者快速学习Spring Cloud并用于生产。为更好的推动Spring Cloud在中国的发展，让更多的开发者受益。社区针对Spring Cloud在国内的使用情况，结合国内企业使用Spring Cloud落地微服务架构遇到的问题给出实战解决方案，特推出此书。《重新定义Spring Cloud实战》封面如下图所示: 本书基于Spring Cloud的Finchley.RELEASE版编写，由7位作者著，共25章，共670页，我们7位作者并不是Spring Cloud微服务落地的架构专家，我们只是Spring Cloud微服务架构的实践者，把我们自己的实践经验分享给大家，帮助大家解决学习和工作上遇到的问题。三人行，必有我师焉，由于我们学识有限，难免会有不足之处，还请读者多多包涵，一起交流学习，共同进步。 3.本书介绍3.1 填坑记录 3.2 BATJ部分书评过去十几年里，广义的“微服务”架构以其小团队快速创建和迭代服务带来的架构弹性、扩展性、敏捷性，天然匹配了互联网业务快速发展和变化的特点，在各大互联网公司取得了巨大的成功。时至云原生应用时代，已不再是是否采用微服务架构的问题，而是何时采用以及如何在生产上实战的问题。本书将如何基于Spring Cloud生态体系进行微服务实战的方方面面的细节都涵盖了，，从这个意义上来讲，确实做到了“重新定义”。 —— 坤宇 Nacos开源项目创始人/阿里巴巴高级技术专家 微服务以敏捷为目标，以降低复杂的系统结构为基础，带给我们更好的系统可用性和稳定性。Spring Cloud作为一套完善的微服务治理的典型框架，涵盖了微服务治理的方方面面。本书详细介绍了Spring Cloud的每一个核心模块，以理论与实际相结合的方式，透彻地讲述了Spring Cloud的精髓，是每一位奋战在服务化领域一线的工程师、架构师的*选技术书籍。 ——李艳鹏 蚂蚁金服高级技术专家/《分布式服务架构》《可伸缩服务架构》作者 本书可以说是后端架构师的进阶宝典，全面地讲解了如何打造一套强大、健壮的微服务体系，深入分析了涉及到的各个组件。*难得的是，书中结合了作者多年积累的架构经验，分析了各种组件适用的场景，平实地说明了实际使用中的各种考量和细节优化，简直是奋斗在一线的工程师的心血结晶。任何想掌握大型后端架构的工程师，无论使用什么技术框架，都能从本书获益匪浅。 ——李双涛 饿了么中间件资深架构师 Spring Cloud已然成为Java领域应用微服务化的*选框架，但国内一直缺少全面论述Spring Cloud商用实践相关的书籍。本书围绕Spring Cloud框架中的服务注册发现、服务路由、服务网关、分布式配置、服务治理、容器化及微服务设计等关键领域进行了深入浅出的讲解，并给予了大量的真实应用案例，新手和老手都可以从中受益良多。作者作为Spring Cloud中国的资深专家，对于Spring Cloud及微服务有着深刻的架构和实战经验，值得信赖。 ——单家骏 腾讯中间件高级工程师 在微服务体系中，Spring Cloud是目前最热门的构建微服务体系的解决方案，它提供了构建微服务架构的一些基础设施。本书内容上覆盖了Spring Cloud的一些主要组件，不仅在如何使用上做了详细的介绍，也从原理上深入浅出地剖析了其中的技术要点，同时部分组件也跟周边的一些开源项目进行了对比，且提供了一些原理分析和相关的示例，是一本不可多得的Spring Cloud实战书籍。新手和有微服务实践经验的读者都能从书中得到一些不一样的收获。 ——张艺辰 腾讯高级研发工程师 本书不仅对Spring Cloud各核心组件进行了细致入微的介绍，同时也跳出了框架本身，为微服务的实施和分布式架构所面临的基本问题交出了Spring Cloud式答卷，是开发者快速掌握Spring Cloud技术栈的神兵利器。不仅如此，本书还凝聚着Spring Cloud中国社区的智慧结晶，让我们看到了国人在开源领域的研发力量， 可喜可贺。 ——王鸿飞 百度高级研发工程师 在微服务如火如荼的今天，各种微服务框架层出不穷，而Spring Cloud无疑是那颗最闪亮的星。从Spring Framework到Spring Boot，再到如今的Spring Cloud，Spring全家桶给众多程序员带来了真正的春天。由于分布式和服务化是极具挑战的任务，因此Spring Cloud也不可避免的愈加复杂。Spring CLoud中国社区为Spring Cloud的普及做出了巨大的贡献，并迅速的降低了语言问题所带来的学习门槛。这本书由Spring CLoud中国社区倾力打造，书籍涵盖了Spring Cloud的服务发现、网关、熔断器、配置、全链路监控等最核心组件，并很接地气地详述了Dubbo向Spring Cloud迁移以及Spring Cloud与分布式事务相关内容，值得一看。——张亮 京东金融数据研发负责人/分布式数据库中间件Sharding-Sphere负责人 Spring Cloud提供了完整的微服务技术体系，可以帮助开发者快速地实现架构升级。《重新定义Spring Cloud实战》一书完整地介绍了Spring Cloud中各个组件的使用方法并深度剖析了其中的原理，文章深入浅出帮助开发者快速掌握和理解Spring Cloud。——李艺恒 腾讯研发工程师 3.3 读者反馈https://github.com/SpringCloud/spring-cloud-code/issues/1 3.4 源码相关书籍目录：https://github.com/SpringCloud/spring-cloud-catalog 源码地址:https://github.com/SpringCloud/spring-cloud-code 3.5 内容简介这是一本实践与理论并重、广度与深度兼顾的Spring Cloud生产实践开发指南，由Spring Cloud中国社区倾力打造，作者来自阿里、蚂蚁金服、京东金融等企业，本书针对Spring Cloud在国内的使用情况，结合国内企业使用Spring Cloud落地微服务架构遇到的问题，提出可落地的解决方案。 本书内容有3大特色： 足够广：详细讲解了Spring Cloud的核心常用组件以及Spring Cloud的增强生态，针对生产实践中常见问题给出可落地的最佳实践方案，无论您是初学者还是开发人员，还是架构师，都能从此书获益。 有深度：本书对涉及的Spring Cloud组件按照从入门、进阶、实战、扩展增强的顺序循序渐进进行剖析和讲解,帮助作者知其然并知其所以然，授之以渔。 重实践：注重生产实践，通过案例驱动，给出优秀的生产实践方案和优秀的生产配置，帮助读者快速落地企业微服务架构。 全书共25章，分为三个部分： 第一部分 核心组件篇（第1~10章）主要讲解Spring Cloud的核心组件。首先从应用架构的发展历程讲起，介绍了微服务出现的背景，并对微服务架构的落地提出了相应的解决方案；然后分别详细介绍了Spring Cloud微服务体系中的核心常用组件，如Eureka、Feign、Ribbon、Hystrix、Zuul等；最后通过一个综合案例将前面介绍的组件连接起来，帮助大家融会贯通。 第二部分 进阶实战篇（第11~18章）在核心组件的基础上，对Config、Consul、认证和鉴权、全链路监控以及对Spring Cloud生态圈中第二代网关Spring Cloud Gateway进行了详细阐述，循序渐进、案例驱动，帮助读者加深对组件的理解和运用，更好地掌握相关内容运用于生产实践。 第三部分 解决方案篇（第19~25章） 主要从解决方案着手，内容包括Spring Cloud与gRPC的整合方式、版本控制与灰度发布、Spring Cloud容器化、Dubbo向Spring Cloud的迁移、分布式事务、领域驱动等生产级实用解决方案，为企业IT架构微服务化和变革保驾护航。 3.6 推荐理由 本书由Spring Cloud社区官方撰写，核心成员来自原阿里、蚂蚁金服、京东金融等互联网企业，经验丰富。 本书内容有3大特色：宽度足够广、深度足够深，而且立足于生产实践，直接从生产实践出发，包含大量生产实践的配置 本书得到了来自阿里、腾讯、百度、京东等大型互联网企业的近10位专家的鼎力推荐。 3.7 作者介绍 许进:Spring Cloud中国社区创始人，阿里原资深工程师，花名玹霖，专注于基础架构与中间件研发，曾就职于唯品会平台架构部和饿了么。个人网站：http://xujin.org。 钟尊发:Spring Cloud中国社区联合创始人，现就职于京东金融，对微服务有深入研究。 叶志远:Spring Cloud中国社区联合创始人，现就职于蚂蚁金服，花名梓尧。CSDN博客专家，开源社区活跃者，国内Spring Cloud早期实践者 方志朋:Spring Cloud中国社区联合创始人，硕士学历，《深入理解Spring Cloud与微服务构建》作者，CSDN博客专家（阅读量600万+），在社区具有较高活跃度与影响力。 蔡波斯:拥有多年Java开发经验，曾就职于美团、腾讯。国内Spring Cloud领域的早期实践者，现在金融行业从事FinTech相关研发 郭芳碧:多年微服务实践经验，现任职于某互联网金融公司中间件部门。 朱德明:拥有10年Java开发经验，多年技术架构和解决方案经验，现任灵雀云微服务架构师，在微服务领域有着丰富的落地经验，曾任某创业公司技术负责人。","link":"/re/01/"},{"title":"在Spring Cloud中实现降级之权重路由和标签路由","text":"前言 限流、降级、灰度是服务治理的一个很重要的功能。本文参考Spring Cloud中国社区的VIP会员-何鹰的博客-整理Dubbo自带服务降级、限流功能，spring cloud并没有提供此功能，只能由我们自行实现。这里的限流、降级、灰度都是针对服务实例级别，并不是整个服务级别，整个服务级别可以通过实例部署数量来实现。 限流降级设计场景服务A，部署了3个实例A1、A2、A3。spring cloud默认客户端负载均衡策略是采用轮询方式，A1、A2、A3三个实例流量均分，各1/3。如果这个时候需要将服务A由1.0版升级至2.0版，我们需要做的步骤是：将A1的流量降为0，柔性下线，关闭A1实例并升级到2.0，将A1流量提升为10%观察2.0线上运行情况，如果情况稳定，则逐步开放流量至不限制及1/3。依次在A2，A3上执行上述操作。在上述步骤中，我们想让特别的人使用2.0，其他人还是使用1.0版，稳定后再全员开放。 思路分析，服务A的流量产生有两个方面，一个是外部流量，外网通过zuul过来的流量，一个是内部流量，服务间调用，服务B调用服务A的这类流量。不管是zuul还是内部服务来的，都是要通过ribbon做客户端负载均衡，我们可以修改ribbon负载均衡策略来实现上述限流、降级、灰度功能。 要实现这些想法，我们需要对spring-cloud的各个组件、数据流非常熟悉，这样才能知道该在哪里做扩展。一个典型的调用：外网-》Zuul网关-》服务A-》服务B。。。 spring-cloud跟dubbo一样都是客户端负载均衡，所有调用均由Ribbon来做负载均衡选择服务器，所有调用前后会套一层hystrix做隔离、熔断。服务间调用均用带LoadBalanced注解的RestTemplate发出。RestTemplate-》Ribbon-》hystrix 通过上述分析我们可以看到，我们的扩展点就在Ribbon，Ribbon根据我们的规则，选择正确的服务器即可。 我们先来一个dubbo自带的功能：基于权重的流量控制。dubbo自带的控制台可以设置服务实例粒度的半权，倍权。其实就是在客户端负载均衡时，选择服务器带上权重即可，spring-cloud默认是ZoneAvoidanceRule，优先选择相同Zone下的实例，实例间采用轮询方式做负载均衡。我们的想把基于轮询改为基于权重即可。接下来的问题是，每个实例的权重信息保存在哪里？从哪里取？dubbo放在zookeeper中，spring-cloud放在eureka中。我们只需从eureka拿每个实例的权重信息，然后根据权重来选择服务器即可。具体代码LabelAndWeightMetadataRule（先忽略里面的优先匹配label相关代码）。 工程案例演示 https://github.com/SoftwareKing/spring-cloud-study/tree/master/sc-ribbon-demoted 项目结构 config 配置中心端口：8888，方便起见直接读取配置文件，生产环境可以读取git。application-dev.properties为全局配置。先启动配置中心，所有服务的配置（包括注册中心的地址）均从配置中心读取。 consumer 服务消费者端口：18090，调用服务提供者，为了演示header传递。 core 框架核心包核心jar包，所有微服务均引用该包，使用AutoConfig实现免配置，模拟生产环境下spring-cloud的使用。 eureka 注册中心端口：8761，/metadata端点实现metadata信息配置。 provider 服务提供者端口：18090，服务提供者，无特殊逻辑。 zuul 网关端口：8080，演示解析token获得label并放入header往后传递 案例具体实现基于权重的实现思路LabelAndWeightMetadataRule写好了，那么我们如何使用它，使之生效呢？有3种方式。 1）写个AutoConfig将LabelAndWeightMetadataRule声明成@Bean，用来替换默认的ZoneAvoidanceRule。这种方式在技术验证、开发测试阶段使用短平快。但是这种方式是强制全局设置，无法个性化。 2）由于spring-cloud的Ribbon并没有实现netflix Ribbon的所有配置项。netflix配置全局rule方式为：ribbon.NFLoadBalancerRuleClassName=package.YourRule，spring-cloud并不支持，spring-cloud直接到服务粒度，只支持SERVICE_ID.ribbon.NFLoadBalancerRuleClassName=package.YourRule。 我们可以扩展org.springframework.cloud.netflix.ribbon.PropertiesFactory修正spring cloud ribbon未能完全支持netflix ribbon配置的问题。这样我们可以将全局配置写到配置中心的application-dev.properties全局配置中，然后各个微服务还可以根据自身情况做个性化定制。但是PropertiesFactory属性均为私有，应该是spring cloud不建议在此扩展。参见https://github.com/spring-cloud/spring-cloud-netflix/issues/1741。 3）使用spring cloud官方建议的@RibbonClient方式。该方式仅存在于spring-cloud单元测试中（在我提问后，现在还存在于spring-cloud issue list）。具体代码参见DefaultRibbonConfiguration.java、CoreAutoConfiguration.java。 目前采用第三种方式处理 基于权重的路由测试依次开启 config eureka provide（开两个实例，通过启动参数server.port指定不同端口区分） consumer zuul访问 http://localhost:8761/metadata.html 这是我手写的一个简单的metadata管理界面，分别设置两个provider实例的weight值（设置完需要一段2分钟才能生效），然后访问 http://localhost:8080/provider/user 多刷几次来测试zuul是否按权重发送请求，也可以访问 http://localhost:8080/consumer/test 多刷几次来测试consumer是否按权重来调用provide服务。 基于标签的路由处理基于权重的搞定之后，接下来才是重头戏：基于标签的路由。入口请求含有各种标签，然后我们可以根据标签幻化出各种各样的路由规则。例如只有标注为粉丝的用户才使用新版本（灰度、AB、金丝雀），例如标注为中国的用户请求必须发送到中国的服务器（全球部署），例如标注为写的请求必须发送到专门的写服务实例（读写分离），等等等等，唯一限制你的就是你的想象力。 基于标签的路由实现思路根据标签的控制，我们当然放到之前写的Ribbon的rule中，每个实例配置的不同规则也是跟之前一样放到注册中心的metadata中。需要解决以下几个问题: Q:关键是标签数据如何传过来? A:权重随机的实现思路里面有答案，请求都通过zuul进来，因此我们可以在zuul里面给请求打标签，基于用户，IP或其他看你的需求，然后将标签信息放入ThreadLocal中，然后在Ribbon Rule中从ThreadLocal拿出来使用就可以了。 然而，按照这个方式去实验时，发现有问题，拿不到ThreadLocal。原因是有hystrix这个东西，回忆下hystrix的原理，为了做到故障隔离，hystrix启用了自己的线程，不在同一个线程ThreadLocal失效。 那么还有什么办法能够将标签信息一传到底呢，想想之前有没有人实现过类似的东西，没错sleuth，它的链路跟踪就能够将span传递下去，翻翻sleuth源码，找找其他资料，发现可以使用HystrixRequestVariableDefault，这里不建议直接使用HystrixConcurrencyStrategy，会和sleuth的strategy冲突。代码参见CoreHeaderInterceptor.java。现在可以测试zuul里面的rule，看能否拿到标签内容了。 标签传到HystrixRequestVariableDefault这里的，如果项目中没有使用Hystrix就用不了了,这个时候需要做一个判断在restTemple里面做个判断，没有hystrix就直接threadlocal取。 Q:这里还不是终点，解决了zuul的路由，服务A调服务B这里的路由怎么处理呢？zuul算出来的标签如何往后面依次传递下去呢? 我们还是抄sleuth：把标签放入header，服务A调服务B时，将服务A header里面的标签放到服务B的header里，依次传递下去。这里的关键点就是：内部的微服务在接收到发来的请求时(zuul-&gt;A，A-&gt;B）我们将请求放入ThreadLocal，哦，不对，是HystrixRequestVariableDefault，还记得上面说的原因么：）。 这个容易处理，写一个spring mvc拦截器即可，代码参见CoreHeaderInterceptor。然后发送请求时自动带上这个里面保存的标签信息，参见RestTemplate的拦截器CoreHttpRequestInterceptor。到此为止，技术上全部走通实现。 总结一下：zuul依据用户或IP等计算标签，并将标签放入header里向后传递，后续的微服务通过拦截器，将header里的标签放入RestTemplate请求的header里继续向后接力传递。标签的内容通过放入类似于ThreadLocal的全局变量（HystrixRequestVariableDefault），使Ribbon Rule可以使用。 基于标签路由的测试参见PreFilter源码，模拟了几个用户的标签，参见LabelAndWeightMetadataRule源码，模拟了OR AND两种标签处理策略。依次开启 config eureka provide（开两个实例，通过启动参数server.port指定不同端口区分） consumer zuul. 访问 http://localhost:8761/metadata.html 设置第一个provide 实例 orLabel为 CN,Test 发送请求头带入Authorization: emt 访问http://localhost:8080/provider/user 多刷几次，可以看到zuul所有请求均路由给了第一个实例。访问http://localhost:8080/consumer/test 多刷几次，可以看到，consumer调用均路由给了第一个实例。 设置第二个provide 实例 andLabel为 EN,Male 发送请求头带入Authorization: em 访问http://localhost:8080/provider/user 多刷几次，可以看到zuul所有请求均路由给了第二个实例。访问http://localhost:8080/consumer/test 多刷几次，可以看到，consumer调用均路由给了第二个实例。 Authorization头还可以设置为PreFilter里面的模拟token来做测试，至此所有内容讲解完毕，技术路线拉通，剩下的就是根据需求来完善你自己的路由策略啦。 伪代码分析实现流程伪代码示例Ribbon默认采用ZoneAvoidanceRule，优先选择同zone下的实例。我们继承这个rule并扩展我们自己的限流功能，仔细阅读ZoneAvoidanceRule及其父类源码。 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class WeightedMetadataRule extends ZoneAvoidanceRule {public static final String META_DATA_KEY_WEIGHT = \"weight\";@Overridepublic Server choose(Object key) { List&lt;Server&gt; serverList = this.getPredicate().getEligibleServers(this.getLoadBalancer().getAllServers(), key); if (CollectionUtils.isEmpty(serverList)) { return null; } // 计算总值并剔除0权重节点 int sum = 0; Map&lt;Server, Integer&gt; serverWeightMap = new HashMap&lt;&gt;(); for (Server server : serverList) { String strWeight = ((DiscoveryEnabledServer) server).getInstanceInfo().getMetadata().get(META_DATA_KEY_WEIGHT); int weight = 100; try { weight = Integer.parseInt(strWeight); } catch (Exception e) { // 无需处理 } if (weight &lt;= 0) { continue; } serverWeightMap.put(server, weight); sum += weight; } // 权重随机 int random = (int) (Math.random() * sum); int current = 0; for (Map.Entry&lt;Server, Integer&gt; entry : serverWeightMap.entrySet()) { current += entry.getValue(); if (random &lt; current) { return entry.getKey(); } } return null;}} 使上述代码生效，在zuul网关中加入 1234@Beanpublic IRule weightedMetadataRule(){ return new WeightedMetadataRule();} 代码示例测试打断点测试是否进入WeightedMetadataRule，开启多个服务A实例，通过zuul访问服务A。成功进入断点，代码生效后，我们再来看如何指定metadata。访问eureka restful API （我的eureka服务器端口为8100，修改为你自己的eureka端口）Get http://localhost:8100/eureka/apps这个api可以看到所有服务Get http://localhost:8100/eureka/apps/YOUR_SERVICE_NAME这个api可以看到你的服务信息，包括部署了哪些实例Get http://localhost:8100/eureka/apps/YOUR_SERVICE_NAME/INSTANCE_ID这个api可以看到服务实例的信息，注意其中的metadata节点，目前为emptyPut http://localhost:8100/eureka/apps/YOUR_SERVICE_NAME/INSTANCE_ID/metadata?weight=10通过put方式可以修改metadata的内容，放入weight，设为10 然后稍等两分钟，让zuul更新注册中心中的信息，接着重新访问，调试就可以看到metadata的内容了，并且也是按照权重随机来进行流量限制的，至此hello world搞定。 生产上使用WeightedMetadataRule接下来，在生产环境中，我们如何应用这个WeightedMetadataRule呢，有如下几种方式： 手动指定服务策略，spring cloud ribbon并没有完整实现netflix ribbon的所有配置功能，负载策略默认只能配置微服务级别，无法配置全局默认值。例如：只能配置 SOME_SERVICE_ID.ribbon.NFLoadBalancerRuleClassName=package.WeightedMetadataRule而不支持配置全局默认值 ribbon.NFLoadBalancerRuleClassName=package.WeightedMetadataRule这种方案明显不符合我们的要求。 通过声明Irule spring bean配置全局负载策略1234@Beanpublic IRule weightedMetadataRule(){ return new WeightedMetadataRule();} 这种方式也就是我们上面用的hello world方式，配置后强制所有微服务使用该策略，没有例外，微服务无法个性化定制策略，符合目前需求，但不适于长期规划。 继承重写PropertiesFactory继承重写org.springframework.cloud.netflix.ribbon.PropertiesFactory类，修正spring cloud ribbon未能完全支持netflix ribbon的问题。但是PropertiesFactory属性均为私有，应该是spring cloud不建议在此扩展。参见https://github.com/spring-cloud/spring-cloud-netflix/issues/1741 使用spring cloud官方建议的@RibbonClient方式1234567891011121314151617181920212223242526272829@Configuration@RibbonClients(defaultConfiguration = DefaultRibbonConfiguration.class)public class DefaultRibbonConfiguration { @Value(\"${ribbon.client.name:#{null}}\") private String name; @Autowired(required = false) private IClientConfig config; @Autowired private PropertiesFactory propertiesFactory; @Bean public IRule ribbonRule() { if (StringUtils.isEmpty(name)) { return null; } if (this.propertiesFactory.isSet(IRule.class, name)) { return this.propertiesFactory.get(IRule.class, config, name); } // 默认配置 WeightedMetadataRule rule = new WeightedMetadataRule(); rule.initWithNiwsConfig(config); return rule; }} 总结关于权重随机的性能，上述代码用的数组分段查找法，还可以采用TreeMap二分查找法。可以将权重数组或权重TreeMap缓存起来。根据测试，在实例数量为50个时 缓存权重数组和权重TreeMap，数组分段查找百万次耗时78-125ms，TreeMap二分耗时50-80ms。 这篇文章只是把技术打通，至于如何根据服务器负载情况，自动降级，限流等需求，只需要监控服务器状况，调用eureka接口设置metadata即可（其实我个人建议这方面需求通过docker的自动扩容缩容完成，只是有朋友问到如何通过spring cloud实现）。 下一篇会写基于标签的流量控制。如何控制部分用户使用服务A2.0，其他用户使用服务A1.0。 参考文章江南白衣-服务化之－路由SpringCloud Ribbon 降级、限流、灰度发布","link":"/sc/sc-ribbon-demoted/"},{"title":"微服务网关解决方案调研和使用总结","text":"一.什么是网关1.1 什么是网关API Gateway（APIGW / API 网关），顾名思义，是出现在系统边界上的一个面向API的、串行集中式的强管控服务，这里的边界是企业IT系统的边界，可以理解为企业级应用防火墙，主要起到隔离外部访问与内部系统的作用。在微服务概念的流行之前，API网关就已经诞生了，例如银行、证券等领域常见的前置机系统，它也是解决访问认证、报文转换、访问统计等问题的。 API网关的流行，源于近几年来，移动应用与企业间互联需求的兴起。移动应用、企业互联，使得后台服务支持的对象，从以前单一的Web应用，扩展到多种使用场景，且每种使用场景对后台服务的要求都不尽相同。这不仅增加了后台服务的响应量，还增加了后台服务的复杂性。随着微服务架构概念的提出，API网关成为了微服务架构的一个标配组件。 1.2 网关应该具有的功能 如上图所示：网关该具备的最基本的四大功能:统一接入，流量管控，协议适配转发，安全防护。 二.目前网关解决方案2.1 Nginx+ Lua Nginx是由IgorSysoev为俄罗斯访问量第二的Rambler.ru站点开发的，一个高性能的HTTP和反向代理服务器。Ngnix一方面可以做反向代理，另外一方面做可以做静态资源服务器。 但是准确的来说，在我看来，这种方案不是真正意义上的网关，而且即使自研网关的目标也是干掉Ngnix。 2.2 Kong Kong是Mashape提供的一款API管理软件，它本身是基于Ngnix+lua的，但比nginx提供了更简单的配置方式，数据采用了 ApacheCassandra/PostgreSQL存储，并且提供了一些优秀的插件，比如验证，日志，调用频次限制等。 Kong的一个非常诱人的地方就是提供了大量的插件来扩展应用，通过设置不同的插件可以为服务提供各种增强的功能。Kong默认插件插件包括： 身份认证：Kong提供了Basic Authentication、Key authentication、OAuth2.0authentication、HMAC authentication、JWT、LDAP authentication认证实现。 安全：ACL（访问控制）、CORS（跨域资源共享）、动态SSL、IP限制、爬虫检测实现。 流量控制：请求限流（基于请求计数限流）、上游响应限流（根据upstream响应计数限流）、请求大小限制。限流支持本地、Redis和集群限流模式。 分析监控：Galileo（记录请求和响应数据，实现API分析）、Datadog（记录API Metric如请求次数、请求大小、响应状态和延迟，可视化API Metric）、Runscope（记录请求和响应数据，实现API性能测试和监控）。 转换：请求转换、响应转换 优点:Kong本身也是基于Nginx的，所以在性能和稳定性上都没有问题。Kong作为一款商业软件，在Nginx上做了很扩展工作，而且还有很多付费的商业插件。Kong本身也有付费的企业版，其中包括技术支持、使用培训服务以及API 分析插件。 缺点:Kong的缺点就是，如果你使用Spring Cloud，Kong如何结合目前已有的服务治理体系？ 2.3 Spring Cloud ZuulZuul 是Netflix公司开源的一个API网关组件，Spring Cloud对其进行二次基于Spring Boot的注解式封装做到开箱即用。目前来说，结合Sring Cloud提供的服务治理体系，可以做到请求转发，根据配置的或者默认的路由规则进行路由和Load Balance，集成Hystrix。详细可以参考Spring Cloud Zuul的URL转发和路由规则。 Spring Cloud Zuul处理每个请求的方式是针对每个请求是用一个线程来处理。PS，根据统计数据目前Zuul最多能达到（1000-2000)QPS。使用过Netty的都知道，一般都会使用Boos组和work组，通常情况下，为了提高性能，所有请求会被放到处理队列中，从线程池中选取空闲线程来处理该请求。 Spring Cloud Zuul需要做一些灰度，降级，标签路由，限流，WAF封禁，需要自定义Filter去或者做一些定制化实现。详细文章可以参考在Spring Cloud中实现降级之权重路由和标签路由 虽然可以通过自定义Filter实现，我们想要的功能，但是由于Zuul本身的设计和基于单线程的接收请求和转发处理，在我看来目前来看Zuul 就显得很鸡肋，随着Zuul2一直跳票，Spring Cloud推出自己的Spring Cloud Gateway. The API Gateway is Dead! Long Live the API Gateway! 大意:Zuul已死，Spring Cloud Gateway永生。 2.4 Spring Cloud GatewayA Gateway built on Spring Framework 5.0 and Spring Boot 2.0 providing routing and more。 Spring Cloud Gateway是基于Spring 框架5.0版本和Spring Boot 2.0的版本构建，提供路由等功能。 Spring Cloud GateWay具有以下特征 Java 8/Spring 5/Boot 2 WebFlux/Reactor HTTP/2 and Websockets Finchley Release Train (Q4 2017) 由于Spring 5.0支持Netty，Http2，而Spring Boot 2.0支持Spring 5.0，因此Spring Cloud Gateway支持Netty和Http2顺理成章。至于2017年Q4季度是否发布完整的Spring Cloud Gateway我们拭目以待，但是至于最终落地看最终使用情况。 详细信息可以参考：Spring Cloud Gateway离开孵化器的变化 2.5 Kong+Zuul的网关方案 如上图所示:Kong+Zuul实现的网关方案，在加上阿里云的SLB，整个调用链路多了好几层，为什么要这么做呢？发挥Kong+Spring Cloud Zuul各自的优点形成“聚合网关”。个人不建议这样使用网关，因此自研网关中间件，显得尤其重要。 三.基于Spring Cloud Zuul构建网关用Spring Cloud Zuul构建网关其实相当鸡肋，比如动态Filter，比如标签路由，降级，比如动态Filter，比如带管控审计流程，易操作的UI界面等。 zuul是netfix的api 网关，主要特色有：filter的PRPE(pre,route,post,error)模型、groovy的fitler机制，其中spring cloud对其有比较好的扩展，但是spring cloud对其的扩展感觉不是很完美，存在路由规则无法只能是通过配置文件来存储，而无法动态配置的目的，其中有一个人写了一个starter插件来解决路由规则配置到Cassandra的问题，详细请看：将路由规则配置到KV分布式存储系统Cassandra 3.1 定义自己的Filter机制这里主要是做了流控及协议转化的工作，这里主要是http-&gt;grpc的转换；LimitAccessFilter：利用redis令牌桶算法进行流控GrpcRemoteRouteFilter：http转化为grpc的协议转换 3.2 路由数据变更基于事件通知路由规则刷新实现动态路由有两种实现方式:1.第一是DiscoveryClientRouteLocator的重新覆盖,推荐是，Spring Cloud整合GRPC，REST协议适配转发为内部GRPC服务时采用此种方法扩展修改。 2.第二是实现了RefreshableRouteLocator接口，能够实现动态刷新，可以参考 spring cloud Zuul动态路由 3.2.1 基于事件更新源码分析 为什么要基于事件更新，原理如下所示：在org.springframework.cloud.netflix.zuul.ZuulConfiguration.java中228-250行 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136 @Configuration@EnableConfigurationProperties({ ZuulProperties.class })@ConditionalOnClass(ZuulServlet.class)// Make sure to get the ServerProperties from the same place as a normal web app would@Import(ServerPropertiesAutoConfiguration.class)public class ZuulConfiguration { //zuul的配置信息,对应了application.properties或yml中的配置信息 @Autowired protected ZuulProperties zuulProperties; @Autowired protected ServerProperties server; @Autowired(required = false) private ErrorController errorController; @Bean public HasFeatures zuulFeature() { return HasFeatures.namedFeature(\"Zuul (Simple)\", ZuulConfiguration.class); } @Bean @ConditionalOnMissingBean(RouteLocator.class) public RouteLocator routeLocator() { //默认配置的实现是SimpleRouteLocator.class return new SimpleRouteLocator(this.server.getServletPrefix(), this.zuulProperties); } @Bean public ZuulController zuulController() { return new ZuulController(); } @Bean public ZuulHandlerMapping zuulHandlerMapping(RouteLocator routes) { ZuulHandlerMapping mapping = new ZuulHandlerMapping(routes, zuulController()); mapping.setErrorController(this.errorController); return mapping; } //注册了一个路由刷新监听器，默认实现是ZuulRefreshListener.class @Bean public ApplicationListener&lt;ApplicationEvent&gt; zuulRefreshRoutesListener() { return new ZuulRefreshListener(); } @Bean @ConditionalOnMissingBean(name = \"zuulServlet\") public ServletRegistrationBean zuulServlet() { ServletRegistrationBean servlet = new ServletRegistrationBean(new ZuulServlet(), this.zuulProperties.getServletPattern()); // The whole point of exposing this servlet is to provide a route that doesn't // buffer requests. servlet.addInitParameter(\"buffer-requests\", \"false\"); return servlet; } // pre filters @Bean public ServletDetectionFilter servletDetectionFilter() { return new ServletDetectionFilter(); } @Bean public FormBodyWrapperFilter formBodyWrapperFilter() { return new FormBodyWrapperFilter(); } @Bean public DebugFilter debugFilter() { return new DebugFilter(); } @Bean public Servlet30WrapperFilter servlet30WrapperFilter() { return new Servlet30WrapperFilter(); } // post filters @Bean public SendResponseFilter sendResponseFilter() { return new SendResponseFilter(); } @Bean public SendErrorFilter sendErrorFilter() { return new SendErrorFilter(); } @Bean public SendForwardFilter sendForwardFilter() { return new SendForwardFilter(); } @Configuration protected static class ZuulFilterConfiguration { @Autowired private Map&lt;String, ZuulFilter&gt; filters; @Bean public ZuulFilterInitializer zuulFilterInitializer() { return new ZuulFilterInitializer(this.filters); } } private static class ZuulRefreshListener implements ApplicationListener&lt;ApplicationEvent&gt; { @Autowired private ZuulHandlerMapping zuulHandlerMapping; private HeartbeatMonitor heartbeatMonitor = new HeartbeatMonitor(); @Override public void onApplicationEvent(ApplicationEvent event) { if (event instanceof ContextRefreshedEvent || event instanceof RefreshScopeRefreshedEvent || event instanceof RoutesRefreshedEvent) { this.zuulHandlerMapping.setDirty(true); } else if (event instanceof HeartbeatEvent) { if (this.heartbeatMonitor.update(((HeartbeatEvent) event).getValue())) { this.zuulHandlerMapping.setDirty(true); } } } }} 如上所示,当使用ApplicationEventPublisher发送的Event为ContextRefreshedEvent，RefreshScopeRefreshedEvent，RoutesRefreshedEvent才会通知Zuul去刷新路由。 3.3 基于事件更新实现方式处理方式-DiscoveryClientRouteLocator3.3.1 处理思路此插件针对的spring cloud zuul版本比较老，因此需要对其进行改进，将路由配置可以配置到mysql这样的关系型数据库中，详细请看Zuul的改动点。 3.3.2 对DiscoveryClientRouteLocator的重新覆盖 对DiscoveryClientRouteLocator的重新覆盖，该类的作用就是从yml或属性文件中读取路由规则； 具体参看源码org.springframework.cloud.netflix.zuul.filters.discovery.DiscoveryClientRouteLocator，主要方法如下，浅显易懂，就不做多余解释。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263@Override protected LinkedHashMap&lt;String, ZuulRoute&gt; locateRoutes() { LinkedHashMap&lt;String, ZuulRoute&gt; routesMap = new LinkedHashMap&lt;String, ZuulRoute&gt;(); routesMap.putAll(super.locateRoutes()); if (this.discovery != null) { Map&lt;String, ZuulRoute&gt; staticServices = new LinkedHashMap&lt;String, ZuulRoute&gt;(); for (ZuulRoute route : routesMap.values()) { String serviceId = route.getServiceId(); if (serviceId == null) { serviceId = route.getId(); } if (serviceId != null) { staticServices.put(serviceId, route); } } // Add routes for discovery services by default List&lt;String&gt; services = this.discovery.getServices(); String[] ignored = this.properties.getIgnoredServices() .toArray(new String[0]); for (String serviceId : services) { // Ignore specifically ignored services and those that were manually // configured String key = \"/\" + mapRouteToService(serviceId) + \"/**\"; if (staticServices.containsKey(serviceId) &amp;&amp; staticServices.get(serviceId).getUrl() == null) { // Explicitly configured with no URL, cannot be ignored // all static routes are already in routesMap // Update location using serviceId if location is null ZuulRoute staticRoute = staticServices.get(serviceId); if (!StringUtils.hasText(staticRoute.getLocation())) { staticRoute.setLocation(serviceId); } } if (!PatternMatchUtils.simpleMatch(ignored, serviceId) &amp;&amp; !routesMap.containsKey(key)) { // Not ignored routesMap.put(key, new ZuulRoute(key, serviceId)); } } } if (routesMap.get(DEFAULT_ROUTE) != null) { ZuulRoute defaultRoute = routesMap.get(DEFAULT_ROUTE); // Move the defaultServiceId to the end routesMap.remove(DEFAULT_ROUTE); routesMap.put(DEFAULT_ROUTE, defaultRoute); } LinkedHashMap&lt;String, ZuulRoute&gt; values = new LinkedHashMap&lt;&gt;(); for (Entry&lt;String, ZuulRoute&gt; entry : routesMap.entrySet()) { String path = entry.getKey(); // Prepend with slash if not already present. if (!path.startsWith(\"/\")) { path = \"/\" + path; } if (StringUtils.hasText(this.properties.getPrefix())) { path = this.properties.getPrefix() + path; if (!path.startsWith(\"/\")) { path = \"/\" + path; } } values.put(path, entry.getValue()); } return values; } 3.3.3 生产者产生事件通知数据变更对网关的稳定性来说，也是一个很大的挑战。当对路由信息进行CRUD操作之后，需要Spring Cloud Zuul重新刷新路由规则，实现方式通过spring的event来实现。 1.实现基于ApplicationEventPublisherAware的事件生产者的代码片段12private ApplicationEventPublisher publisher;publisher.publishEvent(new InstanceRegisteredEvent&lt;&gt;(this, this.environment)); 2.Spring Cloud netflix内部的事件消费者 org.springframework.cloud.netflix.zuul.RoutesRefreshedEvent 123456789101112131415@SuppressWarnings(\"serial\")public class RoutesRefreshedEvent extends ApplicationEvent { private RouteLocator locator; public RoutesRefreshedEvent(RouteLocator locator) { super(locator); this.locator = locator; } public RouteLocator getLocator() { return this.locator; }} 四.基于Spring Cloud Gateway构建网关由于Spring Cloud Gateway未完全成熟，而且性能，稳定性等，现在无从考证，没有使用案例，基于Spring Cloud Gateway方案构建自己的网关风险比较大，而且PS不知道到年底是否成熟可用。故在这里不做过多说明。 五.基于Netty自研网关中间件5.1 架构图可以参考架构图如下: 5.2 设计原则 1.每个Filter基于责任链，只做专一的一件事 2.每个Filter有各自独立的数据 3.损耗性能的Filter顺序往后放 4.启动读取配置顺序，先远端，若远端失败，则读取本地。 5.集群网关，要注意数据的diff和灰度 6.尽量做到和服务治理框架解耦，易于接入，易于升级 六.参考文章企业级API网关的设计微服务与API 网关（上）: 为什么需要API网关？http://blog.csdn.net/u013815546/article/details/68944039https://segmentfault.com/a/1190000009191419","link":"/janus/gw-solution/"},{"title":"并发编程总结之synchronized细节问题","text":"摘要:本节主要介绍了并发编程下怎么避免数据脏读和什么是synchronized的可重入锁，synchronized的可重入锁的几种使用场景下，是线程安全的。以及一些细节的synchronized使用问题和synchronized常见代码块示例Code可以直接Copy运行。 脏读什么是脏读 对于对象的同步和异步方法，我们在设计程序，一定要考虑问题的整体性，不然会出现数据不一致的错误，最经典的错误就是脏读(DirtyRead)。 示例Code业务整体需要使用完整的synchronized，保持业务的原子性。1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * 业务整体需要使用完整的synchronized，保持业务的原子性。 * * @author xujin * */public class DirtyRead { private String username = \"xujin\"; private String password = \"123\";&lt;!--more--&gt; public synchronized void setValue(String username, String password) { this.username = username; try { Thread.sleep(2000); } catch (InterruptedException e) { e.printStackTrace(); } this.password = password; System.out.println(\"setValue最终结果：username = \" + username + \" , password = \" + password); } //①这里getValue没有加synchronized修饰 public void getValue() { System.out.println(\"getValue方法得到：username = \" + this.username + \" , password = \" + this.password); } public static void main(String[] args) throws Exception { final DirtyRead dr = new DirtyRead(); Thread t1 = new Thread(new Runnable() { @Override public void run() { dr.setValue(\"张三\", \"456\"); } }); t1.start(); Thread.sleep(1000); dr.getValue(); }} 上面的Code中，getValue没有加synchronized修饰，打印结果如下,出现脏读12getValue方法得到：username = 张三 , password = 123setValue最终结果：username = 张三 , password = 456 只需在getValue加synchronized修饰，如下:123public synchronized void getValue() { System.out.println(\"getValue方法得到：username = \" + this.username + \" , password = \" + this.password);} 运行结果如下,没有造成数据脏读12setValue最终结果：username = 张三 , password = 456getValue方法得到：username = 张三 , password = 456 小结 在我们对对象中的一个方法加锁的时候，需要考虑业务的或程序的整体性，也就是为程序中的set和get方法同时加锁synchronized同步关键字，保证业务的(service层)的原子性，不然会出现数据错误，脏读。 synchronized的重入什么是synchronized的重入锁 synchronized,它拥有强制原子性的内置锁机制,是一个重入锁,所以在使用synchronized时,当一个线程请求得到一个对象锁后再次请求此对象锁,可以再次得到该对象锁,就是说在一个synchronized方法/块的内部调用本类的其他synchronized方法/块时，是永远可以拿到锁。 当线程请求一个由其它线程持有的对象锁时，该线程会阻塞，而当线程请求由自己持有的对象锁时，如果该锁是重入锁,请求就会成功,否则阻塞. 简单的说:关键字synchronized具有锁重入的功能，也就是在使用synchronized时，当一个线程得到一个对象锁的锁后，再次请求此对象时可以再次得到该对象对应的锁。 嵌套调用关系synchronized的重入嵌套调用关系synchronized的重入也是线程安全的，下面是method1，method2，method3都被synchronized修饰，调用关系method1–&gt;method2–&gt;method3,也是线程安全的。1234567891011121314151617181920212223242526272829303132/** * synchronized的重入 * * @author xujin * */public class SyncReenTrant { public synchronized void method1() { System.out.println(\"method1..\"); method2(); } public synchronized void method2() { System.out.println(\"method2..\"); method3(); } public synchronized void method3() { System.out.println(\"method3..\"); } public static void main(String[] args) { final SyncReenTrant sd = new SyncReenTrant(); Thread t1 = new Thread(new Runnable() { @Override public void run() { sd.method1(); } }); t1.start(); } 运行结果如下:123method1..method2..method3.. 继承关系的synchronized的重入简单 Code1：123456789101112131415161718192021222324252627public class Son extends Father { public synchronized void doSomething() { System.out.println(&quot;child.doSomething()&quot;); // 调用自己类中其他的synchronized方法 doAnotherThing(); } private synchronized void doAnotherThing() { // 调用父类的synchronized方法 super.doSomething(); System.out.println(&quot;child.doAnotherThing()&quot;); } public static void main(String[] args) { Son child = new Son(); child.doSomething(); }}class Father { public synchronized void doSomething() { System.out.println(&quot;father.doSomething()&quot;); }} 运行结果:123child.doSomething()father.doSomething()child.doAnotherThing() 这里的对象锁只有一个,就是child对象的锁,当执行child.doSomething时，该线程获得child对象的锁，在doSomething方法内执行doAnotherThing时再次请求child对象的锁，因为synchronized是重入锁，所以可以得到该锁，继续在doAnotherThing里执行父类的doSomething方法时第三次请求child对象的锁，同理可得到，如果不是重入锁的话，那这后面这两次请求锁将会被一直阻塞，从而导致死锁。 所以在Java内部，同一线程在调用自己类中其他synchronized方法/块或调用父类的synchronized方法/块都不会阻碍该线程的执行，就是说同一线程对同一个对象锁是可重入的，而且同一个线程可以获取同一把锁多次，也就是可以多次重入。因为java线程是基于“每线程（per-thread）”，而不是基于“每调用（per-invocation）”的（java中线程获得对象锁的操作是以每线程为粒度的，per-invocation互斥体获得对象锁的操作是以每调用作为粒度的） 我们再来看看重入锁是怎么实现可重入性的，其实现方法是为每个锁关联一个线程持有者和计数器，当计数器为0时表示该锁没有被任何线程持有，那么任何线程都可能获得该锁而调用相应的方法；当某一线程请求成功后，JVM会记下锁的持有线程，并且将计数器置为1；此时其它线程请求该锁，则必须等待；而该持有锁的线程如果再次请求这个锁，就可以再次拿到这个锁，同时计数器会递增；当线程退出同步代码块时，计数器会递减，如果计数器为0，则释放该锁。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class SyncExtends { // 父类 static class Father { public int i = 10; public synchronized void operationSup() { try { i--; System.out.println(\"Father print i = \" + i); Thread.sleep(100); } catch (InterruptedException e) { e.printStackTrace(); } } } // 子类继承父类 static class Son extends Father { public synchronized void operationSub() { try { while (i &gt; 0) { i--; System.out.println(\"Son print i = \" + i); Thread.sleep(100); this.operationSup(); } } catch (InterruptedException e) { e.printStackTrace(); } } } public static void main(String[] args) { Thread t1 = new Thread(new Runnable() { @Override public void run() { Son sub = new Son(); sub.operationSub(); } }); t1.start(); }} 运行结果如下:12345678910Son print i = 9Father print i = 8Son print i = 7Father print i = 6Son print i = 5Father print i = 4Son print i = 3Father print i = 2Son print i = 1Father print i = 0 参考文章:http://blog.csdn.net/aigoogle/article/details/29893667 synchronized常见代码块 synchronized可以使用任意的Object进行加锁， 使用synchronized代码块加锁,比较灵活，如下代码所示: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869public class ObjectLock { public void method1() { // 对this当前ObjectLock实例对象加锁 synchronized (this) { try { System.out.println(\"do method1..\"); Thread.sleep(2000); } catch (InterruptedException e) { e.printStackTrace(); } } } public void method2() { // 对ObjectLock类加锁 synchronized (ObjectLock.class) { try { System.out.println(\"do method2..\"); Thread.sleep(2000); } catch (InterruptedException e) { e.printStackTrace(); } } } // 任何对象锁 private Object anyObjectlock = new Object(); public void method3() { synchronized (anyObjectlock) { try { System.out.println(\"do method3..\"); Thread.sleep(2000); } catch (InterruptedException e) { e.printStackTrace(); } } } public static void main(String[] args) { final ObjectLock objLock = new ObjectLock(); Thread t1 = new Thread(new Runnable() { @Override public void run() { objLock.method1(); } }); Thread t2 = new Thread(new Runnable() { @Override public void run() { objLock.method2(); } }); Thread t3 = new Thread(new Runnable() { @Override public void run() { objLock.method3(); } }); t1.start(); t2.start(); t3.start(); }} 2.使用synchronized声明的方法在某些情况下，是有弊端的，比如A线程调用同步的方法执行一个很长时间的任务,那么B线程就必须等待很长的时间才可以执行，这样情况下可以使用synchronize的去优化代码执行时间，也就是我们通常所说的减小锁的粒度。 1234567891011121314151617181920212223242526272829303132333435363738public class Optimize { public void doLongTimeTask() { try { System.out.println(\"当前线程开始：\" + Thread.currentThread().getName() + \", 正在执行一个较长时间的业务操作，其内容不需要同步\"); Thread.sleep(2000); // 使用synchronized代码块减小锁的粒度，提高性能 synchronized (this) { System.out.println(\"当前线程：\" + Thread.currentThread().getName() + \", 执行同步代码块，对其同步变量进行操作\"); Thread.sleep(1000); } System.out.println(\"当前线程结束：\" + Thread.currentThread().getName() + \", 执行完毕\"); } catch (InterruptedException e) { e.printStackTrace(); } } public static void main(String[] args) { final Optimize otz = new Optimize(); Thread t1 = new Thread(new Runnable() { @Override public void run() { otz.doLongTimeTask(); } }, \"t1\"); Thread t2 = new Thread(new Runnable() { @Override public void run() { otz.doLongTimeTask(); } }, \"t2\"); t1.start(); t2.start(); }} 执行结果: 123456当前线程开始：t1, 正在执行一个较长时间的业务操作，其内容不需要同步当前线程开始：t2, 正在执行一个较长时间的业务操作，其内容不需要同步当前线程：t2, 执行同步代码块，对其同步变量进行操作当前线程结束：t2, 执行完毕当前线程：t1, 执行同步代码块，对其同步变量进行操作当前线程结束：t1, 执行完毕 3.注意就是不要使用String的常量加锁，会出现死循环问题。 synchronized代码块对字符串的锁，注意String常量池的缓存功能,示例代码如下: 1234567891011121314151617181920212223242526272829303132333435public class StringLock { public void method() { synchronized (\"字符串常量\") { try { while(true){ System.out.println(\"当前线程 : \" + Thread.currentThread().getName() + \"开始\"); Thread.sleep(1000); System.out.println(\"当前线程 : \" + Thread.currentThread().getName() + \"结束\"); } } catch (InterruptedException e) { e.printStackTrace(); } } } public static void main(String[] args) { final StringLock stringLock = new StringLock(); Thread t1 = new Thread(new Runnable() { @Override public void run() { stringLock.method(); } },\"t1\"); Thread t2 = new Thread(new Runnable() { @Override public void run() { stringLock.method(); } },\"t2\"); t1.start(); t2.start(); }} 提示:运行结果是:t1线程一直死循环。t2线程不执行。修改为如下代码,t1和t2线程交替执行 1234567891011121314public void method() { //把synchronized (\"字符串常量\") 修改为synchronized (new String(\"字符串常量\")) synchronized (new String(\"字符串常量\")) { try { while (true) { System.out.println(\"当前线程 : \" + Thread.currentThread().getName() + \"开始\"); Thread.sleep(1000); System.out.println(\"当前线程 : \" + Thread.currentThread().getName() + \"结束\"); } } catch (InterruptedException e) { e.printStackTrace(); } } } 4.锁对象的改变问题: 当使用一个对象进行加锁的时候，要注意对象本身发生变化的时候，那么持有的锁就不同。如果对象本身不发生改变，那么依然是同步的，即使是对象的属性发生了变化。 4.1 示例代码1:对象本身发生变化的时候,那么对象持有的锁就发生变化 12345678910111213141516171819202122232425262728293031323334353637383940414243public class ChangeLock { private String lock = \"lock\"; private void method() { synchronized (lock) { try { System.out.println(\"当前线程 : \" + Thread.currentThread().getName() + \"开始\"); // 这里把锁的内容改变了，因此t1,t2线程基本同时进来，而不是t1休眠2秒后，t2进来 lock = \"change lock\"; Thread.sleep(2000); System.out.println(\"当前线程 : \" + Thread.currentThread().getName() + \"结束\"); } catch (InterruptedException e) { e.printStackTrace(); } } } public static void main(String[] args) { final ChangeLock changeLock = new ChangeLock(); Thread t1 = new Thread(new Runnable() { @Override public void run() { changeLock.method(); } }, \"t1\"); Thread t2 = new Thread(new Runnable() { @Override public void run() { changeLock.method(); } }, \"t2\"); t1.start(); try { Thread.sleep(100); } catch (InterruptedException e) { e.printStackTrace(); } t2.start(); }} 4.2 示例代码2:同一对象属性的修改不会影响锁的情况 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public class ModifyLock { private String name; private int age; public String getName() { return name; } public void setName(String name) { this.name = name; } public int getAge() { return age; } public void setAge(int age) { this.age = age; } public synchronized void changeAttributte(String name, int age) { try { System.out.println(\"当前线程 : \" + Thread.currentThread().getName() + \" 开始\"); this.setName(name); this.setAge(age); System.out.println(\"当前线程 : \" + Thread.currentThread().getName() + \" 修改对象内容为： \" + this.getName() + \", \" + this.getAge()); Thread.sleep(2000); System.out.println(\"当前线程 : \" + Thread.currentThread().getName() + \" 结束\"); } catch (InterruptedException e) { e.printStackTrace(); } } public static void main(String[] args) { final ModifyLock modifyLock = new ModifyLock(); Thread t1 = new Thread(new Runnable() { @Override public void run() { modifyLock.changeAttributte(\"许进\", 25); } }, \"t1\"); Thread t2 = new Thread(new Runnable() { @Override public void run() { modifyLock.changeAttributte(\"李四X\", 21); } }, \"t2\"); t1.start(); try { Thread.sleep(100); } catch (InterruptedException e) { e.printStackTrace(); } t2.start(); }} 运行结果: 123456当前线程 : t1 开始当前线程 : t1 修改对象内容为： 许进, 25当前线程 : t1 结束当前线程 : t2 开始当前线程 : t2 修改对象内容为： 李四X, 21当前线程 : t2 结束","link":"/bf/bf-synchronized/"},{"title":"走进Spring Cloud CodeGen上篇","text":"摘要:本文主要介绍由Spring Cloud中国社区发起的以Spring Cloud为主的代码生成器，目的是快速，按需勾选，生成最优实践的Spring Cloud工程。欢迎有想法的小伙伴加入Spring Cloud中国社区开源战队，关于代码生成器和spring-cloud-codegen的设计细节后面将有一系列的文章介绍。 一.Spring Cloud CodeGen概述1.1 为什么要开发Spring Cloud CodeGen 如何生成项目的代码？ 不少开发人员都会使用Maven的Archetype或IDEA的Gradle插件，通过几个简单的交互就可以快速完成项目的结构和对应的代码生成。但是Spring官方也给我们提供了http://start.spring.io 生成，道理很简单：UI可视化，选择项多，更新快。但是例如:application.properties文件的生成,官方是不会生成对应的配置项的 因此也有不少公司对其进行代码增强处理二次开发处理。 根据目前社区和现在使用代码生成器的现状，迫切希望打造一个如下的代码生成器: 业界最佳Spring Cloud微服务实战经验打造最佳代码生成模板 容器化/Docker支持： 根据你选择的dependency，自动生成docker-compose.yml文件，如选择mysql，redis等，会在docker-compse.yml自动添加对应的镜像配置，方便使用docker compose进行环境配置和组件编排。 application.properties文件生成： 官方是不会生成对应的配置项的，但是我们将会结合Spring Cloud的最优实践配置，不仅如此我们将会集成市面上口碑最好的中间件给出最优配置。 规范：pom.xml的规范，application.properties的规范等，提供默认配置，只需要稍微调整一下或者不需要任何调整就可以使用。 其他标准文件的规范：.gitignore, logback-spring.xml等。 如果你选择mybatis会自动生成mybatis-config.xml文件等。 持续集成：自动生成 .gitlab-ci.yml 文件，自动集成 Gitlab CI 基于如上原因和愿景,因此我们需要开发一个最优Spring Cloud实践的代码生成器。 1.2 Spring Cloud CodeGen概述spring-cloud-codegen是由Spring Cloud中国社区发起的一个代码生成器开源项目，目前该开源项目由许进，任浩军，李云龙，刘美胜奇持续开发迭代。基于Freemarker+模板文件的代码生成器，可以按需勾选组件，轻松快速实现对框架代码的一键创建（例如业务部门实现对基础架构部提供的框架快速搭建），实现对Spring Cloud的最优实践和配置工具化和规范化。 1.3 功能最终功能包含如下，包括屏蔽XXX注解和配置 generate app structure ——&gt;状态doing generate java code and resources ——&gt;状态todo generate docker-compose.yml ——&gt;状态todo generate .gitlab-ci.yml ——&gt;状态todo generate DDD structure ——&gt;状态todo 二.走进Spring Cloud CodeGen2.1 项目介绍 项目Demo地址:http://start.springcloud.cn/项目开发人员:许进,任浩军,刘美胜奇,李云龙github地址:https://github.com/springcloud/spring-cloud-codegenhttps://github.com/springcloud/spring-cloud-skeleton 2.2 项目技术选型Spring Boot+Spring MVC+FreeMarker+Vue 2.3 代码生成器配置1.skeleton-data.properties 用来描述模板文件的全局配置值，里面的值替换模板文件里的动态变量(用${}表示)1234567891011121314151617# ---------- 工程配置 ----------# moduleName=sales-projectmoduleName=salesbasePackage=cn.springcloudpomGroupId=cn.springcloudpomArtifactId=salespomName=springcloud salespomVersion=1.0.0springCloudVersion=Dalston.SR4springBootVersion=1.5.6.RELEASEjavaVersion=1.8# ---------- 框架配置 ----------serviceName=spring-cloud-salesport=2222eurekaEnabled=trueeurekaUrl=http://localhost:1111/eureka/ skeleton-description.xml 如上图所示，用来描述模界面驱动和渲染的组件，分为Group和Entity结构，一个Group包含多个Entity，其他属性比较容易理解，主要介绍如下 highlightable - 标识为高亮项，一般组件渲染成高亮方式，例如Label红色字体，提示使用者着重关注 defaultable - 标识为默认项，一般组件渲染成默认项方式，提示使用者可以不修改对应值 emptiable - 标识为留空项，一般组件渲染成留空项方式，提示使用者对应值可以为空 editable - 标识为不可编辑项，一般组件渲染成不可编辑项方式，如果false则把组件灰掉，提示使用者对应值不可编辑 示例Demo数据如下: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;skeleton&gt; &lt;!-- 工程基本配置 --&gt; &lt;group&gt; &lt;key&gt;basic&lt;/key&gt; &lt;label&gt;&lt;/label&gt; &lt;description&gt;&lt;/description&gt; &lt;entity&gt; &lt;key&gt;pomGroupId&lt;/key&gt; &lt;label&gt;Group&lt;/label&gt; &lt;description&gt;&lt;/description&gt; &lt;type&gt;TEXTFIELD&lt;/type&gt; &lt;highlightable&gt;true&lt;/highlightable&gt; &lt;defaultable&gt;false&lt;/defaultable&gt; &lt;emptiable&gt;false&lt;/emptiable&gt; &lt;editable&gt;true&lt;/editable&gt; &lt;/entity&gt; &lt;entity&gt; &lt;key&gt;pomArtifactId&lt;/key&gt; &lt;label&gt;Artifact&lt;/label&gt; &lt;description&gt;&lt;/description&gt; &lt;type&gt;TEXTFIELD&lt;/type&gt; &lt;highlightable&gt;true&lt;/highlightable&gt; &lt;defaultable&gt;false&lt;/defaultable&gt; &lt;emptiable&gt;false&lt;/emptiable&gt; &lt;editable&gt;true&lt;/editable&gt; &lt;/entity&gt; &lt;entity&gt; &lt;key&gt;moduleName&lt;/key&gt; &lt;label&gt;工程模块名&lt;/label&gt; &lt;description&gt;moduleName&lt;/description&gt; &lt;note&gt;【必改项】首字母必须小写，中间只允许出现“-”&lt;/note&gt; &lt;type&gt;TEXTFIELD&lt;/type&gt; &lt;highlightable&gt;true&lt;/highlightable&gt; &lt;defaultable&gt;false&lt;/defaultable&gt; &lt;emptiable&gt;false&lt;/emptiable&gt; &lt;editable&gt;true&lt;/editable&gt; &lt;/entity&gt; &lt;entity&gt; &lt;key&gt;basePackage&lt;/key&gt; &lt;label&gt;上层包路径&lt;/label&gt; &lt;description&gt;basePackage&lt;/description&gt; &lt;note&gt;【必改项】该路径会作为所有Java代码的上层路径。moduleName、basePackage和projectType三者组合起来解析出相关目录和结构规则，例如moduleName=payment-ccb，basePackage=com.nepxion，projectType=server，那么工程名为payment-ccb-server，类路径为com.nepxion.payment.ccb.server &lt;/note&gt; &lt;type&gt;TEXTFIELD&lt;/type&gt; &lt;highlightable&gt;true&lt;/highlightable&gt; &lt;defaultable&gt;false&lt;/defaultable&gt; &lt;emptiable&gt;false&lt;/emptiable&gt; &lt;editable&gt;true&lt;/editable&gt; &lt;/entity&gt; &lt;entity&gt; &lt;key&gt;javaVersion&lt;/key&gt; &lt;label&gt;Java Version&lt;/label&gt; &lt;description&gt;&lt;/description&gt; &lt;type&gt;COMBOBOX&lt;/type&gt; &lt;options&gt;1.8;1.7;1.6&lt;/options&gt; &lt;highlightable&gt;false&lt;/highlightable&gt; &lt;defaultable&gt;false&lt;/defaultable&gt; &lt;emptiable&gt;false&lt;/emptiable&gt; &lt;editable&gt;true&lt;/editable&gt; &lt;/entity&gt; &lt;/group&gt; &lt;!-- 是否Docker化 --&gt; &lt;group&gt; &lt;key&gt;docker-template&lt;/key&gt; &lt;label&gt;Docker模板&lt;/label&gt; &lt;description&gt;&lt;/description&gt; &lt;type&gt;RADIO_GROUP&lt;/type&gt; &lt;layout&gt;HORIZONTAL&lt;/layout&gt; &lt;entity&gt; &lt;key&gt;true&lt;/key&gt; &lt;label&gt;是&lt;/label&gt; &lt;description&gt;&lt;/description&gt; &lt;type&gt;RADIO&lt;/type&gt; &lt;value&gt;false&lt;/value&gt; &lt;highlightable&gt;false&lt;/highlightable&gt; &lt;defaultable&gt;false&lt;/defaultable&gt; &lt;emptiable&gt;false&lt;/emptiable&gt; &lt;editable&gt;true&lt;/editable&gt; &lt;/entity&gt; &lt;entity&gt; &lt;key&gt;false&lt;/key&gt; &lt;label&gt;否&lt;/label&gt; &lt;description&gt;&lt;/description&gt; &lt;type&gt;RADIO&lt;/type&gt; &lt;value&gt;false&lt;/value&gt; &lt;highlightable&gt;false&lt;/highlightable&gt; &lt;defaultable&gt;false&lt;/defaultable&gt; &lt;emptiable&gt;false&lt;/emptiable&gt; &lt;editable&gt;true&lt;/editable&gt; &lt;/entity&gt; &lt;/group&gt; &lt;!-- 应用类型 --&gt; &lt;group&gt; &lt;key&gt;appType&lt;/key&gt; &lt;label&gt;应用类型&lt;/label&gt; &lt;description&gt;&lt;/description&gt; &lt;type&gt;RADIO_GROUP&lt;/type&gt; &lt;layout&gt;HORIZONTAL&lt;/layout&gt; &lt;entity&gt; &lt;key&gt;Spring Boot&lt;/key&gt; &lt;label&gt;Spring Boot&lt;/label&gt; &lt;description&gt;&lt;/description&gt; &lt;type&gt;RADIO&lt;/type&gt; &lt;value&gt;false&lt;/value&gt; &lt;highlightable&gt;false&lt;/highlightable&gt; &lt;defaultable&gt;false&lt;/defaultable&gt; &lt;emptiable&gt;false&lt;/emptiable&gt; &lt;editable&gt;true&lt;/editable&gt; &lt;/entity&gt; &lt;entity&gt; &lt;key&gt;Spring Cloud&lt;/key&gt; &lt;label&gt;Spring Cloud&lt;/label&gt; &lt;note&gt;Spring Cloud应用&lt;/note&gt; &lt;description&gt;&lt;/description&gt; &lt;type&gt;RADIO&lt;/type&gt; &lt;value&gt;false&lt;/value&gt; &lt;highlightable&gt;false&lt;/highlightable&gt; &lt;defaultable&gt;false&lt;/defaultable&gt; &lt;emptiable&gt;false&lt;/emptiable&gt; &lt;editable&gt;true&lt;/editable&gt; &lt;/entity&gt; &lt;entity&gt; &lt;key&gt;war&lt;/key&gt; &lt;label&gt;war应用&lt;/label&gt; &lt;description&gt;&lt;/description&gt; &lt;type&gt;RADIO&lt;/type&gt; &lt;value&gt;false&lt;/value&gt; &lt;highlightable&gt;false&lt;/highlightable&gt; &lt;defaultable&gt;false&lt;/defaultable&gt; &lt;emptiable&gt;false&lt;/emptiable&gt; &lt;editable&gt;true&lt;/editable&gt; &lt;/entity&gt; &lt;/group&gt; &lt;!-- Spring Cloud独立部署组件 --&gt; &lt;group&gt; &lt;key&gt;sc-alone&lt;/key&gt; &lt;label&gt;Spring Cloud&lt;/label&gt; &lt;description&gt;&lt;/description&gt; &lt;type&gt;RADIO_GROUP&lt;/type&gt; &lt;layout&gt;HORIZONTAL&lt;/layout&gt; &lt;entity&gt; &lt;key&gt;独立组件&lt;/key&gt; &lt;label&gt;独立组件&lt;/label&gt; &lt;description&gt;&lt;/description&gt; &lt;type&gt;RADIO&lt;/type&gt; &lt;value&gt;false&lt;/value&gt; &lt;highlightable&gt;false&lt;/highlightable&gt; &lt;defaultable&gt;false&lt;/defaultable&gt; &lt;emptiable&gt;false&lt;/emptiable&gt; &lt;editable&gt;true&lt;/editable&gt; &lt;/entity&gt; &lt;entity&gt; &lt;key&gt;service-provider&lt;/key&gt; &lt;label&gt;服务提供者&lt;/label&gt; &lt;description&gt;&lt;/description&gt; &lt;type&gt;RADIO&lt;/type&gt; &lt;value&gt;false&lt;/value&gt; &lt;highlightable&gt;false&lt;/highlightable&gt; &lt;defaultable&gt;false&lt;/defaultable&gt; &lt;emptiable&gt;false&lt;/emptiable&gt; &lt;editable&gt;true&lt;/editable&gt; &lt;/entity&gt; &lt;entity&gt; &lt;key&gt;service-consumer&lt;/key&gt; &lt;label&gt;服务消费者&lt;/label&gt; &lt;description&gt;&lt;/description&gt; &lt;type&gt;RADIO&lt;/type&gt; &lt;value&gt;false&lt;/value&gt; &lt;highlightable&gt;false&lt;/highlightable&gt; &lt;defaultable&gt;false&lt;/defaultable&gt; &lt;emptiable&gt;false&lt;/emptiable&gt; &lt;editable&gt;true&lt;/editable&gt; &lt;/entity&gt; &lt;/group&gt; &lt;!-- web基础框架 --&gt; &lt;group&gt; &lt;key&gt;basic-framework&lt;/key&gt; &lt;label&gt;基础框架&lt;/label&gt; &lt;description&gt;基础框架-1&lt;/description&gt; &lt;type&gt;CHECKBOX_GROUP&lt;/type&gt; &lt;layout&gt;HORIZONTAL&lt;/layout&gt; &lt;entity&gt; &lt;key&gt;spring-mvc&lt;/key&gt; &lt;label&gt;Spring MVC&lt;/label&gt; &lt;description&gt;Spring MVC&lt;/description&gt; &lt;type&gt;CHECKBOX&lt;/type&gt; &lt;highlightable&gt;false&lt;/highlightable&gt; &lt;defaultable&gt;true&lt;/defaultable&gt; &lt;emptiable&gt;false&lt;/emptiable&gt; &lt;editable&gt;true&lt;/editable&gt; &lt;/entity&gt; &lt;entity&gt; &lt;key&gt;Mybatis&lt;/key&gt; &lt;label&gt;Mybatis&lt;/label&gt; &lt;description&gt;Mybatis&lt;/description&gt; &lt;type&gt;CHECKBOX&lt;/type&gt; &lt;highlightable&gt;false&lt;/highlightable&gt; &lt;defaultable&gt;false&lt;/defaultable&gt; &lt;emptiable&gt;false&lt;/emptiable&gt; &lt;editable&gt;true&lt;/editable&gt; &lt;/entity&gt; &lt;/group&gt; &lt;!-- Spring Cloud独立部署单选组件 --&gt; &lt;group&gt; &lt;key&gt;sc-alone-radio&lt;/key&gt; &lt;label&gt;独立组件&lt;/label&gt; &lt;description&gt;&lt;/description&gt; &lt;type&gt;RADIO_GROUP&lt;/type&gt; &lt;layout&gt;HORIZONTAL&lt;/layout&gt; &lt;entity&gt; &lt;key&gt;eureka-server&lt;/key&gt; &lt;label&gt;Eureka Server&lt;/label&gt; &lt;description&gt;&lt;/description&gt; &lt;type&gt;RADIO&lt;/type&gt; &lt;value&gt;false&lt;/value&gt; &lt;highlightable&gt;false&lt;/highlightable&gt; &lt;defaultable&gt;false&lt;/defaultable&gt; &lt;emptiable&gt;false&lt;/emptiable&gt; &lt;editable&gt;true&lt;/editable&gt; &lt;/entity&gt; &lt;entity&gt; &lt;key&gt;zuul-server&lt;/key&gt; &lt;label&gt;Zuul Server&lt;/label&gt; &lt;description&gt;&lt;/description&gt; &lt;type&gt;RADIO&lt;/type&gt; &lt;value&gt;false&lt;/value&gt; &lt;highlightable&gt;false&lt;/highlightable&gt; &lt;defaultable&gt;false&lt;/defaultable&gt; &lt;emptiable&gt;false&lt;/emptiable&gt; &lt;editable&gt;true&lt;/editable&gt; &lt;/entity&gt; &lt;entity&gt; &lt;key&gt;sc-gateway&lt;/key&gt; &lt;label&gt;SC Gateway&lt;/label&gt; &lt;description&gt;&lt;/description&gt; &lt;type&gt;RADIO&lt;/type&gt; &lt;value&gt;false&lt;/value&gt; &lt;highlightable&gt;false&lt;/highlightable&gt; &lt;defaultable&gt;false&lt;/defaultable&gt; &lt;emptiable&gt;false&lt;/emptiable&gt; &lt;editable&gt;true&lt;/editable&gt; &lt;/entity&gt; &lt;entity&gt; &lt;key&gt;config-server&lt;/key&gt; &lt;label&gt;Config Server&lt;/label&gt; &lt;description&gt;&lt;/description&gt; &lt;type&gt;RADIO&lt;/type&gt; &lt;value&gt;false&lt;/value&gt; &lt;highlightable&gt;false&lt;/highlightable&gt; &lt;defaultable&gt;false&lt;/defaultable&gt; &lt;emptiable&gt;false&lt;/emptiable&gt; &lt;editable&gt;true&lt;/editable&gt; &lt;/entity&gt; &lt;entity&gt; &lt;key&gt;zipkin-server&lt;/key&gt; &lt;label&gt;Zipkin Server&lt;/label&gt; &lt;description&gt;&lt;/description&gt; &lt;type&gt;RADIO&lt;/type&gt; &lt;value&gt;false&lt;/value&gt; &lt;highlightable&gt;false&lt;/highlightable&gt; &lt;defaultable&gt;false&lt;/defaultable&gt; &lt;emptiable&gt;false&lt;/emptiable&gt; &lt;editable&gt;true&lt;/editable&gt; &lt;/entity&gt; &lt;/group&gt; &lt;!-- Spring Cloud可组合多选组件 --&gt; &lt;group&gt; &lt;key&gt;sc-group-checkBox&lt;/key&gt; &lt;label&gt;可组合组件&lt;/label&gt; &lt;description&gt;Spring Cloud组件&lt;/description&gt; &lt;type&gt;CHECKBOX_GROUP&lt;/type&gt; &lt;layout&gt;HORIZONTAL&lt;/layout&gt; &lt;entity&gt; &lt;key&gt;fegin&lt;/key&gt; &lt;label&gt;Fegin&lt;/label&gt; &lt;description&gt;Spring MVC&lt;/description&gt; &lt;type&gt;CHECKBOX&lt;/type&gt; &lt;highlightable&gt;false&lt;/highlightable&gt; &lt;defaultable&gt;false&lt;/defaultable&gt; &lt;emptiable&gt;false&lt;/emptiable&gt; &lt;editable&gt;true&lt;/editable&gt; &lt;/entity&gt; &lt;entity&gt; &lt;key&gt;hystrix&lt;/key&gt; &lt;label&gt;hystrix&lt;/label&gt; &lt;description&gt;hystrix&lt;/description&gt; &lt;type&gt;CHECKBOX&lt;/type&gt; &lt;highlightable&gt;false&lt;/highlightable&gt; &lt;defaultable&gt;true&lt;/defaultable&gt; &lt;emptiable&gt;false&lt;/emptiable&gt; &lt;editable&gt;true&lt;/editable&gt; &lt;/entity&gt; &lt;entity&gt; &lt;key&gt;ribbon&lt;/key&gt; &lt;label&gt;Ribbon&lt;/label&gt; &lt;description&gt;Ribbon&lt;/description&gt; &lt;type&gt;CHECKBOX&lt;/type&gt; &lt;highlightable&gt;false&lt;/highlightable&gt; &lt;defaultable&gt;false&lt;/defaultable&gt; &lt;emptiable&gt;false&lt;/emptiable&gt; &lt;editable&gt;true&lt;/editable&gt; &lt;/entity&gt; &lt;/group&gt;&lt;/skeleton&gt; 2.4 Spring-cloud-CodeGen开发接口根据配置文件进行界面驱动的元数据接口 12@RequestMapping(value = \"/getMetaData\", method = RequestMethod.GET)public List&lt;SkeletonGroup&gt; getMetaData() 返回JSON格式的文件，简单介绍一下格式： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368[ { \"key\": \"basic\", \"label\": \"\", \"description\": \"\", \"type\": \"NORMAL_GROUP\", \"layoutType\": \"VERTICAL\", \"entityList\": [ { \"key\": \"pomGroupId\", \"label\": \"Group\", \"description\": \"\", \"note\": null, \"value\": \"cn.springcloud\", \"type\": \"TEXTFIELD\", \"options\": null, \"highlightable\": true, \"defaultable\": false, \"emptiable\": false, \"editable\": true }, { \"key\": \"pomArtifactId\", \"label\": \"Artifact\", \"description\": \"\", \"note\": null, \"value\": \"sales\", \"type\": \"TEXTFIELD\", \"options\": null, \"highlightable\": true, \"defaultable\": false, \"emptiable\": false, \"editable\": true }, { \"key\": \"moduleName\", \"label\": \"工程模块名\", \"description\": \"moduleName\", \"note\": \"【必改项】首字母必须小写，中间只允许出现“-”\", \"value\": \"sales\", \"type\": \"TEXTFIELD\", \"options\": null, \"highlightable\": true, \"defaultable\": false, \"emptiable\": false, \"editable\": true }, { \"key\": \"basePackage\", \"label\": \"上层包路径\", \"description\": \"basePackage\", \"note\": \"【必改项】该路径会作为所有Java代码的上层路径。moduleName、basePackage和projectType三者组合起来解析出相关目录和结构规则，例如moduleName=payment-ccb，basePackage=com.nepxion，projectType=server，那么工程名为payment-ccb-server，类路径为com.nepxion.payment.ccb.server\", \"value\": \"cn.springcloud\", \"type\": \"TEXTFIELD\", \"options\": null, \"highlightable\": true, \"defaultable\": false, \"emptiable\": false, \"editable\": true }, { \"key\": \"javaVersion\", \"label\": \"Java Version\", \"description\": \"\", \"note\": null, \"value\": \"1.8\", \"type\": \"COMBOBOX\", \"options\": [ \"1.8\", \"1.7\", \"1.6\" ], \"highlightable\": false, \"defaultable\": false, \"emptiable\": false, \"editable\": true } ] }, { \"key\": \"docker-template\", \"label\": \"Docker模板\", \"description\": \"\", \"type\": \"RADIO_GROUP\", \"layoutType\": \"HORIZONTAL\", \"entityList\": [ { \"key\": \"true\", \"label\": \"是\", \"description\": \"\", \"note\": null, \"value\": null, \"type\": \"RADIO\", \"options\": null, \"highlightable\": false, \"defaultable\": false, \"emptiable\": false, \"editable\": true }, { \"key\": \"false\", \"label\": \"否\", \"description\": \"\", \"note\": null, \"value\": null, \"type\": \"RADIO\", \"options\": null, \"highlightable\": false, \"defaultable\": false, \"emptiable\": false, \"editable\": true } ] }, { \"key\": \"appType\", \"label\": \"应用类型\", \"description\": \"\", \"type\": \"RADIO_GROUP\", \"layoutType\": \"HORIZONTAL\", \"entityList\": [ { \"key\": \"Spring Boot\", \"label\": \"Spring Boot\", \"description\": \"\", \"note\": null, \"value\": null, \"type\": \"RADIO\", \"options\": null, \"highlightable\": false, \"defaultable\": false, \"emptiable\": false, \"editable\": true }, { \"key\": \"Spring Cloud\", \"label\": \"Spring Cloud\", \"description\": \"\", \"note\": \"Spring Cloud应用\", \"value\": null, \"type\": \"RADIO\", \"options\": null, \"highlightable\": false, \"defaultable\": false, \"emptiable\": false, \"editable\": true }, { \"key\": \"war\", \"label\": \"war应用\", \"description\": \"\", \"note\": null, \"value\": null, \"type\": \"RADIO\", \"options\": null, \"highlightable\": false, \"defaultable\": false, \"emptiable\": false, \"editable\": true } ] }, { \"key\": \"sc-alone\", \"label\": \"Spring Cloud\", \"description\": \"\", \"type\": \"RADIO_GROUP\", \"layoutType\": \"HORIZONTAL\", \"entityList\": [ { \"key\": \"独立组件\", \"label\": \"独立组件\", \"description\": \"\", \"note\": null, \"value\": null, \"type\": \"RADIO\", \"options\": null, \"highlightable\": false, \"defaultable\": false, \"emptiable\": false, \"editable\": true }, { \"key\": \"service-provider\", \"label\": \"服务提供者\", \"description\": \"\", \"note\": null, \"value\": null, \"type\": \"RADIO\", \"options\": null, \"highlightable\": false, \"defaultable\": false, \"emptiable\": false, \"editable\": true }, { \"key\": \"service-consumer\", \"label\": \"服务消费者\", \"description\": \"\", \"note\": null, \"value\": null, \"type\": \"RADIO\", \"options\": null, \"highlightable\": false, \"defaultable\": false, \"emptiable\": false, \"editable\": true } ] }, { \"key\": \"basic-framework\", \"label\": \"基础框架\", \"description\": \"基础框架-1\", \"type\": \"CHECKBOX_GROUP\", \"layoutType\": \"HORIZONTAL\", \"entityList\": [ { \"key\": \"spring-mvc\", \"label\": \"Spring MVC\", \"description\": \"Spring MVC\", \"note\": null, \"value\": null, \"type\": \"CHECKBOX\", \"options\": null, \"highlightable\": false, \"defaultable\": true, \"emptiable\": false, \"editable\": true }, { \"key\": \"Mybatis\", \"label\": \"Mybatis\", \"description\": \"Mybatis\", \"note\": null, \"value\": null, \"type\": \"CHECKBOX\", \"options\": null, \"highlightable\": false, \"defaultable\": false, \"emptiable\": false, \"editable\": true } ] }, { \"key\": \"sc-alone-radio\", \"label\": \"独立组件\", \"description\": \"\", \"type\": \"RADIO_GROUP\", \"layoutType\": \"HORIZONTAL\", \"entityList\": [ { \"key\": \"eureka-server\", \"label\": \"Eureka Server\", \"description\": \"\", \"note\": null, \"value\": null, \"type\": \"RADIO\", \"options\": null, \"highlightable\": false, \"defaultable\": false, \"emptiable\": false, \"editable\": true }, { \"key\": \"zuul-server\", \"label\": \"Zuul Server\", \"description\": \"\", \"note\": null, \"value\": null, \"type\": \"RADIO\", \"options\": null, \"highlightable\": false, \"defaultable\": false, \"emptiable\": false, \"editable\": true }, { \"key\": \"sc-gateway\", \"label\": \"SC Gateway\", \"description\": \"\", \"note\": null, \"value\": null, \"type\": \"RADIO\", \"options\": null, \"highlightable\": false, \"defaultable\": false, \"emptiable\": false, \"editable\": true }, { \"key\": \"config-server\", \"label\": \"Config Server\", \"description\": \"\", \"note\": null, \"value\": null, \"type\": \"RADIO\", \"options\": null, \"highlightable\": false, \"defaultable\": false, \"emptiable\": false, \"editable\": true }, { \"key\": \"zipkin-server\", \"label\": \"Zipkin Server\", \"description\": \"\", \"note\": null, \"value\": null, \"type\": \"RADIO\", \"options\": null, \"highlightable\": false, \"defaultable\": false, \"emptiable\": false, \"editable\": true } ] }, { \"key\": \"sc-group-checkBox\", \"label\": \"可组合组件\", \"description\": \"Spring Cloud组件\", \"type\": \"CHECKBOX_GROUP\", \"layoutType\": \"HORIZONTAL\", \"entityList\": [ { \"key\": \"fegin\", \"label\": \"Fegin\", \"description\": \"Spring MVC\", \"note\": null, \"value\": null, \"type\": \"CHECKBOX\", \"options\": null, \"highlightable\": false, \"defaultable\": false, \"emptiable\": false, \"editable\": true }, { \"key\": \"hystrix\", \"label\": \"hystrix\", \"description\": \"hystrix\", \"note\": null, \"value\": null, \"type\": \"CHECKBOX\", \"options\": null, \"highlightable\": false, \"defaultable\": true, \"emptiable\": false, \"editable\": true }, { \"key\": \"ribbon\", \"label\": \"Ribbon\", \"description\": \"Ribbon\", \"note\": null, \"value\": null, \"type\": \"CHECKBOX\", \"options\": null, \"highlightable\": false, \"defaultable\": false, \"emptiable\": false, \"editable\": true } ] }] 下载脚手架Zip文件的接口，返回Zip文件的byte数组类型，Body的内容为src\\main\\resources\\config\\skeleton-data.properties 12@RequestMapping(value = \"/downloadBytes\", method = RequestMethod.POST)public byte[] downloadBytes(@RequestBody String config) 下载脚手架Zip文件的接口，返回Zip文件的ResponseEntity类型 12@RequestMapping(value = \"/downloadResponse\", method = RequestMethod.POST)public ResponseEntity&lt;Resource&gt; downloadResponse(@RequestBody String config) 2.5 前端运行spring-cloud-codegen-ui采用Vue开发，本地开发调试，采用如下命令安装。 12345678# install dependenciesnpm install# serve with hot reload at localhost:8081npm run dev# build for production with minificationnpm run build","link":"/ex/sc-codegen/"},{"title":"Spring Cloud第二代","text":"摘要: 随着Eureka不再维护，Hystrix不再开发新功能，进入维护状态。以及最近中国开源出现一些大事，预测一下2019年未来Spring Cloud生态圈中的第二代组件的组合，仅代表个人看法。 1. Spring Cloud第一代 Spring Cloud自从推出之后，给大家的感觉就是Spring Cloud做它最擅长的事，也就是高度抽象和封装，强强联手整合最优东西为我所用，比如Netflix开源的Eureka，Hystrix，Ribbon等。而且提供多种技术选型，态度中立而选最优。8天前也就是2018年11月19号左右，Netflix的开源项目Hystrix宣布状态，不再开发新功能，处于维护状态。引发朋友圈的一些思考。 虽然Eureka，Hystrix等不再继续开发或维护，但是目前来说不影响使用，不管怎么说感谢开源，向Netflix公司的开源致敬。 随着Spring Cloud生态圈的发展与成长，Spring Cloud陆续推出了自己的一些组件，挑选主要组件说明如下表所示: 组件 来源 说明 Spring-cloud-openfeign 基于Feign的升级 服务之间调用的必备组件 spring-cloud-zuul 来源于Netflix Zuul 目前还在继续维护，但是已经有自己的Spring Cloud Gateway,不久将来逐渐淘汰 spring-cloud-eureka 集成于Netflix Eureka 目前还在跟随Spring Cloud版本升级维护，最终也会被替代 spring-cloud-config 自研 功能不足，国内使用其它配置中心替代，比如携程的Apollo 全链路监控(sleuth+zikpin或pinpont) sleuth自研，其它第三方 国内目前使用最多的是skywaling等上生产 spring-cloud-ribbon 来源于Netflix集成 ribbon目前还在跟随Spring Cloud版本维护中，目前孵化未来替代品spring-cloud-lb Spring-cloud-hystrix 来源于Netflix集成 目前还在跟随Spring Cloud版本维护中目前已经孵化spring-cloud-r4j 2. Spring Cloud 第二代 Spring Cloud第一代和第二代的组件组合汇总，如下表所示。 Spring Cloud第一代 Spring Cloud第二代 网关 Spring Cloud Zuul Spring Cloud Gateway 注册中心 eureka(不再更新)，Consul,ZK 阿里Nacos，拍拍贷radar等可选 配置中心 spring cloud config 阿里Nacos，携程Apollo，随行付Config Keeper 客户端软负载均衡 Ribbon spring-cloud-loadbalancer 熔断器 Hystrix spring-cloud-r4j(Resilience4J)，阿里Sentinel 由于Zuul性能一般，zuul 2.x(一直跳票，虽最终开源）但是Spring Cloud官方已经推出Spring Cloud gateway,Spring Cloud中国社区很久之前已经证实，Spring Cloud将不会集成zuul 2.x，也就是说在不就未来Zuul将从Spring Cloud生态圈中退出。 ribbon由于不支持webFlux的负载均衡，Spring Cloud官方很早就在孵化器项目中孵化spring-cloud-loadbalancer，目前已经将代码合并到spring-cloud-common中，预计在Spring Cloud G版可以使用，预计2018年12月底realese。 至于Hystrix，Netflix在2018年11月19号左右，Netflix的开源项目Hystrix宣布状态，不再开发新功能，处于维护状态，其实在之前Spring Cloud官方就在孵化spring-cloud-r4j. 3.开源项目的链接本文所提到的开源项目链接汇总如下所示： https://github.com/alibaba/Sentinel https://github.com/spring-cloud-incubator/spring-cloud-r4j 阿里Nacos-https://github.com/alibaba/nacos 随行付Config-keeper-https://github.com/sxfad/config-keeper spring-cloud-loadbalancer https://github.com/ctripcorp/apollo https://github.com/apache/incubator-skywalking","link":"/sc/sc2/"},{"title":"FAQ","text":"How do I put text instead of an image as my site’s logo?If you consider using a piece of text instead of an image as the logo of your site, you can do something like this: _config.yml12logo: text: My Beautiful Site How do I change the site’s language?Edit your blog’s _config.yml(not your theme’s), change the following field: 12- language: en+ language: zh-CN You can find available translations under icarus/languages folder. How to add an excerpt for a post? How to display the “Read more” button?Add &lt;!-- more --&gt; tag in your post. Post content before this tag will be marked as an excerpt and content after this tag will not show on the index page. Why aren’t my changes deployed to the Github Pages?Please run these commands before hexo deploy: 12$ hexo clean$ rm -r .deploy_git How to add meta tags for a specified post/page?You can add meta tags for each post/page through front-matter: 1234567title: test postdate: 2015-01-26 21:55:37tags:comments: false+ meta:+ - name=\"robots\";content=\"noindex, follow\"+ - name=\"another-meta\";value=\"hello world\";enabled=false Does this theme support RTL(Right-to-Left) language?Partially yes. Please refer to Issues#234 unsplash-logoChristopher Czermak","link":"/FAQ/"},{"title":"Getting Started with Icarus","text":"A simple, delicate, and modern theme for the static site generator Hexo. It allows you to set up a single or multiple-column (up to three column) blog with its versatile layout configuration. Additionally, it offers plentiful plugins and pluggable widgets so that you can enable the features you want in no time. And with the all-new API designing, Icarus makes the development of this theme painless for developers and users. To set up Icarus in your blog, please download the tarball from the GitHub and extract it to your Hexo blog’s theme directory. Alternatively, you can run the following command: 1git clone https://github.com/ppoffice/hexo-theme-icarus.git themes/icarus -b &lt;version number&gt; You may omit the -b &lt;version number&gt; to get the latest development version of Icarus. Furthermore, you can install Icarus as a git submodule by executing the following command: 1git submodule add https://github.com/ppoffice/hexo-theme-icarus.git themes/icarus Next, replace the theme setting in your blog’s _config.yml file: 1theme: icarus Finally, use the following command to start the Hexo local server and begin composing! 1hexo s Don’t forget to check out the Getting Started series to help you master Icarus quickly! Also, you can fetch the site branch from the GitHub repository if you need more configuration examples. unsplash-logoChandler Chen","link":"/Getting-Started/"},{"title":"Facebook Comment Plugin","text":"Installation instructions _config.yml12comment: type: facebook","link":"/comment/Facebook/"},{"title":"Changyan Comment Plugin","text":"Installation instructions _config.yml1234comment: type: changyan appid: xxxxxxxx # (required) conf: prod_xxxxxxxx # (required)","link":"/comment/Changyan/"},{"title":"Gitment Comment Plugin","text":"Installation instructions _config.yml123456comment: type: gitment owner: xxxxxxxx # (required) GitHub user name repo: xxxxxxxx # (required) GitHub repository name client_id: xxxxxxxx # (required) OAuth application client id client_secret: xxxxxxxx # (required) OAuth application client secret","link":"/comment/Gitment/"},{"title":"Valine Comment Plugin","text":"Installation instructions _config.yml1234567comment: type: valine app_id: xxxxxxxx # (required) LeanCloud application id app_key: xxxxxxxx # (required) LeanCloud application key notify: false # (optional) receive email notification verify: false # (optional) show verification code placeholder: xxxxxxxx # (optional) comment box placeholder text","link":"/comment/Valine/"},{"title":"Disqus Comment Plugin","text":"Installation instructions _config.yml123comment: type: disqus shortname: xxxxxxxx # (required) post.md1234# (optional) a unique id to identify the post in Disqus systemdisqusId: xxxxxxxx---Post content...","link":"/comment/Disqus/"},{"title":"LiveRe Comment Plugin","text":"Installation instructions _config.yml123comment: type: livere uid: xxxxxxxx # (required) application id of your site","link":"/comment/Livere/"},{"title":"Isso Comment Plugin","text":"Installation instructions _config.yml123comment: type: isso url: isso.service/path # (required) url of your Isso service","link":"/comment/Isso/"},{"title":"Site Analytics Plugin","text":"Google AnalyticsInstallation instructions _config.yml123plugins: google-analytics: tracking_id: XXXXXX (required) Baidu AnalyticsInstallation instructions _config.yml123plugins: baidu-analytics: tracking_id: XXXXXX (required) HotjarInstallation instructions _config.yml123plugins: hotjar: site_id: XXXXXX (required)","link":"/plugin/Analytics/"},{"title":"MathJax Plugin","text":"f(a)=12πi∮γf(z)z−adz ConfigurationTo enable MathJax support, just set plugins.mathjax = true in your theme _config.yml file. 1234# Pluginsplugins: ... mathjax: true # options: true, false For further MathJax configurations, please edit &lt;theme folder&gt;/layout/plugin/scripts.ejs:1234567&lt;% if (theme.plugins.mathjax) { %&gt; &lt;!-- Edit here --&gt; &lt;script type=\"text/x-mathjax-config\"&gt; MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\\\(','\\\\)']] } }); &lt;/script&gt; &lt;%- js('https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML') %&gt;&lt;% } %&gt; TeX and LaTeX input Attention: Please be noted that when you write Tex/LaTeX in Markdown files, you need to use escape characters to prevent certain signs from being processed by Markdown interpreter. Input12When $a \\ne 0$, there are two solutions to \\\\(ax^2 + bx + c = 0\\\\) and they are$$x = {-b \\pm \\sqrt{b^2-4ac} \\over 2a}.$$ ResultWhen $a \\ne 0$, there are two solutions to \\(ax^2 + bx + c = 0\\) and they are$$x = {-b \\pm \\sqrt{b^2-4ac} \\over 2a}.$$ MathML input Attention: please be noted that newline characters may be transformed to &lt;br&gt; tag by Markdown interpreter and this will interfere with MathML notation. Please write all MathML inline. Input12When&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo&gt;&amp;#x2260;&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/math&gt;, there are two solutions to &lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;msup&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;mo&gt;+&lt;/mo&gt; &lt;mi&gt;b&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt; &lt;mi&gt;c&lt;/mi&gt; &lt;mo&gt;=&lt;/mo&gt; &lt;mn&gt;0&lt;/mn&gt;&lt;/math&gt; and they are&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mi&gt;x&lt;/mi&gt; &lt;mo&gt;=&lt;/mo&gt;&lt;mrow&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;mo&gt;&amp;#x00B1;&lt;/mo&gt;&lt;msqrt&gt;&lt;msup&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mn&gt;4&lt;/mn&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;/msqrt&gt;&lt;/mrow&gt;&lt;mrow&gt; &lt;mn&gt;2&lt;/mn&gt;&lt;mi&gt;a&lt;/mi&gt; &lt;/mrow&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;mtext&gt;.&lt;/mtext&gt;&lt;/math&gt; ResultWhena≠0, there are two solutions to ax2+ bx+ c = 0 and they are x =−b±b2−4ac 2a . AsciiMath input Attention: please be noted that when you write AsciiMath in Markdown files, you need to use escape characters to prevent certain signs from being processed by Markdown interpreter. Input1When \\`a != 0\\`, there are two solutions to \\`ax^2 + bx + c = 0\\` and they are&lt;p style=&quot;text-align:center&quot;&gt;\\`x = (-b +- sqrt(b^2-4ac))/(2a) .\\`&lt;/p&gt; ResultWhen `a != 0`, there are two solutions to `ax^2 + bx + c = 0` and they are`x = (-b +- sqrt(b^2-4ac))/(2a) .` unsplash-logoJESHOOTS.COM","link":"/plugin/MathJax/"},{"title":"Gallery Plugin","text":"You can create a gallery by just adding photos in the post, and enable the gallery plugin in the _config.yml: 12plugins: gallery: true Furthermore, you can also use Justified Gallery to display you photos in a grid: HTML + Markdown123456789&lt;div class=\"justified-gallery\"&gt;![Elephant](/hexo-theme-icarus/gallery/animals/elephant.jpeg)![Dog](/hexo-theme-icarus/gallery/animals/dog.jpeg)![Birds](/hexo-theme-icarus/gallery/animals/birds.jpeg)![Cat](/hexo-theme-icarus/gallery/animals/cat.jpeg)![Fox](/hexo-theme-icarus/gallery/animals/fox.jpeg)![Horse](/hexo-theme-icarus/gallery/animals/horse.jpeg)![Leopard](/hexo-theme-icarus/gallery/animals/leopard.jpeg)&lt;/div&gt; The following photos come from pexel.com","link":"/plugin/Gallery/"},{"title":"Baidu Search Plugin","text":"_config.yml12search: type: baidu","link":"/search/Baidu/"},{"title":"Adding a Thumbnail to Your Article","text":"You can add thumbnail images to your posts in two steps. First, make sure the thumbnail is enabled in the theme’s configuration file: _config.yml12article: thumbnail: true Then, provide an URL or path to the image file in the front-matter of your post: post.md1234title: Getting Started with Icarusthumbnail: /gallery/thumbnails/desert.jpg---Post content... About thumbnail image pathThe image path you put in the front-matter needs to be the relative path to the source directory of your website. For example, if you want to use the following image as a thumbnail: 1&lt;your blog&gt;/source/gallery/image.jpg You need to use the following as the image path: 1/gallery/image.jpg Also, it is recommended that you put all the images under a dedicated asset folder that is separated from the _posts folder.","link":"/post/Adding-A-Thumbnail-to-Your-Article/"},{"title":"Insight Search Plugin","text":"From Icarus 2.0.0, you no longer need to install hexo-generator-json-content to use the insight search plugin. _config.yml12search: type: insight","link":"/search/Insight/"},{"title":"Google CSE Plugin","text":"Installation instructions _config.yml123search: type: google-cse cx: xxxxxxxxxxxxxxxxx # (required)","link":"/search/Google-CSE/"},{"title":"AddToAny Share Plugin","text":"Installation instructions _config.yml12share: type: addtoany","link":"/share/AddToAny/"},{"title":"Hexo Built-in Tag Helpers","text":"The following content is directly copied from Hexo official documentation Tag plugins are different from post tags. They are ported from Octopress and provide a useful way for you to quickly add specific content to your posts. Block QuotePerfect for adding quotes to your post, with optional author, source and title information. Alias: quote 123{% blockquote [author[, source]] [link] [source_link_title] %}content{% endblockquote %} ExamplesNo arguments. Plain blockquote. 123{% blockquote %}Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque hendrerit lacus ut purus iaculis feugiat. Sed nec tempor elit, quis aliquam neque. Curabitur sed diam eget dolor fermentum semper at eu lorem.{% endblockquote %} Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque hendrerit lacus ut purus iaculis feugiat. Sed nec tempor elit, quis aliquam neque. Curabitur sed diam eget dolor fermentum semper at eu lorem. Quote from a book 123{% blockquote David Levithan, Wide Awake %}Do not just seek happiness for yourself. Seek happiness for all. Through kindness. Through mercy.{% endblockquote %} Do not just seek happiness for yourself. Seek happiness for all. Through kindness. Through mercy. David LevithanWide Awake Quote from Twitter 123{% blockquote @DevDocs https://twitter.com/devdocs/status/356095192085962752 %}NEW: DevDocs now comes with syntax highlighting. http://devdocs.io{% endblockquote %} NEW: DevDocs now comes with syntax highlighting. http://devdocs.io @DevDocstwitter.com/devdocs/status/356095192085962752 Quote from an article on the web 123{% blockquote Seth Godin http://sethgodin.typepad.com/seths_blog/2009/07/welcome-to-island-marketing.html Welcome to Island Marketing %}Every interaction is both precious and an opportunity to delight.{% endblockquote %} Every interaction is both precious and an opportunity to delight. Seth GodinWelcome to Island Marketing Code BlockUseful feature for adding code snippets to your post. Alias: code 123{% codeblock [title] [lang:language] [url] [link text] %}code snippet{% endcodeblock %} ExamplesA plain code block 123{% codeblock %}alert(&apos;Hello World!&apos;);{% endcodeblock %} 1alert(&apos;Hello World!&apos;); Specifying the language 123{% codeblock lang:objc %}[rectangle setX: 10 y: 10 width: 20 height: 20];{% endcodeblock %} 1[rectangle setX: 10 y: 10 width: 20 height: 20]; Adding a caption to the code block 123{% codeblock Array.map %}array.map(callback[, thisArg]){% endcodeblock %} Array.map1array.map(callback[, thisArg]) Adding a caption and a URL 1234{% codeblock _.compact http://underscorejs.org/#compact Underscore.js %}_.compact([0, 1, false, 2, &apos;&apos;, 3]);=&gt; [1, 2, 3]{% endcodeblock %} _.compactUnderscore.js12_.compact([0, 1, false, 2, &apos;&apos;, 3]);=&gt; [1, 2, 3] Backtick Code BlockThis is identical to using a code block, but instead uses three backticks to delimit the block. 123``` [language] [title] [url] [link text]code snippet``` Pull QuoteLorem ipsum dolor sit amet, consectetur adipiscing elit. Morbi semper auctor nulla, a mollis nibh congue luctus. Maurissagittis dui sit amet scelerisque gravida. Proin porttitor convallis libero. To add pull quotes to your posts: 123{% pullquote [CSS class] %}content{% endpullquote %} jsFiddleTo embed a jsFiddle snippet: 1{% jsfiddle shorttag [tabs] [skin] [width] [height] %} GistTo embed a Gist snippet: 1{% gist gist_id [filename] %} iframeTo embed an iframe: 1{% iframe url [width] [height] %} ImageInserts an image with specified size. 1{% img [class names] /path/to/image [width] [height] [title text [alt text]] %} LinkInserts a link with target=&quot;_blank&quot; attribute. 1{% link text url [external] [title] %} Hexo.io Include CodeInserts code snippets in source/downloads/code folder. 1{% include_code [title] [lang:language] path/to/file %} YouTubeInserts a YouTube video. 1{% youtube video_id %} VimeoInserts a Vimeo video. 1{% vimeo video_id %} Include PostsInclude links to other posts. 12{% post_path slug %}{% post_link slug [title] %} Include AssetsInclude post assets. 123{% asset_path slug %}{% asset_img slug [title] %}{% asset_link slug [title] %} RawIf certain content is causing processing issues in your posts, wrap it with the raw tag to avoid rendering errors. 123{% raw %}content{% endraw %} Post ExcerptUse text placed before the &lt;!-- more --&gt; tag as an excerpt for the post. Examples: 123Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.&lt;!-- more --&gt;Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.","link":"/post/Hexo-Built-In-Tag-Helpers/"},{"title":"Table of Contents / Catalogue","text":"To display a Table of Contents / Catalogue (toc) widget on a post page, please first add toc: true to the front-matter of your post Markdown file:post.md1234title: Table of Contents Exampletoc: true---Post content... Then, add the toc widget to the theme’s configuration file: _config.yml1234widgets: - type: toc position: left First level titleSecond level titleThird level titleLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque rutrum faucibus tellus in lobortis. Etiam ultriceset risus at tempor. Aenean mollis in metus sed rutrum. Sed aliquet vel urna in luctus. Donec at sodales mauris. Donecsed metus fermentum, pellentesque velit ac, tincidunt augue. Integer mattis risus a finibus iaculis. Donec mattis,tellus a iaculis fringilla, ante quam rutrum urna, a mollis lorem lacus cursus risus. Pellentesque a quam in tellustincidunt imperdiet. Etiam eget fringilla risus. Praesent mauris massa, aliquam non nibh et, commodo rutrum ligula. Duisfermentum gravida lectus at placerat. Suspendisse blandit rutrum lacus vel semper. Nulla magna ex, gravida quis antesed, gravida ornare ipsum. [TOP] Another third level titlePellentesque porta odio sed odio venenatis, non efficitur est scelerisque. Vivamus dignissim ac massa in feugiat. Donecauctor pulvinar arcu. Aenean auctor mi sed enim aliquam euismod. Vivamus eros arcu, faucibus non ullamcorper at,sagittis a turpis. Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas.Suspendisse potenti. Cras et viverra felis. Fusce ullamcorper ex a orci eleifend tempor. Cras lacinia efficitur viverra.Aenean lobortis placerat rhoncus. Praesent luctus pellentesque tristique. Cras convallis dignissim odio, sit ametsagittis purus euismod et. [TOP] Another second level titlePhasellus ipsum urna, laoreet venenatis augue eleifend, dignissim tempor sem. Donec consectetur magna vitae orci viverra,sit amet lacinia dolor sagittis. Pellentesque quis sagittis elit. Cras mattis velit ac lacus rutrum, quis luctus enimscelerisque. Vestibulum eu tincidunt felis, in molestie nunc. Donec condimentum ultrices erat, volutpat ultricies nisi.Pellentesque eu dui vitae augue congue accumsan. Proin eleifend tristique metus nec cursus. [TOP] Another first level titleDonec id erat in nulla condimentum commodo. Curabitur iaculis id ipsum a cursus. Vestibulum volutpat leo at dignissimsemper. Fusce at ex nec ipsum vestibulum posuere. Phasellus pretium felis tellus, non commodo dui tristique eu. Doneciaculis posuere augue, ac condimentum purus feugiat sit amet. Etiam rutrum non mauris et pulvinar. Vestibulum ac nullamagna. [TOP] Final titleSuspendisse potenti. Fusce ullamcorper lacus vitae leo dignissim malesuada. Sed commodo efficitur fermentum. Maecenasmollis eget massa a tincidunt. Etiam non arcu lorem. In imperdiet venenatis ipsum, vitae venenatis magna tristique sitamet. Donec quis pulvinar orci, sagittis convallis nisi. [TOP]","link":"/post/Table-of-Contents/"},{"title":"AddThis Share Plugin","text":"Installation instructions _config.yml123share: type: addthis install_url: //s7.addthis.com/js/300/addthis_widget.js#pubid=xxxxxxxx # (required)","link":"/share/AddThis/"},{"title":"Baidu Share Plugin","text":"Installation instructions _config.yml12share: type: bdshare","link":"/share/BaiduShare/"},{"title":"ShareThis Share Plugin","text":"Installation instructions _config.yml123share: type: sharethis install_url: //platform-api.sharethis.com/js/sharethis.js#...... # (required)","link":"/share/ShareThis/"},{"title":"Configuring Icarus","text":"The configuration of Icarus consists of two parts: theme configuration and post configuration. Theme ConfigurationIcarus uses the _config.yml file for global page layout, plugins and widgets settings. It will check and validate the configuration file, points out any misconfigurations, and generates one for you if none exists. You can check the specifications at any time from the *.spec.js files inside the themes/icarus/includes/specs folder. A default theme configuration consists of the following parts: Site preference and page meta data Top navigation bar links Page footer links Article display settings Comment, share and search plugin settings Sidebar widget settings Other display and analytics plugins CDN settings Most of the settings are documented in the _config.yml file. For more details on configuring plugins, you can refer to the online documentation. Post ConfigurationApart from the global theme configuration, you can also make customizations in any post. That is, you can override the theme configurations from a post. Let’s say you want to show different navigation bar menus in a post. To do this, you only need to put the navbar settings in the post’s front-matter: 1234navbar: menu: Home: / Special!: /special The configurations you set here will be applied only to this post. This feature can be very useful for displaying customized/optimized pages to a specific audience. For example, you can enable faster CDNs or a localized comment service based on the country and language of the page viewers. unsplash-logoAlex Holt","link":"/theme/Configuring-Icarus/"},{"title":"Share.js Share Plugin","text":"Installation instructions _config.yml12share: type: sharejs","link":"/share/Sharejs/"},{"title":"Speed up Your Site with Custom CDN","text":"Using a right CDN provider can speed up page loading process of your viewers. Icarus allows you to specify the CDN provider of third-party static libraries you want to use. Built-in CDN providersCurrently, you can choose between these built-in providers: General CDNs CDN.js (cdnjs) jsDelivr (jsdelivr) Unpkg (unpkg) Font CDNs Google Fonts (google) Icon Font CDNs Font Awesome (fontawesome) The default CDN settings are: 1234providers: cdn: jsdelivr fontcdn: google iconcdn: fontawesome Custom CDN providersAdditionally, you can also use custom CDN providers by putting their URLs in the configuration file. For general CDNs, you should provide a URL format string with the following format: 1https://some.cdn.domain.name/${package}/${version}/${filename} You need to replace the actual package name, version of the package and relative file path with ${package}, ${version}, and ${filename} placeholders. For example, a JavaScript library with the following URL 1https://unpkg.com/d3@5.7.0/dist/d3.min.js can be generalized to this 1https://unpkg.com/${package}@${version}/${filename} You should know that CDN providers may adopt different URL schemes where the package name and file path for a library are not exactly the same. For example, the moment.js library has the URL like this on CDN.js: 1https://cdnjs.cloudflare.com/ajax/libs/moment.js/2.22.2/moment.js while has the following URL on Unpkg: 1https://unpkg.com/moment@2.22.2/min/moment.min.js Therefore, you should be aware of the URL format of your custom CDN provider. By default, Icarus will try to pass in the parameter just like they would be for an npm repository (e.g., `moment@2.22.2/min/moment.min.js). This npm scheme is used by jsDelivr and Unpkg. Otherwise, if you are using a CDN.js like provider, please prepend[cdnjs]` to its format string: 1[cdnjs]https://some.cdn.domain.name/${package}/${version}/${filename} For font CDN, you can pass in the URL of a Google Font mirror or compatible webfont CDN. Icarus depends on the Ubuntu and Source Code Pro fonts, so make sure your CDN provides those. The URL should have two placeholders for font type (icon or font) and font name: 1https://some.google.font.mirror/${type}?family=${fontname} For icon CDN, you can pass in the URL to a custom Font Awesome CDN. No placeholders are required. The provided custom CDN should at lease have Font Awesome 5 icons as some of them are used in this theme. 1https://custom.fontawesome.mirror/some.stylesheet.css All of the above should be put in the provider section of theme configuration file: 1234providers: cdn: 'https://some.cdn.domain.name/${package}/${version}/${filename}' fontcdn: 'https://some.google.font.mirror/${type}?family=${fontname}' iconcdn: 'https://custom.fontawesome.mirror/some.stylesheet.css' CDN helper functionsThree helper functions have been defined to help developers include third-party libraries easily with custom CDN support. You can check them out in includes/helpers/cdn.js under the Icarus theme folder.","link":"/theme/Custom-CDN/"},{"title":"Polymorphic Link Settings","text":"You may already notice that Icarus allows you to put icon links on the right of the navigation bar, the bottom of the profile widget, and the right side of the footer with the following format: 12345678footer: links: 'Creative Commons': icon: fab fa-creative-commons url: 'https://creativecommons.org/' 'Attribution 4.0 International': icon: fab fa-creative-commons-by url: 'https://creativecommons.org/licenses/by/4.0/' In the above link format, you need to specify the name of the link (e.g., Creative Commons), as well as the icon class name (e.g., Font Awesome class name) and link URL. However, Icarus also accept pure text links with a link name and URL in the format below: 1234footer: links: 'Creative Commons': 'https://creativecommons.org/' 'Attribution 4.0 International': 'https://creativecommons.org/licenses/by/4.0/' unsplash-logoEvie Shaffer","link":"/theme/Polymorphic-Link-Settings/"},{"title":"Make a Sidebar Sticky When Page Scrolls","text":"Sometimes you may want your sidebar’s position to stay fixed when other parts of your page scrolls. This can be done via the sticky option of the sidebar in the theme’s _config.yml. You can set any of the sidebar or even both of them to sticky. 12345sidebar: left: sticky: false right: sticky: true This is some really long content.","link":"/theme/Sticky-Sidebar/"},{"title":"اختبار اللغة العربية","text":"كل تصفح بالفشل التّحول ذات, أعمال اعتداء المتحدة مكن ٣٠. تلك للسيطرة واشتدّت أن, بل انذار العاصمة الخاسرة أما. تحت مع دفّة بالرّغم, وبالرغم وبالتحديد، مع جهة. مسارح يتمكن يتسنّى جهة ان, التي اتفاقية قد كان. فمرّ الوراء ان غير. شيء ما شمال أدوات بالجانب, لكل وشعار اتفاق بـ, بها الإنزال مواقعها في. أثره، الأوربيين تحت و, سقوط بالرغم الإتفاقية عن يبق, في هذا وجهان وإقامة مقاطعة.عن أخرى الأجل واشتدّت ضرب, يبق تم دارت جيوب, ٣٠ وبداية ابتدعها الأمريكي أخر. لم كما شرسة غرّة، الأعمال, كل بخطوط وعُرفت الضروري ولم, وسفن واستمرت تلك من. مع حيث وأزيز الأخذ, فاتّبع مقاطعة ويكيبيديا، عن وفي, بـ لها كثيرة المتحدة. قد ضرب وسوء إعلان, ان وتم اعتداء إستيلاء, يكن نقطة معاملة ثم. بحث في بلديهما الصينية, هذه ما حصدت شرسة, ذات أم الشمل والقرى. بينما أوراقهم مكن تم, تحت أي وفنلندا بمحاولة شموليةً. بحث عن بلديهما المنتصر, لم شاسعة للجزر كلا. بل مما وتنصيب بمباركة والكوري, هناك الأرض تم قبل. غضون عُقر الجديدة، يبق مع, أثره، واُسدل استعملت تم تلك. عن فصل هُزم والنرويج. قد بحق أواخر نتيجة قُدُماً, جعل ان تمهيد الشتاء الشّعبين. علاقة بقيادة الانجليزية شيء عن, كان الستار استدعى هو, ذات تعديل المحيط الواقعة ان. في غير مليون وبالرغم تزامناً, ان جُل حقول يذكر بالعمل, ما انه فشكّل والنفيس. لكل معارضة بمحاولة الإقتصادية عن, من تلك الشمل الأبرياء. أمّا والعتاد هو ولم, مما كردة الجو ابتدعها ثم. الغالي العالم إيو هو. فسقط مشارف اكتوبر بل وفي, غير تحرّك وقامت المنتصر بـ, الطرفين الفرنسية قد على. الى هو إستعمل السيطرة, ضرب رئيس مساعدة ثم. عدد مرجع وبحلول عل, قبل الشرقية أوراقهم لبلجيكا، عن. هو إحتار والتي المنتصر بحث, قد بحق سياسة ميناء لإعادة, مكن لفشل الشّعبين إذ. كان عل جيما بشرية لإعلان. ٣٠ معاملة الأثنان بها. عملية الصين وتنصيب أخذ تم, يبق بالرغم العاصمة في. دفّة إختار ولاتّساع في عدم. دنو فهرست وقوعها، عل, قبل ٠٨٠٤ ومحاولة لم. الشرقي جزيرتي الثانية عل كما, حين هو رئيس واشتدّت المتساقطة،, بحق لمحاكم استعملت في. ان وإقامة والمعدات لها, هو إيو مئات يرتبط. بحق مع وصغار وهولندا،, بعد سقوط لإنعدام لم, يكن قد وكسبت الأوروبي. بل لعدم الأمور واستمر كلا. تم حول مكثّفة البرية الإنزال. هو إعلان مدينة لهيمنة أخذ. دار وبعض لهذه الأسيوي ان, حدى سكان بقسوة أن, أم الأولى الجديدة، كلا. عرض ٣٠ وبعد ماذا بتحدّي, بالفشل تزامناً التكاليف يكن عن. كل فمرّ وانتهاءً حين. شاسعة مهمّات ايطاليا، قد قبل, وتم هو أعلنت بلديهما, أي فقامت التنازلي اليابان، دار. ثم ضمنها الإمتعاض بريطانيا-فرنسا على, قد حول وقرى استدعى. أوروبا ألمانيا ٣٠ يبق. عرض إذ احداث الصين. في بين ببعض ويكيبيديا،, وصل بسبب تحرير النفط بـ. التي ضمنها به، إذ, دارت مشروط أي حول, فقد عن فقامت الأرضية ماليزيا،. تنفّس انتهت يونيو شيء إذ, أي عدم لليابان الدولارات. وإقامة الخاطفة والمانيا عن حول. بل جُل أكثر والإتحاد, تم ضرب انتباه والإتحاد. من قامت انتهت دنو. unsplash-logoDan Freeman","link":"/translation/Arabic/"},{"title":"Sidebar Widgets Overview","text":"With the brand-new widget configuration scheme, you can place any widgets on either side of the page and set up them fair easily. Icarus reads the list of widgets that are enabled from _config.yml and displays them in the order they are defined. The following widgets are supported in Icarus 2.0.0: Archives (archive) Categories (category) Links (links) Profiles (profile) Recent Posts (recent_posts) Tags (tag) Tag Cloud (tagcloud) Table of Content / Catalogue (toc) The enabled widgets are defined as an array. Each widget has two mandatory fields in common: type and position. The type field specific what widget is enabled and can be one of the (name) above. The position can be either left or right, which tells on which side will the widget be placed. 12345678910111213141516widgets: - type: category position: left - type: tagcloud position: left - type: recent_posts position: right - type: archive position: right - type: tag position: right Most of these widgets do not take any extra configurations. However, for those who do, please refer to the documentation.","link":"/widget/Sidebar-Widgets-Overview/"},{"title":"Links Sidebar Widget","text":"You can show a list of links to other websites in the sidebar by enabling the links widget. Add the following configuration to the widgets section in your _config.yml file, and you are good to go: 1234567- type: links position: left links: 'Website name': 'http://website/url' Hexo: 'https://hexo.io' PPOffice: 'https://github.com/ppoffice' One thing you should note is that the links widget only takes a list of website name and URL, and the URL is displayed on the right side of the widget.","link":"/widget/Links/"},{"title":"Icarus快速上手","text":"作为静态网站生成器Hexo的一款主题，Icarus以简洁、现代和精美为设计理念。在灵活且强大的配置系统的助力下，用户可以自由实现单栏与多栏的灵活页面布局。同时，Icarus提供了丰富的插件与挂件供用户选择，让网站的个性化配置变得触手可及。此外，得力于全新设计的API，开发者可以更便捷地对Icarus进行深层定制。 Icarus的安装非常简单，您只需从GitHub的仓库中下载Icarus源码并解压到博客的主题目录下的icarus目录中(themes/icarus)。您也可以使用如下命令将此主题下载到博客中： 1git clone https://github.com/ppoffice/hexo-theme-icarus.git themes/icarus -b &lt;version number&gt; 您可以省略-b &lt;version number&gt;来下载Icarus的最新开发版本。另外，您也可以将Icarus安装为Git子模块(submodule)到您的博客中： 1git submodule add https://github.com/ppoffice/hexo-theme-icarus.git themes/icarus 接下来，请将博客根目录下的_config.yml中的主题设置改为icarus： 1theme: icarus 最后，请使用如下命令来启动Hexo本地测试服务器。祝您下笔如有神！ 1hexo s 在此网站上您可以阅读开始使用系列文章来快速掌握Icarus。同时，如果需要更多的Icarus使用示例，您可以从GitHub上下载site分支的Icarus源码。 unsplash-logoPascal Müller","link":"/translation/Chinese/"},{"title":"Profile Sidebar Widget","text":"Icarus offers a way to showcase yourself using the profile sidebar widget. To use this widget, add the following lines to the widgets section of your _config.yml: _config.yml12345678910- type: profile position: # show in left or right sidebar author: # your name author_title: # your title location: # where are you avatar: # path or url to your avatar image gravatar: # your gravatar email follow_link: # path or url to any page you want social_links: # add links to your social network here There are two things that you should note: If you want to Gravatar, fill in your email in the gravatar field. Otherwise, leave it blank in case it overrides the avatar setting. The social_links field accepts an array of links which are either shown as a text link or icon link. The details are described in Polymorphic Link Settings. unsplash-logoJoey Pilgrim","link":"/widget/Profile/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","link":"/tags/Spring-Boot/"},{"name":"项目经验","slug":"项目经验","link":"/tags/项目经验/"},{"name":"Eureka Server","slug":"Eureka-Server","link":"/tags/Eureka-Server/"},{"name":"Spring Cloud","slug":"Spring-Cloud","link":"/tags/Spring-Cloud/"},{"name":"http2","slug":"http2","link":"/tags/http2/"},{"name":"Spring Cloud Eureka","slug":"Spring-Cloud-Eureka","link":"/tags/Spring-Cloud-Eureka/"},{"name":"Spring Cloud Netflix","slug":"Spring-Cloud-Netflix","link":"/tags/Spring-Cloud-Netflix/"},{"name":"Eureka","slug":"Eureka","link":"/tags/Eureka/"},{"name":"Spring Cloud Feign","slug":"Spring-Cloud-Feign","link":"/tags/Spring-Cloud-Feign/"},{"name":"Spring Cloud Gateway","slug":"Spring-Cloud-Gateway","link":"/tags/Spring-Cloud-Gateway/"},{"name":"Spring Cloud 源码分析","slug":"Spring-Cloud-源码分析","link":"/tags/Spring-Cloud-源码分析/"},{"name":"Spring Cloud Zuul","slug":"Spring-Cloud-Zuul","link":"/tags/Spring-Cloud-Zuul/"},{"name":"Spring Cloud自研组件","slug":"Spring-Cloud自研组件","link":"/tags/Spring-Cloud自研组件/"},{"name":"实践分享","slug":"实践分享","link":"/tags/实践分享/"},{"name":"Spring Cloud Fegin","slug":"Spring-Cloud-Fegin","link":"/tags/Spring-Cloud-Fegin/"},{"name":"Spring Cloud Sleuth","slug":"Spring-Cloud-Sleuth","link":"/tags/Spring-Cloud-Sleuth/"},{"name":"全链路监控","slug":"全链路监控","link":"/tags/全链路监控/"},{"name":"微服务","slug":"微服务","link":"/tags/微服务/"},{"name":"Spring Cloud Config","slug":"Spring-Cloud-Config","link":"/tags/Spring-Cloud-Config/"},{"name":"tools","slug":"tools","link":"/tags/tools/"},{"name":"dincos","slug":"dincos","link":"/tags/dincos/"},{"name":"Venus Framework","slug":"Venus-Framework","link":"/tags/Venus-Framework/"},{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"Lombok","slug":"Lombok","link":"/tags/Lombok/"},{"name":"开发工具","slug":"开发工具","link":"/tags/开发工具/"},{"name":"沉思录","slug":"沉思录","link":"/tags/沉思录/"},{"name":"代码片","slug":"代码片","link":"/tags/代码片/"},{"name":"mysql","slug":"mysql","link":"/tags/mysql/"},{"name":"Jdk","slug":"Jdk","link":"/tags/Jdk/"},{"name":"Venus Boot","slug":"Venus-Boot","link":"/tags/Venus-Boot/"},{"name":"并发编程","slug":"并发编程","link":"/tags/并发编程/"},{"name":"多线程","slug":"多线程","link":"/tags/多线程/"},{"name":"基础架构","slug":"基础架构","link":"/tags/基础架构/"},{"name":"hexo","slug":"hexo","link":"/tags/hexo/"},{"name":"云计算SaaS","slug":"云计算SaaS","link":"/tags/云计算SaaS/"},{"name":"微服务网关","slug":"微服务网关","link":"/tags/微服务网关/"},{"name":"Netty","slug":"Netty","link":"/tags/Netty/"},{"name":"MyBatis","slug":"MyBatis","link":"/tags/MyBatis/"},{"name":"网关中间件","slug":"网关中间件","link":"/tags/网关中间件/"},{"name":"中间件","slug":"中间件","link":"/tags/中间件/"},{"name":"数据库连接池","slug":"数据库连接池","link":"/tags/数据库连接池/"},{"name":"重新定义","slug":"重新定义","link":"/tags/重新定义/"},{"name":"Spring Cloud Ribbon","slug":"Spring-Cloud-Ribbon","link":"/tags/Spring-Cloud-Ribbon/"},{"name":"代码生成器","slug":"代码生成器","link":"/tags/代码生成器/"},{"name":"Getting Started","slug":"Getting-Started","link":"/tags/Getting-Started/"},{"name":"Advanced Topics","slug":"Advanced-Topics","link":"/tags/Advanced-Topics/"}],"categories":[{"name":"Spring Boot","slug":"Spring-Boot","link":"/categories/Spring-Boot/"},{"name":"Eureka Server","slug":"Eureka-Server","link":"/categories/Eureka-Server/"},{"name":"Spring Cloud","slug":"Spring-Cloud","link":"/categories/Spring-Cloud/"},{"name":"社区","slug":"社区","link":"/categories/社区/"},{"name":"跟我学Spring Cloud","slug":"跟我学Spring-Cloud","link":"/categories/跟我学Spring-Cloud/"},{"name":"Spring Cloud Eureka","slug":"Spring-Cloud-Eureka","link":"/categories/Spring-Cloud-Eureka/"},{"name":"Spring Cloud Gateway","slug":"Spring-Cloud-Gateway","link":"/categories/Spring-Cloud-Gateway/"},{"name":"Spring Cloud Sleuth","slug":"Spring-Cloud-Sleuth","link":"/categories/Spring-Cloud-Sleuth/"},{"name":"tools","slug":"tools","link":"/categories/tools/"},{"name":"dincos","slug":"dincos","link":"/categories/dincos/"},{"name":"venus","slug":"venus","link":"/categories/venus/"},{"name":"项目经验","slug":"项目经验","link":"/categories/项目经验/"},{"name":"沉思录","slug":"沉思录","link":"/categories/沉思录/"},{"name":"代码片","slug":"代码片","link":"/categories/代码片/"},{"name":"java","slug":"java","link":"/categories/java/"},{"name":"Venus Boot","slug":"Venus-Boot","link":"/categories/Venus-Boot/"},{"name":"并发编程","slug":"并发编程","link":"/categories/并发编程/"},{"name":"中间件","slug":"中间件","link":"/categories/中间件/"},{"name":"云计算Saas","slug":"云计算Saas","link":"/categories/云计算Saas/"},{"name":"Janus网关","slug":"Janus网关","link":"/categories/Janus网关/"},{"name":"Netty","slug":"Netty","link":"/categories/Netty/"},{"name":"MyBatis","slug":"MyBatis","link":"/categories/MyBatis/"},{"name":"重新定义","slug":"重新定义","link":"/categories/重新定义/"},{"name":"Plugins","slug":"Plugins","link":"/categories/Plugins/"},{"name":"Comment","slug":"Plugins/Comment","link":"/categories/Plugins/Comment/"},{"name":"General","slug":"Plugins/General","link":"/categories/Plugins/General/"},{"name":"Search","slug":"Plugins/Search","link":"/categories/Plugins/Search/"},{"name":"Configuration","slug":"Configuration","link":"/categories/Configuration/"},{"name":"Posts","slug":"Configuration/Posts","link":"/categories/Configuration/Posts/"},{"name":"Share","slug":"Plugins/Share","link":"/categories/Plugins/Share/"},{"name":"Theme","slug":"Configuration/Theme","link":"/categories/Configuration/Theme/"},{"name":"Translations","slug":"Translations","link":"/categories/Translations/"},{"name":"Widgets","slug":"Widgets","link":"/categories/Widgets/"}]}